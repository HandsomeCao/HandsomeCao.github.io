<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>linear-algebra</title>
      <link href="/2020/03/02/linear-algebra/"/>
      <url>/2020/03/02/linear-algebra/</url>
      <content type="html"><![CDATA[<h1 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h1><p><a href="http://www.huaxiaozhuan.com/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/chapters/1_algebra.html" target="_blank" rel="noopener">地址</a></p><h2 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h2><pre><code class="lang-python">import numpy as npimport torch</code></pre><h3 id="向量"><a href="#向量" class="headerlink" title="向量"></a>向量</h3><script type="math/tex; mode=display">\vec x = (x_{1}, x_{2},...x_{n})^{T}</script><pre><code class="lang-python">x = np.array([1, 2, 3])y = torch.Tensor([1, 2, 3])print(x, y)</code></pre><pre><code>[1 2 3] tensor([1., 2., 3.])</code></pre><h3 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h3><pre><code class="lang-python">x = np.array([[1, 2, 3],[4, 5, 6]])y = torch.Tensor([[1, 2, 3], [4, 5, 6]])print(x)print(y)</code></pre><pre><code>[[1 2 3] [4 5 6]]tensor([[1., 2., 3.],        [4., 5., 6.]])</code></pre><h3 id="矩阵的F范数"><a href="#矩阵的F范数" class="headerlink" title="矩阵的F范数"></a>矩阵的F范数</h3><p>设矩阵 $A=(a_{i,j})_{m,n}$,则其<code>F</code>范数为<script type="math/tex">||A||_{F}=\sqrt{\sum_{i,j}a^2_{i,j}}</script></p><pre><code class="lang-python">l2_x = np.linalg.norm(x)l2_y = torch.norm(y)print(&quot;norm of x is {}&quot;.format(l2_x))print(&quot;norm of y is {}&quot;.format(l2_y))</code></pre><pre><code>norm of x is 9.539392014169456norm of y is 9.539392471313477</code></pre><h3 id="矩阵的迹"><a href="#矩阵的迹" class="headerlink" title="矩阵的迹"></a>矩阵的迹</h3><p>矩阵$A=(a_{i,j})_{m,n}$，则$A$的迹为:</p><script type="math/tex; mode=display">tr(A)=\sum_{i}{a_{i,i}}</script><pre><code class="lang-python">x_trace = x.trace()y_trace = torch.trace(y)print(&quot;trace of x is {}&quot;.format(x_trace))print(&quot;trace of y is {}&quot;.format(y_trace))</code></pre><pre><code>trace of x is 6trace of y is 6.0</code></pre><h2 id="矩阵运算"><a href="#矩阵运算" class="headerlink" title="矩阵运算"></a>矩阵运算</h2><h3 id="逐元素积（哈达玛积）"><a href="#逐元素积（哈达玛积）" class="headerlink" title="逐元素积（哈达玛积）"></a>逐元素积（哈达玛积）</h3><script type="math/tex; mode=display">\vec u * \vec v = [u_{i,j}v_{i,j},...]</script><pre><code class="lang-python"># 向量a = np.arange(0,9)b = a[::-1]c = a * bprint(&quot;dot of vector a,b is {}&quot;.format(c))</code></pre><pre><code>dot of vector a,b is [ 0  7 12 15 16 15 12  7  0]</code></pre><pre><code class="lang-python"># 矩阵a = np.arange(1, 5).reshape(2,2)b = np.arange(5, 9).reshape(2,2)c = a * bprint(&quot;dot of matrix a,b is {}&quot;.format(c))</code></pre><pre><code>dot of matrix a,b is [[ 5 12] [21 32]]</code></pre><pre><code class="lang-python"># pytorcha = torch.arange(1,5).reshape(2,2)b = torch.arange(5,9).view(2, 2)print(a * b)print(a.mul(b))</code></pre><pre><code>tensor([[ 5, 12],        [21, 32]])tensor([[ 5, 12],        [21, 32]])</code></pre><h3 id="点积（矩阵乘法）"><a href="#点积（矩阵乘法）" class="headerlink" title="点积（矩阵乘法）"></a>点积（矩阵乘法）</h3><script type="math/tex; mode=display">(AB)_{ij} = \sum_{k=1}^{p}a_{ik}b_{kj}</script><pre><code class="lang-python">a = np.arange(1, 5).reshape(2,2)b = np.arange(5, 9).reshape(2,2)np.dot(a,b)</code></pre><pre><code>array([[19, 22],       [43, 50]])</code></pre><pre><code class="lang-python">a = torch.arange(1,5).reshape(2,2)b = torch.arange(5,9).view(2, 2)a.mm(b)</code></pre><pre><code>tensor([[19, 22],        [43, 50]])</code></pre><h3 id="克罗内克积"><a href="#克罗内克积" class="headerlink" title="克罗内克积"></a>克罗内克积</h3><script type="math/tex; mode=display">A \bigotimes B = \begin{bmatrix} a_{1,1}B &... &a_{1,n}B \\ ... & ... &...\\a_{m,1}B & ... &a_{m,n}B \end{bmatrix}</script><pre><code class="lang-python">a = np.arange(1, 5).reshape(2,2)b = np.arange(5, 9).reshape(2,2)np.kron(a,b)</code></pre><pre><code>array([[ 5,  6, 10, 12],       [ 7,  8, 14, 16],       [15, 18, 20, 24],       [21, 24, 28, 32]])</code></pre><h2 id="特殊函数"><a href="#特殊函数" class="headerlink" title="特殊函数"></a>特殊函数</h2><h3 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h3><script type="math/tex; mode=display">\sigma (x) = \frac{1}{1+exp(-x)}</script><ul><li>导数<script type="math/tex; mode=display">\sigma^{'}(x) = \sigma(x) \cdot (1-\sigma(x))</script></li><li>值域在0和1之间，用于二分类</li><li>函数具有非常好的对称性</li><li>在趋于无穷时，函数值变化小，容易产生梯度消失</li></ul><pre><code class="lang-python">import matplotlib.pyplot as plt%matplotlib inlinedef sigmoid(x):    return 1. / (1.+np.exp(-x))x = np.arange(-5, 5, 0.2)y = sigmoid(x)plt.plot(x,y)plt.show()</code></pre><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcfptc2pqcj30ac06w3yg.jpg" alt="png"></p><h3 id="softplus函数"><a href="#softplus函数" class="headerlink" title="softplus函数"></a>softplus函数</h3><script type="math/tex; mode=display">\zeta(x) = log(1+exp(x)</script><ul><li>平滑版的ReLu函数</li><li>导数:<script type="math/tex; mode=display">\frac{d}{dx}\zeta(x) = \sigma(x)</script></li></ul><pre><code class="lang-python">def softplus(x):    return np.log(1.+np.exp(x))x = np.arange(-10, 10, 0.2)y = softplus(x)plt.plot(x,y)plt.show()</code></pre><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcfptby0sej30a806wwef.jpg" alt="png"></p><h3 id="伽玛函数"><a href="#伽玛函数" class="headerlink" title="伽玛函数"></a>伽玛函数</h3><script type="math/tex; mode=display">\Gamma(x) = \int_{0}^{\infty}t^{x-1}e^{-t} \mathrm{d}x</script><ul><li>对于整数$n$：$\Gamma(n)=(n-1)!$</li><li>$\Gamma(x+1)=x\Gamma(x)$</li><li>对于$x \in (0,1)$:<script type="math/tex; mode=display">\Gamma(1-x)\Gamma(x) = \frac{\pi}{sin\pi x}</script>可以推出重要公式: $\Gamma(\frac{1}{2}) = \sqrt{\pi}$</li></ul><pre><code class="lang-python">from scipy.special import gammax = np.linspace(0, 5, 100)y = gamma(x)plt.plot(x,y)plt.show()</code></pre><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcfptbqkjnj30a806zq2w.jpg" alt="png"></p><h3 id="贝塔函数"><a href="#贝塔函数" class="headerlink" title="贝塔函数"></a>贝塔函数</h3><script type="math/tex; mode=display">B(m,n) = \int_{0}{1} x^{m-1}(1-x)^{n-1} \mathrm{d}x</script><ul><li>与伽玛函数关系:<script type="math/tex; mode=display">B(m,n) = \frac{\Gamma(m)\Gamma(n)}{\Gamma(m+n)}</script><script type="math/tex; mode=display">B(m,1-m) = \Gamma(m)\Gamma(1-m)</script></li><li>对称性: $B(m,n) = B(n,m)$</li></ul>]]></content>
      
      
        <tags>
            
            <tag> 数学 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>first-logic</title>
      <link href="/2019/10/11/first-logic/"/>
      <url>/2019/10/11/first-logic/</url>
      <content type="html"><![CDATA[<h2 id="Augmenting-Neural-Networks-with-First-order-Logics"><a href="#Augmenting-Neural-Networks-with-First-order-Logics" class="headerlink" title="Augmenting Neural Networks with First-order Logics"></a>Augmenting Neural Networks with First-order Logics</h2><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><p>这篇论文提出一个新的框架，将外部一阶逻辑知识系统地嵌入到计算图中以增强网络，并且没有<strong>额外网络参数</strong>和<strong>网络二次设计</strong>，在三个任务：阅读理解、语言推理和文本分块任务中进行了实验，在小数据量下有效提升了基准模型。</p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><pre><code>这篇论文利用公开知识（一阶逻辑形式）来解决网络训练所需要的大量数据。例如，在机器阅读理解任务中，通常使用的是**注意力机制**去匹配单词作为中间步骤，进而找到文本中的答案段。</code></pre><p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g7r4mifls1j30v20keq6r.jpg" alt=""></p><pre><code>作者认为实则上不需要这么复杂的注意力机制去*Align*单词，实则上只需要一些简单的规则，例如*ConceptNet*中的方法，如果这种公开的规则能够加入到网络的训练之中，那么自然而然就会减少对数据的依赖。这篇论文主要关注三个问题：</code></pre><ol><li>能否将公开的规则(外部知识)整合到端到端的网络训练之中？</li><li>这种规则能够减轻网络对数据的需要？</li><li>使用外部领域知识这种方法和现在的利用大量数据预训练获得语句表达的方法比起来哪一个更好？</li></ol><p>其中第一个问题是这篇论文主要解决的，更重要的是其中规则是不可导的，要将其嵌入到网络之中，就要讲规则转化为可导的，嵌入到网络的计算图中。这篇论文主要做了这些贡献：</p><ol><li>提出一个新的框架将一阶逻辑整合到网络的训练和预测之中。</li><li>在三个自然语言处理的任务中进行实验，在小样本训练数据时，都有很大的提高。</li></ol><ul><li><p><strong>ConceptNet</strong></p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g7rw0g5tzmj31rp0u0dt0.jpg" alt=""></p></li></ul><h3 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h3><h4 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h4><p>神经网络可以看作是<strong>非循环</strong>的计算图$G=(V,E)$，其中的节点$V$有时没有实在的意义，但有时却因为任务的不同节点被嵌入了一些语义，而作者们的目标就是通过公开的规则来增强神经网络中的<strong>神经元</strong>。</p><h4 id="一阶逻辑"><a href="#一阶逻辑" class="headerlink" title="一阶逻辑"></a>一阶逻辑</h4><pre><code>                                                    $$L \to R$$</code></pre><p>可表达为$L$引起了$R$，即若$L$，则$R$。将一阶逻辑嵌入到网络中主要有三个难点：</p><ol><li>需要将一阶逻辑中的断言映射为神经网络中的神经元节点。</li><li>逻辑是不可微的，需要将逻辑编码保证可导性，从而使用梯度方法训练。</li><li>网络计算图是非循环的，而用户定义的规则是可能循环的，所以要解决循环性。</li></ol><h5 id="表示"><a href="#表示" class="headerlink" title="表示"></a>表示</h5><ul><li>$a_{i},b_{j}$为计算图节点</li><li>$A_{i}，B_{j}$为规则中的断言</li></ul><h5 id="循环性"><a href="#循环性" class="headerlink" title="循环性"></a>循环性</h5><p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g7r5zs909bj30v40ke418.jpg" alt=""></p><p>对于如图的神经网络，$A_{1}\land B_{1}\to A_{2} \land B_{2}$是循环的，而$A_{1} \land A_{2} \to B_{1} \land B_{2}$是非循环的。</p><p>有时通过一些等价变化可以将循环的断言变成非循环的，这也是一种方法，例如：$B_{1} \to A_{1}$对于上面的图是循环的，而等价的$\neg A_{1} \to \neg B_{1}$是非循环的</p><h3 id="整体框架"><a href="#整体框架" class="headerlink" title="整体框架"></a>整体框架</h3><h5 id="条件距离函数-Constraints-Beget-Distance-Functions"><a href="#条件距离函数-Constraints-Beget-Distance-Functions" class="headerlink" title="条件距离函数(Constraints Beget Distance Functions)"></a>条件距离函数(Constraints Beget Distance Functions)</h5><p>假设非循环条件语句</p><pre><code>                                                    $$Z \to Y$$</code></pre><p>定义与$Y$联系的神经元为</p><pre><code>                                                    $$y=g(Wx)$$</code></pre><p>其中$g$代表激活函数，$W$为网络参数，$x$是对$y$的输入。此外，使用向量$z$代表断言$Z$。</p><h5 id="限制网络层-Constrained-Neural-Layers"><a href="#限制网络层-Constrained-Neural-Layers" class="headerlink" title="限制网络层(Constrained Neural Layers)"></a>限制网络层(Constrained Neural Layers)</h5><p>作者的目标是去增强$y$的计算，从而无论$Z$何时为真，如果$Y$不是否定的，那么$y$进入激活函数都是增加的。所以定义限制网络层为：</p><pre><code>                                                    $$y=g(Wx+\rho d(z))$$</code></pre><p>其中$d$就是作为距离函数，$\rho \ge 0$。</p><h5 id="距离函数的设计"><a href="#距离函数的设计" class="headerlink" title="距离函数的设计"></a>距离函数的设计</h5><p>理想中的距离函数如下，</p><pre><code>                            $$d_{i d e a l}(\mathbf{z})=\left\{\begin{array}{ll}{1,} &amp; {\text { if } Z \text { holds }} \\ {0,} &amp; {\text { otherwise }}\end{array}\right.$$</code></pre><p>可惜的是它并不可微。所以需要做一些平滑的替代。</p><p>作者在论文中使用了自己设计的距离函数，这个函数是由probabilistic soft logic (c.f. Klement et al., 2013) and its use of the Łukasiewicz T-norm and T-conorm所启发的。</p><p><img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g7rwq7wjnej30wo0oo0w9.jpg" alt=""></p><p>上表表现了对于$Z$不同的与或逻辑处理，所使用的不同距离函数$d(z)$。例如对于第一行，当其中一个$Z_{i}$为假，距离函数的值就会变为0。</p><h5 id="否定假设"><a href="#否定假设" class="headerlink" title="否定假设"></a>否定假设</h5><p>对于$Z \to Y$，前因$Z$和结果$Y$都有可能是否定的。表1的第三和第四行代表了否定的$Z$这种情况，而对于否定的结果$Y$，需要减小神经元$y$进入激活函数前的分数，所以只需要对整个距离函数取负就行。</p><h5 id="规划因子-rho"><a href="#规划因子-rho" class="headerlink" title="规划因子$\rho$"></a>规划因子$\rho$</h5><ol><li>当$\rho = +\infty$，神经元进入激活函数前的分数将由距离函数所控制，此时就将是有一个<strong>硬限制(hard constraint)</strong>。</li><li>当$\rho$很小时，输出结果将取决于$Wx$和距离函数两者，此时叫做<strong>软限制</strong>，而距离函数更多的是起个建议作用。</li></ol><h5 id="普遍的布尔前置"><a href="#普遍的布尔前置" class="headerlink" title="普遍的布尔前置"></a>普遍的布尔前置</h5><p>之前只考虑的是与或这两种单一存在的情况，现在考虑更为普遍的情况。假设现在有个断言前置为</p><pre><code>                                                    $$(\neg A \lor B) \land (C \lor D)$$</code></pre><p>首先我们取中间变量将其转化为</p><pre><code>                                                    $$P \land Q$$</code></pre><p>其中$(\neg A \lor B)\leftrightarrow P $，$(C \lor D) \leftrightarrow Q$。要这样做，需要使用辅助神经元来表示$P$和$Q$，并且辅助神经元完全需要被双向限制。</p><h5 id="限制辅助层"><a href="#限制辅助层" class="headerlink" title="限制辅助层"></a>限制辅助层</h5><p>对于$Z \leftrightarrow Y$，定义辅助层为</p><pre><code>                                                    $$y=d(z)$$</code></pre><p>和之前相比，现在不需要激活函数，因为距离是属于$[0,1]$的，可以直接表示为分数。所以之前的距离函数现在仍然适用。</p><h5 id="结构增强网络"><a href="#结构增强网络" class="headerlink" title="结构增强网络"></a>结构增强网络</h5><p>依据给的<strong>条件语句</strong>和<strong>计算图</strong>可以将框架流程总结为：</p><ol><li>如果有必要，将语句前置转化为与或逻辑形式</li><li>将与或形式根据之前的表转化为距离函数</li><li>根据距离函数去生成限制辅助层或限制网络层去替代原来的网络层。</li><li>最后使用增强的网络去进行训练和推理。</li></ol><h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="机器阅读理解"><a href="#机器阅读理解" class="headerlink" title="机器阅读理解"></a>机器阅读理解</h4><ul><li>使用数据集为SQuAD，外部资源为ConceptNet。</li></ul><h5 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h5><p>使用的基线模型为BiDAF，另一个为使用ELMo增强的BiDAF。将模型实施步骤简化为如下：</p><ol><li><script type="math/tex; mode=display">p, q = encoder(p), encoder(q)</script></li><li>$\overleftarrow{a}, \overrightarrow{a} = \sigma(layers(p, q))$</li><li><script type="math/tex; mode=display">y, z = \sigma(layers(p, q, \overleftarrow{a}, \overrightarrow{a}))</script></li></ol><p>其中$p, q$是篇章和问题，$\sigma$代表softmax激活函数，$\overleftarrow{a},\overrightarrow{a}$代表$q$对$p$以及$p$对$q$的双向注意力，$y,z$是输出答案边界的概率。</p><h5 id="增强"><a href="#增强" class="headerlink" title="增强"></a>增强</h5><p>作者使用ConceptNet来代替上方的步骤二去获得相关单词之间的关系。具体地，使用两条规则来诠释他们框架的灵活。首先有如下定义：</p><ul><li>$K_{i, j}$：单词$p_{i}$在ConceptNet中与单词$q_{i}$有以下联系<strong>{Synonym, DistinctFrom, IsA, Related}</strong></li><li>$\overleftarrow{A_{i, j}}$：没有限制的模型对$p_{i}$和$q_{j}$最佳匹配关系的决策。</li><li>$\overleftarrow{A_{i, j}^{‘}}$：有限制的模型对以上关系的决策。</li></ul><p>根据以上定义，有以下规则：</p><script type="math/tex; mode=display">\begin{array}{ll}{R_{1}:} & {\forall i, j \in C, K_{i, j} \rightarrow \overleftarrow A_{i, j}^{\prime}} \\ {R_{2}:} & {\forall i, j \in C, K_{i, j} \wedge {A}_{i, j} \rightarrow \overleftarrow A_{i, j}^{\prime}}\end{array}</script><p>其中$R_{1}$代表如果两个单词在ConceptNet中有关系，则这两个单词在模型编码结果应该相<strong>aligned</strong></p><p>而$R_{2}$代表有限制的模型结果是与两者相关的：不仅是ConceptNet,还有原本的模型结果。</p><p>因为$K_{i, j}$不能映射到网络中的一个结点，所以作者创造了一个新结点$k_{i,j}$，它的值是由ConceptNet决定的。</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20191011142151.png" alt=""></p><h5 id="是否提升模型效果，和预训练模型比较？"><a href="#是否提升模型效果，和预训练模型比较？" class="headerlink" title="是否提升模型效果，和预训练模型比较？"></a>是否提升模型效果，和预训练模型比较？</h5><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20191011143236.png" alt=""></p><p>在数据量更少时，提升更多。$R_{1}$比$R_{2}$效果更好。</p><h4 id="自然语言推理"><a href="#自然语言推理" class="headerlink" title="自然语言推理"></a>自然语言推理</h4><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20191011202501.png" alt=""></p><h4 id="句子分块-命名实体识别"><a href="#句子分块-命名实体识别" class="headerlink" title="句子分块(命名实体识别)"></a>句子分块(命名实体识别)</h4>]]></content>
      
      
        <tags>
            
            <tag> 算法 </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker-install</title>
      <link href="/2019/09/06/docker-install/"/>
      <url>/2019/09/06/docker-install/</url>
      <content type="html"><![CDATA[]]></content>
      
      
    </entry>
    
    <entry>
      <title>transformer</title>
      <link href="/2019/08/07/transformer/"/>
      <url>/2019/08/07/transformer/</url>
      <content type="html"><![CDATA[<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20190807161255.png" alt=""></p><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self Attention"></a>Self Attention</h3><h3 id="Position-Encoding"><a href="#Position-Encoding" class="headerlink" title="Position Encoding"></a>Position Encoding</h3>]]></content>
      
      
        <tags>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>vscode-docker</title>
      <link href="/2019/07/13/vscode-docker/"/>
      <url>/2019/07/13/vscode-docker/</url>
      <content type="html"><![CDATA[<h2 id="使用vscode连接远程docker"><a href="#使用vscode连接远程docker" class="headerlink" title="使用vscode连接远程docker"></a>使用vscode连接远程docker</h2><p>之前写代码一般简单的话都在<code>jupyter</code>或者<code>vim</code>上写，复杂的话就在本地写好之后再传到服务器上，但由于本地和服务器环境不同，往往需要下载很多包，才能更好完成代码编写，终于找到一个方法能实时编写服务器上容器上的代码，记录一下。</p><h3 id="docker配置"><a href="#docker配置" class="headerlink" title="docker配置"></a>docker配置</h3><ol><li><p>首先重新运行一个容器，这个容器在之前的基础上新加上一个对服务器主机22端口的映射，因为ssh到服务器端口一般是22.</p><pre><code class="lang-bash">$ sudo docker run -p 7964:8888 -p 7965:5000 -p 7966:6000 -p 8022:22 -it -v /home/caoshuai/:/root/workspace --runtime=nvidia --name=&quot;caoshuai&quot; f722eab170b7 /bin/bash</code></pre></li><li><p>进入容器之后在容器内安装<code>openssh-server</code></p><pre><code class="lang-bash">$ apt-get update$ apt-get install -y openssh-server</code></pre></li><li><p>建立一个文件，并对ssh做相关的配置</p><pre><code class="lang-bash">$ mkdir /var/run/sshd$ echo &#39;root:[passwd]&#39; | chpasswd# 这里使用你自己想设置的用户名和密码，但是一定要记住！$ sed -i &#39;s/PermitRootLogin prohibit-password/PermitRootLogin yes/&#39; /etc/ssh/sshd_config$ sed &#39;s@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g&#39; -i /etc/pam.d/sshd$ echo &quot;export VISIBLE=now&quot; &gt;&gt; /etc/profile</code></pre></li><li><p>重启ssh激活配置</p><pre><code class="lang-bash">$ service ssh restart</code></pre></li><li><p>在服务器主机上测试刚才新建容器哪个端口映射到服务器上22号端口，并测试能否ssh到docker容器内</p><pre><code class="lang-bash">$ sudo docker port [your_container_name] 22# 如果前面的配置生效了，你会看到如下输出# 0.0.0.0:8022$ ssh root@[your_host_ip] -p 8022# 密码是你前面自己设置的</code></pre><p>到这里docker 环境就配置完成，接下来vscode配置就简单了。</p></li></ol><h3 id="Vscode配置"><a href="#Vscode配置" class="headerlink" title="Vscode配置"></a>Vscode配置</h3><ol><li><p>安装<strong>Remote SSH插件</strong>(或Remote Devolopment三件套)</p></li><li><p>安装完成之后只需要<code>ctrl+shift+p</code>选择<code>ssh-setting</code>并配置相应ssh host即可</p><pre><code class="lang-txt">HostName: [ip地址]User: [用户名(docker就是root)]Port: [端口号8022]</code></pre></li><li><p>接下来就选择连接到Remote Host并输入之前设置的密码就可以愉快地使用Vscode远程开发啦！</p></li></ol><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><p><a href="https://www.itcodemonkey.com/article/15433.html" target="_blank" rel="noopener">PyCharm + Docker：打造最舒适的深度学习炼丹炉</a></p>]]></content>
      
      
        <tags>
            
            <tag> vscode </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>中文分词</title>
      <link href="/2019/07/07/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/"/>
      <url>/2019/07/07/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/</url>
      <content type="html"><![CDATA[<h2 id="中文分词算法及实现"><a href="#中文分词算法及实现" class="headerlink" title="中文分词算法及实现"></a>中文分词算法及实现</h2><h3 id="主流方法"><a href="#主流方法" class="headerlink" title="主流方法"></a>主流方法</h3><p>中文分类方法大致可以分为以下三类：</p><ul><li>基于词表的分词方法<ul><li>正向最大匹配法FMM</li><li>逆向最大匹配法BMM</li><li>N-最短路径方法</li></ul></li><li>基于统计模型的分词方法<ul><li>基于n-gram语言模型的分词方法</li></ul></li><li>基于序列标注的分词方法<ul><li>基于HMM的分词方法</li><li>基于CRF的分词方法</li><li>基于词感知机的分词方法</li><li>基于深度学习的端到端的分词方法</li></ul></li></ul><h3 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h3><ul><li><p>准确率(Precision)</p><script type="math/tex; mode=display">Precision=\frac{WordCount(CorrectResults)}{WordCount(TrainSet)}</script></li><li><p>召回率(Recall)</p><script type="math/tex; mode=display">Recal=\frac{WordCount(CorrectResults)}{WordCount(TestSet)}</script></li><li><p>F-测度</p><script type="math/tex; mode=display">F1=\frac{2 * P*R}{P+R}</script></li><li><p>未登录词的召回率(ROOV)</p></li><li>词典词的召回率（RIV）</li></ul><h3 id="基于词表的最大匹配方法"><a href="#基于词表的最大匹配方法" class="headerlink" title="基于词表的最大匹配方法"></a>基于词表的最大匹配方法</h3><p>正向最大匹配和反向最大匹配算法实际上都是通过贪心的方法依据词典切分出当前位置上长度最大的词，只是两种方法对于句子的处理方向不同而已。FMM实质上是很简单粗暴的匹配方法，对于一些歧义词的处理能力很一般。一般来说，BMM方法要优于FMM方法，但现在是几乎不会使用这种基于匹配的方法了。</p><p>BMM算法：</p><p>逆向匹配法思想与正向一样，只是从右向左切分，这里举一个例子：<br>输入例句：S1=”计算语言学课程有意思” ；<br>定义：最大词长MaxLen = 5；S2= “ “；分隔符 = “/”；<br>假设存在词表：…，计算语言学，课程，意思，…；<br><strong>最大逆向匹配分词算法</strong>过程如下：<br>（1）S2=””；S1不为空，从S1右边取出候选子串W=”课程有意思”；<br>（2）查词表，W不在词表中，将W最左边一个字去掉，得到W=”程有意思”；<br>（3）查词表，W不在词表中，将W最左边一个字去掉，得到W=”有意思”；<br>（4）查词表，W不在词表中，将W最左边一个字去掉，得到W=”意思”<br>（5）查词表，“意思”在词表中，将W加入到S2中，S2=” 意思/“，并将W从S1中去掉，此时S1=”计算语言学课程有”；<br>（6）S1不为空，于是从S1左边取出候选子串W=”言学课程有”；<br>（7）查词表，W不在词表中，将W最左边一个字去掉，得到W=”学课程有”；<br>（8）查词表，W不在词表中，将W最左边一个字去掉，得到W=”课程有”；<br>（9）查词表，W不在词表中，将W最左边一个字去掉，得到W=”程有”；<br>（10）查词表，W不在词表中，将W最左边一个字去掉，得到W=”有”，这W是单字，将W加入到S2中，S2=“ /有 /意思”，并将W从S1中去掉，此时S1=”计算语言学课程”；<br>（11）S1不为空，于是从S1左边取出候选子串W=”语言学课程”；<br>（12）查词表，W不在词表中，将W最左边一个字去掉，得到W=”言学课程”；<br>（13）查词表，W不在词表中，将W最左边一个字去掉，得到W=”学课程”；<br>（14）查词表，W不在词表中，将W最左边一个字去掉，得到W=”课程”；<br>（15）查词表，“意思”在词表中，将W加入到S2中，S2=“ 课程/ 有/ 意思/”，并将W从S1中去掉，此时S1=”计算语言学”；<br>（16）S1不为空，于是从S1左边取出候选子串W=”计算语言学”；<br>（17）查词表，“计算语言学”在词表中，将W加入到S2中，S2=“计算语言学/ 课程/ 有/ 意思/”，并将W从S1中去掉，此时S1=””；<br>（18）S1为空，输出S2作为分词结果，分词过程结束。</p><pre><code class="lang-python">class BMM(object):    def __init__(self,                 dict_path=&#39;./dict.txt&#39;,                 max_word_length=5,                 split_mark=&#39;/&#39;):        self.dict = self.load_dict(_get_abs_path(dict_path))        self.max_word_length = max_word_length        self.split_mark = split_mark    def load_dict(self, path):        word_dict = []        with open(path, &#39;r&#39;, encoding=&#39;utf-8&#39;) as fr:            for line in fr:                word = line.strip().split(&#39; &#39;)[0]                word_dict.append(word)        return word_dict    def seg(self, line):        &quot;&quot;&quot;        seg the line into word list        &quot;&quot;&quot;        word_list = []        s1 = line[-self.max_word_length:]        while len(s1):            if s1 in self.dict or len(s1) == 1:                word_list.append(s1)                s1 = line[:len(line)-len(&#39;&#39;.join(word_list))]            else:                s1 = s1[1:]        return self.split_mark.join(word_list[::-1])</code></pre><h3 id="基于n-gram语言模型的分词方法"><a href="#基于n-gram语言模型的分词方法" class="headerlink" title="基于n-gram语言模型的分词方法"></a>基于n-gram语言模型的分词方法</h3><p>假设$S$表示一个有意义的句子，由一连串特定顺序排列的词$w_{1}, w_{2},…., w_{n}$组成，则此句子成立的概率为</p><script type="math/tex; mode=display">P(S)=P\left(w_{1}\right) P\left(w_{2} | w_{1}\right) P\left(w_{3} | w_{1}, w_{2}\right) \cdots P\left(w_{n} | w_{1}, w_{2}, \dots, w_{n-1}\right)</script><p>$P(S)$称为语言模型，<strong>就是建立了一个基于统计的模型去计算一个序列$S$的可能性</strong>。 </p><p><strong>N-gram就是语言模型。</strong>对于前面提到的语言模型从计算上来看，序列的前两个词的条件概率 <img src="https://www.zhihu.com/equation?tex=P%28w_%7B1%7D%29%2CP%28w_%7B2%7D%7Cw_%7B1%7D%29" alt="[公式]"> 不难计算，但是，越到后面的单词可能性越多，无法估算。因此，引入马尔可夫假设：任意一个词出现的概率只和它前面的几个词有关，于是 <img src="https://www.zhihu.com/equation?tex=P%28S%29%3DP%28w_%7B1%7D%29P%28w_%7B2%7D%7Cw_%7B1%7D%29P%28w_%7B3%7D%7Cw_%7B2%7D%29%5Ccdot%5Ccdot%5Ccdot+P%28w_%7Bn%7D%7Cw_%7Bn-1%7D%29" alt="[公式]"> ，这就是N-gram模型中的二元模型(bigram)。同理，可得到一元模型(unigram)、三元模型(trigram)的定义。</p><p>求解概率：</p><h4 id="P-left-w-i-w-i-1-right-frac-P-left-w-i-1-w-i-right-P-left-w-i-1-right"><a href="#P-left-w-i-w-i-1-right-frac-P-left-w-i-1-w-i-right-P-left-w-i-1-right" class="headerlink" title="$P\left(w_{i} | w_{i-1}\right)=\frac{P\left(w_{i-1}, w_{i}\right)}{P\left(w_{i-1}\right)}$"></a>$P\left(w_{i} | w_{i-1}\right)=\frac{P\left(w_{i-1}, w_{i}\right)}{P\left(w_{i-1}\right)}$</h4><p>当训练集语料库足够大，通过其相应的词和词对的频数，相对频度就约等于概率。所以<strong>BI-gram</strong>分词时，有以下步骤：</p><ol><li>首先要准备一个足够大语料库作为训练集，对此语料库构造出<strong>词频统计字典</strong>和<strong>每个词之后的词频度字典</strong></li><li>要分词的语句首先找出所有可能的备选分词结果，根据<strong>词频统计字典</strong>中出现的键递归寻找。</li><li>对每个分词结果，计算其相应的概率$P$，输出最大的就为分词结果。而怎么计算$P$可见下面的代码</li></ol><pre><code class="lang-python">def _get_prob(self, result):        &quot;&quot;&quot;        计算每种情况的概率分数        &quot;&quot;&quot;        p = 1.0        for index in range(len(result)):            if index == 0:                if result[index] in self.word_count:                    # 第一项a在词频表中，p = (count(a) + 1) / count(all)                    p *= ((self.word_count[result[index]] + 1) / self.length)                else:                    # 若不在则 p = 1 / count(all)                    p *= (1 / self.length)            else:                if result[index - 1] in self.word2_dict and \                        result[index] in self.word2_dict[result[index - 1]]:                    # 若前一项a存在于gram表，且下一项b存在于它对应的value中                    # p = (count(b|a) + 1) / count(|a)                    p *= ((self.word2_dict[result[index - 1]][result[index]] + 1) /                          self.word_next_count[result[index - 1]])                elif result[index - 1] in self.word2_dict:                    # 若前一项a存在于gram表，但下一项b不存在于它对应的value中                    # p = 1 / count(|a)                    p *= (1 / self.word_next_count[result[index - 1]])                else:                    p = p * pow(0.1, 10)        return p</code></pre><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ul><li>比赛<strong>SIGHAN</strong><a href="http://sighan.cs.uchicago.edu/bakeoff2005/" target="_blank" rel="noopener">官网</a></li><li><a href="http://www.52nlp.cn/maximum-matching-method-of-chinese-word-segmentation" target="_blank" rel="noopener">中文分词入门之最大匹配法</a></li><li></li></ul>]]></content>
      
      
        <tags>
            
            <tag> 分词 </tag>
            
            <tag> 算法 </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>redis</title>
      <link href="/2019/06/10/redis/"/>
      <url>/2019/06/10/redis/</url>
      <content type="html"><![CDATA[<h1 id="Redis数据库学习"><a href="#Redis数据库学习" class="headerlink" title="Redis数据库学习"></a>Redis数据库学习</h1><p>Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。</p><p>Redis 与其他 key - value 缓存产品有以下三个特点：</p><ul><li>Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li><li>Redis支持数据的备份，即master-slave模式的数据备份。</li></ul><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><pre><code class="lang-bash">sudo apt-get install redis-server</code></pre><h3 id="后台启动服务"><a href="#后台启动服务" class="headerlink" title="后台启动服务"></a>后台启动服务</h3><pre><code class="lang-bash"># 默认启动redis-server &amp;# 以配置文件启动</code></pre><pre><code class="lang-bash">(venv) root@5fb46468cb96:~/workspace# redis-cli127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; get foo&quot;bar&quot;127.0.0.1:6379&gt; del foo   # 删除此键对</code></pre><h3 id="Redis对键操作"><a href="#Redis对键操作" class="headerlink" title="Redis对键操作"></a>Redis对键操作</h3><div class="table-container"><table><thead><tr><th><strong>命令</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td><em>DEL key</em></td><td>该命令用于在 key 存在时删除 key。</td></tr><tr><td><em>DUMP key</em></td><td>序列化给定 key ，并返回被序列化的值。</td></tr><tr><td><em>EXISTS key</em></td><td>检查给定 key 是否存在。</td></tr><tr><td><em>EXPIRE key <seconds></seconds></em></td><td>为给定 key 设置过期时间，以秒计。</td></tr><tr><td><em>EXPIRE key <timestamp></timestamp></em></td><td>EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。</td></tr><tr><td><em>PEXPIRE key <milliseconds></milliseconds></em></td><td>设置 key 的过期时间以毫秒计。</td></tr><tr><td><em>KEYS pattern</em></td><td>查找所有符合给定模式( pattern)的 key 。</td></tr><tr><td><em>MOVE key <db></db></em></td><td>将当前数据库的 key 移动到给定的数据库 db 当中。</td></tr><tr><td><em>PERSIST key</em></td><td>移除 key 的过期时间，key 将持久保持。</td></tr><tr><td><em>PTTL key</em></td><td>以毫秒为单位返回 key 的剩余的过期时间。</td></tr><tr><td><em>TTL key</em></td><td>以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。</td></tr><tr><td><em>RANDOMKEY</em></td><td>从当前数据库中随机返回一个 key 。</td></tr><tr><td><em>RENAME key newkey</em></td><td>修改 key 的名称</td></tr><tr><td><em>RENAMENX key newkey</em></td><td>仅当 newkey 不存在时，将 key 改名为 newkey 。</td></tr><tr><td><em>TYPE key</em></td><td>返回 key 所储存的值的类型。</td></tr></tbody></table></div><h3 id="Redis-Hash"><a href="#Redis-Hash" class="headerlink" title="Redis Hash"></a>Redis Hash</h3><blockquote><p>Redis Hash 是一个string类型的field和value的映射表， 特别适合用于存储对象</p></blockquote><pre><code class="lang-bash">127.0.0.1:6379&gt; HMSET coos name &quot;coos redis&quot; description &quot;coos des&quot; likes 20 visitors 2000OK127.0.0.1:6379&gt; HGETALL coos  # 获取所有键值对1) &quot;name&quot;2) &quot;coos redis&quot;3) &quot;description&quot;4) &quot;coos des&quot;5) &quot;likes&quot;6) &quot;20&quot;7) &quot;visitors&quot;8) &quot;2000&quot;127.0.0.1:6379&gt; HDEL coos likes  # 删除likes字段(integer) 1127.0.0.1:6379&gt; HGETALL coos1) &quot;name&quot;2) &quot;coos redis&quot;3) &quot;description&quot;4) &quot;coos des&quot;5) &quot;visitors&quot;6) &quot;2000&quot;127.0.0.1:6379&gt; HGET coos visitors  # 获取visitors字段&quot;2000&quot;</code></pre><h3 id="Redis-列表-List"><a href="#Redis-列表-List" class="headerlink" title="Redis 列表(List)"></a>Redis 列表(List)</h3><p>Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）</p><p>一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。</p><pre><code class="lang-bash">127.0.0.1:6379&gt; LPUSH run redis(integer) 1127.0.0.1:6379&gt; LPUSH run mongodb(integer) 2127.0.0.1:6379&gt; LPUSH run mysql(integer) 3127.0.0.1:6379&gt; LRANGE run 0 101) &quot;mysql&quot;2) &quot;mongodb&quot;3) &quot;redis&quot;127.0.0.1:6379&gt; LINDEX run 2&quot;redis&quot;</code></pre><h3 id="Redis集合-Set"><a href="#Redis集合-Set" class="headerlink" title="Redis集合(Set)"></a>Redis集合(Set)</h3><p>Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。</p><p>Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。</p><p>集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。</p><pre><code class="lang-bash">redis 127.0.0.1:6379&gt; SADD runoobkey redis(integer) 1redis 127.0.0.1:6379&gt; SADD runoobkey mongodb(integer) 1redis 127.0.0.1:6379&gt; SADD runoobkey mysql(integer) 1redis 127.0.0.1:6379&gt; SADD runoobkey mysql(integer) 0redis 127.0.0.1:6379&gt; SMEMBERS runoobkey1) &quot;mysql&quot;2) &quot;mongodb&quot;3) &quot;redis&quot;</code></pre><h3 id="Redis有序集合-Sorted-Set"><a href="#Redis有序集合-Sorted-Set" class="headerlink" title="Redis有序集合(Sorted Set)"></a>Redis有序集合(Sorted Set)</h3><p>Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。</p><p>不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。</p><p>有序集合的成员是唯一的,但分数(score)却可以重复。</p><p>集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。</p><pre><code class="lang-bash">redis 127.0.0.1:6379&gt; ZADD runoobkey 1 redis(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 2 mongodb(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 3 mysql(integer) 1redis 127.0.0.1:6379&gt; ZADD runoobkey 3 mysql(integer) 0redis 127.0.0.1:6379&gt; ZADD runoobkey 4 mysql(integer) 0redis 127.0.0.1:6379&gt; ZRANGE runoobkey 0 10 WITHSCORES1) &quot;redis&quot;2) &quot;1&quot;3) &quot;mongodb&quot;4) &quot;2&quot;5) &quot;mysql&quot;6) &quot;4&quot;</code></pre><ul><li>INFO 查看Redis服务器信息</li></ul><h3 id="Redis数据备份与恢复"><a href="#Redis数据备份与恢复" class="headerlink" title="Redis数据备份与恢复"></a>Redis数据备份与恢复</h3><p><strong>备份</strong></p><pre><code class="lang-bash">redis 127.0.0.1:6379&gt; SAVE OK</code></pre><p>该命令将在 redis 安装目录中创建dump.rdb文件。</p><p><strong>恢复</strong></p><p>如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 <strong>CONFIG</strong> 命令，如下所示：</p><pre><code class="lang-bash">127.0.0.1:6379&gt; CONFIG GET dir1) &quot;dir&quot;2) &quot;/root/workspace&quot;</code></pre><p>参考：</p><p><a href="https://www.runoob.com/redis/redis-tutorial.html" target="_blank" rel="noopener">Redis 教程</a></p>]]></content>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>neo4j</title>
      <link href="/2019/06/05/neo4j/"/>
      <url>/2019/06/05/neo4j/</url>
      <content type="html"><![CDATA[<h2 id="Neo4j学习"><a href="#Neo4j学习" class="headerlink" title="Neo4j学习"></a>Neo4j学习</h2><blockquote><p>Neo4j是一个世界领先的开源图形数据库。 它是由Neo技术使用Java语言完全开发的。图形数据库是以图形结构的形式存储数据的数据库。 它以节点，关系和属性的形式存储应用程序的数据。 正如RDBMS以表的“行，列”的形式存储数据，GDBMS以“图形”的形式存储数据。</p></blockquote><p>图形数据库数据模型的主要构建块是：</p><ul><li>节点</li><li>关系</li><li>属性</li></ul><h3 id="CQL语句"><a href="#CQL语句" class="headerlink" title="CQL语句"></a>CQL语句</h3><div class="table-container"><table><thead><tr><th>S.NO</th><th>CQL命令/条</th><th>用法</th></tr></thead><tbody><tr><td>1.</td><td>Create创建</td><td>创建节点，关系和属性</td></tr><tr><td>2.</td><td>Match匹配</td><td>检索有关节点，关系和属性数据</td></tr><tr><td>3.</td><td>RETURN返回</td><td>返回查询结果</td></tr><tr><td>4.</td><td>WHERE哪里</td><td>提供条件过滤检索数据</td></tr><tr><td>5.</td><td>DELETE删除</td><td>删除节点和关系</td></tr><tr><td>6.</td><td>REMOVE移除</td><td>删除节点和关系属性</td></tr><tr><td>7.</td><td>ORDER BY以..排序</td><td>排序检索数据</td></tr><tr><td>8.</td><td>SET组</td><td>添加或更新标签</td></tr></tbody></table></div><h3 id="CQL函数"><a href="#CQL函数" class="headerlink" title="CQL函数"></a>CQL函数</h3><div class="table-container"><table><thead><tr><th>S.NO</th><th>定制列表功能</th><th>用法</th></tr></thead><tbody><tr><td>1.</td><td>String字符串</td><td>它们用于使用String字面量</td></tr><tr><td>2.</td><td>Aggregation聚合</td><td>它们用于对CQL查询结果执行一些聚合操作</td></tr><tr><td>3.</td><td>RelationShip关系</td><td>它们用于获取关系的细节。</td></tr></tbody></table></div><h3 id="创建结点"><a href="#创建结点" class="headerlink" title="创建结点"></a>创建结点</h3><pre><code class="lang-cypher">$ CREATE (   &lt;node-name&gt;:&lt;label-name&gt;   {           &lt;Property1-name&gt;:&lt;Property1-Value&gt;      ........      &lt;Propertyn-name&gt;:&lt;Propertyn-Value&gt;   })# $CREATE (emp:Employee{id:123, name:&quot;Smith&quot;, sal:35000, deptno:10})</code></pre><h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><pre><code class="lang-cypher">$ MATCH (&lt;node-name&gt;:&lt;label-name&gt;) RETURN &lt;node-name&gt;.att1, &lt;node-name&gt;.att2,.......</code></pre><h3 id="创建关系"><a href="#创建关系" class="headerlink" title="创建关系"></a>创建关系</h3><pre><code class="lang-cypher">$ CREATE (p1:Profile1)-[r1:LIKES]-&gt;(p2:Profile2)$ CREATE     (&lt;node1-label-name&gt;:&lt;node1-name&gt;)-   [&lt;relationship-label-name&gt;:&lt;relationship-name&gt;]-&gt;   (&lt;node1-label-name&gt;:&lt;node1-name&gt;)RETURN &lt;relationship-label-name&gt;</code></pre><h3 id="查询关系"><a href="#查询关系" class="headerlink" title="查询关系"></a>查询关系</h3><pre><code class="lang-cypher">$ MATCH (node1)-[r:rname]-&gt;(node2) RETURN r$ MATCH (&lt;node1-label-name&gt;)-[&lt;relationship-label-name&gt;:&lt;relationship-name&gt;]-&gt;(&lt;node2-label-name&gt;)RETURN &lt;relationship-label-name&gt;</code></pre><h3 id="条件查询"><a href="#条件查询" class="headerlink" title="条件查询"></a>条件查询</h3><pre><code class="lang-cypher">$ MATCH (node_name:node_label) WHERE node_name.att1 = &#39;xxxx&#39; OR/AND ... RETURN ...</code></pre><h3 id="使用py2neo操作neo4j数据库"><a href="#使用py2neo操作neo4j数据库" class="headerlink" title="使用py2neo操作neo4j数据库"></a>使用py2neo操作neo4j数据库</h3><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><pre><code class="lang-bash">pip install py2neo</code></pre><h4 id="节点与关系"><a href="#节点与关系" class="headerlink" title="节点与关系"></a>节点与关系</h4><pre><code class="lang-python">from py2neo.data import Node, Relationshipa = Node(&#39;Person&#39;, name=&quot;Alice&quot;)b = Node(&quot;Person&quot;, name=&quot;Bob&quot;)ab = Relationship(a, &quot;KNOWS&quot;, b)ab###(Alice)-[:KNOWS {}]-&gt;(Bob)</code></pre><p>Node 和 Relationship 都继承了 PropertyDict 类，它可以赋值很多属性，类似于字典的形式，例如可以通过如下方式对 Node 或 Relationship 进行属性赋值，接着上面的代码，实例如下:</p><pre><code class="lang-python">a[&#39;age&#39;] = 20b[&#39;age&#39;] = 21ab[&#39;time&#39;] = &#39;2017/08/31&#39;print(a, b, ab)###out(:Person {age: 20, name: &#39;Alice&#39;}) (:Person {age: 21, name: &#39;Bob&#39;}) (Alice)-[:KNOWS {time: &#39;2019/6/5&#39;}]-&gt;(Bob)</code></pre><p>使用<strong>update</strong>批量对属性进行更新</p><pre><code class="lang-python">data = {    &#39;name&#39;: &#39;Amy&#39;,    &#39;age&#39;: 21}a.update(data)print(a)###out(:Person {age: 21, name: &#39;Amy&#39;})</code></pre><h3 id="Subgraph子图"><a href="#Subgraph子图" class="headerlink" title="Subgraph子图"></a>Subgraph子图</h3><p>Subgraph，子图，是 Node 和 Relationship 的集合，最简单的构造子图的方式是通过关系运算符|，实例如下：</p><pre><code class="lang-python">s = a | b | abprint(s)###out&lt;py2neo.data.Subgraph at 0x7fe45c8b2470&gt;# ({(alice:Person {name:&quot;Alice&quot;}), (bob:Person {name:&quot;Bob&quot;})}, {(alice)-[:KNOWS]-&gt;(bob)})</code></pre><ul><li>在v4版本，输出s.nodes是一个SetView对象，需要使用<strong>list转换</strong>,即可打印出来</li></ul><pre><code class="lang-python">print(list(s.nodes))###out[(:Person {name: &#39;Alice&#39;}), (:Person {name: &#39;Bob&#39;})]</code></pre><h3 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h3><p>在 database 模块中包含了和 Neo4j 数据交互的 API，最重要的当属 <strong>Graph</strong>，它代表了 Neo4j 的图数据库，同时 Graph 也提供了许多方法来操作 Neo4j 数据库，直接调用cyper语句操作neo4j。</p><pre><code>from py2neo import Graphgraph = Graph(password=&quot;123456&quot;)# 执行查询graph.run(&quot;MATCH (a:Person) RETURN a.name, a.born LIMIT 4&quot;)# 创建节点关系node = Node(.....)graph.create(node)</code></pre><p>参考：</p><ul><li><a href="https://py2neo.org/v4/" target="_blank" rel="noopener">The py2neo v4 Handbook</a></li><li><a href="https://blog.csdn.net/qq_19707521/article/details/80060675" target="_blank" rel="noopener">Neo4j操作与py2neo用法</a></li></ul>]]></content>
      
      
        <tags>
            
            <tag> 知识图谱，neo4j </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ElasticSearch</title>
      <link href="/2019/05/29/ElasticSearch/"/>
      <url>/2019/05/29/ElasticSearch/</url>
      <content type="html"><![CDATA[<h2 id="ElasticSearch入门"><a href="#ElasticSearch入门" class="headerlink" title="ElasticSearch入门"></a>ElasticSearch入门</h2><blockquote><p><strong>ElasticSearch</strong>是一个实时分布式搜索和分析引擎。它让你以前所未有的速度处理大数据成为 可能。 它用于全文搜索、结构化搜索、分析以及将这三者混合使用 。Elasticsearch是一个基于<strong>Apache Lucene(TM)</strong>的开源搜索引擎。无论在开源还是专有领域， Lucene可以被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。    </p></blockquote><h3 id="安装并运行ElasticSearch"><a href="#安装并运行ElasticSearch" class="headerlink" title="安装并运行ElasticSearch"></a>安装并运行ElasticSearch</h3><ol><li><p>安装Elasticsearch首先需要安装java，去官网下载1.8版本即可。</p></li><li><p>到es官网下载最新版本的Elasticsearch</p><pre><code class="lang-bash">curl -L -O http://download.elasticsearch.org/PATH/TO/VERSION.zip &lt;1&gt;unzip elasticsearch-$VERSION.zipcd elasticsearch-$VERSION</code></pre></li><li><p>新版的ElasticSearch不推荐使用root用户运行，所以如果在docker内运行的话，需要创建新用户</p><pre><code class="lang-bash">sudo adduser elasticsearchsu elasticsearch</code></pre></li><li><p>切换到新用户之后启动ElasticSearch</p><pre><code class="lang-bash">./bin/elasticsearch</code></pre></li><li><p>测试成功启动</p><pre><code class="lang-bash">curl &#39;http://localhost:9200/?pretty&#39;</code></pre><p>若返回以下信息则表示Elasticsearch成功启动</p><pre><code class="lang-bash">{&quot;status&quot;: 200,&quot;name&quot;: &quot;Shrunken Bones&quot;,&quot;version&quot;: {&quot;number&quot;: &quot;1.4.0&quot;,&quot;lucene_version&quot;: &quot;4.10&quot;},&quot;tagline&quot;: &quot;You Know, for Search&quot;}</code></pre></li></ol><h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><p><strong>Elasticsearch</strong>是面向文档(document oriented)的，这意味着它可以存储整个对象或文档 (document)。然而它不仅仅是存储，还会索引(index)每个文档的内容使之可以被搜索。在 Elasticsearch中，你可以对文档（而非成行成列的数据） 进行索引、搜索、排序、过滤。这 种理解数据的方式与以往完全不同，这也是Elasticsearch能够执行复杂的全文搜索的原因之 一。    将Es中信息与传统关系数据库比较</p><pre><code class="lang-bash">Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; ColumnsElasticsearch -&gt; Indices -&gt; Types -&gt; Documents -&gt; Fields</code></pre><p>Elasticsearch集群可以包含多个索引(indices)（数据库） ，每一个索引可以包含多个类型 (types)（表） ，每一个类型包含多个文档(documents)（行） ，然后每个文档包含多个字段 (Fields)（列） 。    </p><p>在bash下使用curl命令创建索引并指定<strong>中文分词器ik_smart</strong></p><pre><code class="lang-bash">curl -H&#39;Content-Type: application/json&#39; -XPUT &#39;localhost:9200/es_test&#39; -d &#39;{  &quot;mappings&quot;: {    &quot;posts&quot;: {      &quot;properties&quot;: {        &quot;title&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;analyzer&quot;: &quot;ik_smart&quot;,          &quot;search_analyzer&quot;: &quot;ik_smart&quot;        },        &quot;desc&quot;: {          &quot;type&quot;: &quot;text&quot;,          &quot;analyzer&quot;: &quot;ik_smart&quot;,          &quot;search_analyzer&quot;: &quot;ik_smart&quot;        },        &quot;answers&quot;:{          &quot;type&quot;: &quot;text&quot;,          &quot;analyzer&quot;: &quot;ik_smart&quot;,          &quot;search_analyzer&quot;: &quot;ik_smart&quot;        }      }    }  }}&#39;</code></pre><p>这样就成功创建了一个索引<em>es_test</em>，而type为<em>post</em>s。</p><h3 id="python常规操作Elasticsearch"><a href="#python常规操作Elasticsearch" class="headerlink" title="python常规操作Elasticsearch"></a>python常规操作Elasticsearch</h3><h4 id="1-使用bulk批量导入数据"><a href="#1-使用bulk批量导入数据" class="headerlink" title="1. 使用bulk批量导入数据"></a>1. 使用bulk批量导入数据</h4><pre><code class="lang-python">from elasticsearch import Elasticsearchfrom elasticsearch.helpers import bulkes = Elasticsearch()actions = []# all_json是要导入的数据for lidx, sample in enumerate(all_json):    action = {        &quot;_index&quot;: &quot;es_test&quot;,        &quot;_type&quot;: &quot;posts&quot;,        &quot;_source&quot;:{        &quot;title&quot;: sample[&#39;title&#39;],        &quot;desc&quot;: sample[&#39;desc&#39;]        &quot;answers&quot;: sample[&#39;content&#39;]        }    }    actions.append(action)    if lidx % 500 == 0:   # 每500组导入一次        res, _ = bulk(es, actions, index=&quot;es_test&quot;, raise_on_error=True)        # print(res)        actions = []</code></pre><h4 id="2-查询所有内容是否导入"><a href="#2-查询所有内容是否导入" class="headerlink" title="2. 查询所有内容是否导入"></a>2. 查询所有内容是否导入</h4><pre><code class="lang-python">res = es.search(index=&quot;es_test&quot;, body={&quot;query&quot;: {&quot;match_all&quot;: {}}})print(&quot;Got %d Hits:&quot; % res[&#39;hits&#39;][&#39;total&#39;])####Got 7001 Hits:</code></pre><h4 id="3-写入数据和读取数据"><a href="#3-写入数据和读取数据" class="headerlink" title="3. 写入数据和读取数据"></a>3. 写入数据和读取数据</h4><p>向Elasticsearch写入一条数据，不指定id，即可随机得到id。当索引不存在时会根据doc字段自动创建索引</p><pre><code class="lang-python">from datetime import datetimefrom elasticsearch import Elasticsearches = Elasticsearch()doc = {    &#39;author&#39;: &#39;kimchy&#39;,    &#39;text&#39;: &#39;Elasticsearch: cool. bonsai cool.&#39;,    &#39;timestamp&#39;: datetime.now(),}# 当索引不存在时会根据doc字段res = es.index(index=&quot;test-index&quot;, doc_type=&#39;tweet&#39;, id=1, body=doc)print(res[&#39;result&#39;])### created</code></pre><p>读取刚才创建的数据，返回形式同样是json格式</p><pre><code class="lang-python">res = es.get(index=&quot;test-index&quot;, doc_type=&#39;tweet&#39;, id=1)print(res[&#39;_source&#39;])###{&#39;author&#39;: &#39;kimchy&#39;, &#39;text&#39;: &#39;Elasticsearch: cool. bonsai cool.&#39;, &#39;timestamp&#39;: &#39;2019-04-04T06:33:37.442271&#39;}</code></pre><p>此时查询这个indices将得到</p><pre><code class="lang-python"># 查询res = es.search(index=&quot;test-index&quot;, body={&quot;query&quot;: {&quot;match_all&quot;: {}}})print(&quot;Got %d Hits:&quot; % res[&#39;hits&#39;][&#39;total&#39;])### outputGot 1 Hits</code></pre><h4 id="4-查询"><a href="#4-查询" class="headerlink" title="4. 查询"></a>4. 查询</h4><p>使用上面的创建方法插入3条数据，供查询</p><pre><code class="lang-python">body1={    &quot;first_name&quot; : &quot;John&quot;,    &quot;last_name&quot; :  &quot;Smith&quot;,    &quot;age&quot; :        25,    &quot;about&quot; :      &quot;I love to go rock climbing&quot;,    &quot;interests&quot;: [ &quot;sports&quot;, &quot;music&quot; ]}#余下代码为写入三段数据body2={    &quot;first_name&quot; :  &quot;Jane&quot;,    &quot;last_name&quot; :   &quot;Smith&quot;,    &quot;age&quot; :         32,    &quot;about&quot; :       &quot;I like to collect rock albums&quot;,    &quot;interests&quot;:  [ &quot;music&quot; ]}body3={    &quot;first_name&quot; :  &quot;Douglas&quot;,    &quot;last_name&quot; :   &quot;Fir&quot;,    &quot;age&quot; :         35,    &quot;about&quot;:        &quot;I like to build cabinets&quot;,    &quot;interests&quot;:  [ &quot;forestry&quot; ]}res1 = es.index(&quot;test-index1&quot;, doc_type=&quot;employee&quot;, id=1, body=body1)re2 = es.index(&quot;test-index1&quot;, doc_type=&quot;employee&quot;, id=2, body=body2)re3 = es.index(&quot;test-index1&quot;, doc_type=&quot;employee&quot;, id=3, body=body3)</code></pre><h5 id="查询姓氏为Smith的字段"><a href="#查询姓氏为Smith的字段" class="headerlink" title="查询姓氏为Smith的字段"></a>查询姓氏为Smith的字段</h5><pre><code class="lang-python">bb1 = {    &quot;query&quot;: {        &quot;match&quot;: {&quot;last_name&quot;: &quot;Smith&quot;}    }}rt1 = es.search(index=&quot;test-index1&quot;, body=bb1)print(rt1)</code></pre><p>输出查询到的两个员工，由于他们姓氏满足Smith。所以分数相同</p><pre><code class="lang-json">{&#39;took&#39;: 48, &#39;timed_out&#39;: False, &#39;_shards&#39;: {&#39;total&#39;: 5, &#39;successful&#39;: 5, &#39;skipped&#39;: 0, &#39;failed&#39;: 0}, &#39;hits&#39;: {&#39;total&#39;: 2,  &#39;max_score&#39;: 0.2876821,  &#39;hits&#39;: [{&#39;_index&#39;: &#39;test-index1&#39;,    &#39;_type&#39;: &#39;employee&#39;,    &#39;_id&#39;: &#39;2&#39;,    &#39;_score&#39;: 0.2876821,    &#39;_source&#39;: {&#39;first_name&#39;: &#39;Jane&#39;,     &#39;last_name&#39;: &#39;Smith&#39;,     &#39;age&#39;: 32,     &#39;about&#39;: &#39;I like to collect rock albums&#39;,     &#39;interests&#39;: [&#39;music&#39;]}},   {&#39;_index&#39;: &#39;test-index1&#39;,    &#39;_type&#39;: &#39;employee&#39;,    &#39;_id&#39;: &#39;1&#39;,    &#39;_score&#39;: 0.2876821,    &#39;_source&#39;: {&#39;first_name&#39;: &#39;John&#39;,     &#39;last_name&#39;: &#39;Smith&#39;,     &#39;age&#39;: 25,     &#39;about&#39;: &#39;I love to go rock climbing&#39;,     &#39;interests&#39;: [&#39;sports&#39;, &#39;music&#39;]}}]}}</code></pre><h5 id="在查询姓氏的基础上同时给上年龄限制"><a href="#在查询姓氏的基础上同时给上年龄限制" class="headerlink" title="在查询姓氏的基础上同时给上年龄限制"></a>在查询姓氏的基础上同时给上年龄限制</h5><pre><code class="lang-python">bb2 = {    &quot;query&quot;: {        &quot;bool&quot;:{            &quot;must&quot;: {&quot;match&quot; :{&quot;last_name&quot;: &quot;Smith&quot;}},            &quot;filter&quot;:{&quot;range&quot;:{&quot;age&quot;: {&quot;gt&quot;: 30}}}        }    }}rt2 = es.search(index=&quot;test-index1&quot;, body=bb2)print(rt2)</code></pre><p>此时输出的只有满足年龄大于30的这个员工</p><pre><code class="lang-json">{&#39;took&#39;: 1019, &#39;timed_out&#39;: False, &#39;_shards&#39;: {&#39;total&#39;: 5, &#39;successful&#39;: 5, &#39;skipped&#39;: 0, &#39;failed&#39;: 0}, &#39;hits&#39;: {&#39;total&#39;: 1,  &#39;max_score&#39;: 0.2876821,  &#39;hits&#39;: [{&#39;_index&#39;: &#39;test-index1&#39;,    &#39;_type&#39;: &#39;employee&#39;,    &#39;_id&#39;: &#39;2&#39;,    &#39;_score&#39;: 0.2876821,    &#39;_source&#39;: {&#39;first_name&#39;: &#39;Jane&#39;,     &#39;last_name&#39;: &#39;Smith&#39;,     &#39;age&#39;: 32,     &#39;about&#39;: &#39;I like to collect rock albums&#39;,     &#39;interests&#39;: [&#39;music&#39;]}}]}}</code></pre><h5 id="全文搜索-—-传统数据库很难实现的功能"><a href="#全文搜索-—-传统数据库很难实现的功能" class="headerlink" title="全文搜索 — 传统数据库很难实现的功能"></a>全文搜索 — 传统数据库很难实现的功能</h5><pre><code class="lang-python">## 全文搜索all_search = {    &quot;query&quot;:{        &quot;match&quot;:{            &quot;about&quot;:&quot;rock climbing&quot;        }    }}rt3 = es.search(index=&quot;test-index1&quot;, body=all_search)print(rt3)</code></pre><p>此时将会得到两个匹配的字段，它们分别有一个对于搜索得到的评分</p><pre><code class="lang-json">{&#39;took&#39;: 15, &#39;timed_out&#39;: False, &#39;_shards&#39;: {&#39;total&#39;: 5, &#39;successful&#39;: 5, &#39;skipped&#39;: 0, &#39;failed&#39;: 0}, &#39;hits&#39;: {&#39;total&#39;: 2,  &#39;max_score&#39;: 0.5753642,  &#39;hits&#39;: [{&#39;_index&#39;: &#39;test-index1&#39;,    &#39;_type&#39;: &#39;employee&#39;,    &#39;_id&#39;: &#39;1&#39;,    &#39;_score&#39;: 0.5753642,    &#39;_source&#39;: {&#39;first_name&#39;: &#39;John&#39;,     &#39;last_name&#39;: &#39;Smith&#39;,     &#39;age&#39;: 25,     &#39;about&#39;: &#39;I love to go rock climbing&#39;,     &#39;interests&#39;: [&#39;sports&#39;, &#39;music&#39;]}},   {&#39;_index&#39;: &#39;test-index1&#39;,    &#39;_type&#39;: &#39;employee&#39;,    &#39;_id&#39;: &#39;2&#39;,    &#39;_score&#39;: 0.2876821,    &#39;_source&#39;: {&#39;first_name&#39;: &#39;Jane&#39;,     &#39;last_name&#39;: &#39;Smith&#39;,     &#39;age&#39;: 32,     &#39;about&#39;: &#39;I like to collect rock albums&#39;,     &#39;interests&#39;: [&#39;music&#39;]}}]}}</code></pre><h5 id="多字段查询"><a href="#多字段查询" class="headerlink" title="多字段查询"></a>多字段查询</h5><p>要对于多字段同时对于一个条目查询匹配程度，在此种方法下可以设置boost，则相应字段的查询匹配权重将会增加。</p><pre><code class="lang-python">query = &quot;头痛了怎么办&quot;all_search = {    &quot;query&quot;:{        &quot;match&quot;:{            &quot;title&quot;:query,            &quot;boost&quot;:2  # 标题权重设置为2，默认为1        },        &quot;match&quot;:{            &quot;desc&quot;:query        }    }}rt = es.search(index=&quot;qa_test&quot;, body=all_search)</code></pre><p>另外一种方法是<strong>布尔查询</strong>，采用的是<strong>“匹配越多越好(More-matches-is-better)”</strong>的方法，所以每个match子句的得分会 被加起来变成最后的每个文档的得分。匹配两个子句的文档的得分会比只匹配了一个文档的 得分高。    </p><pre><code class="lang-python">query = &quot;头痛了怎么办&quot;all_search = {    &quot;query&quot;: {        &quot;bool&quot;:{            &quot;should&quot;:[                {&quot;match&quot;: {&quot;title&quot;: query}},  # 同样可以使用boost:2来提升权重                {&quot;match&quot;: {&quot;desc&quot;: query}}            ]        }}}rt = es.search(index=&quot;qa_test&quot;, body=all_search)</code></pre><p>这两种方法都可以对于多字段查询，但它们查询出来得到的结果将会不同。其它查询方法还包括<strong>dis_max查询，多重匹配查询</strong>，具体使用可查看文档。</p><h3 id="常用的curl操作Elasticsearch"><a href="#常用的curl操作Elasticsearch" class="headerlink" title="常用的curl操作Elasticsearch"></a>常用的curl操作Elasticsearch</h3><h4 id="1-创建索引"><a href="#1-创建索引" class="headerlink" title="1.创建索引"></a>1.创建索引</h4><pre><code class="lang-bash">curl -XPUT &#39;localhost:9200/&lt;indice_name&gt;?pretty&#39;</code></pre><h4 id="2-查询所有的索引"><a href="#2-查询所有的索引" class="headerlink" title="2. 查询所有的索引"></a>2. 查询所有的索引</h4><pre><code class="lang-bash">curl &#39;localhost:9200/_cat/indices?v&#39;</code></pre><h4 id="3-删除指定索引"><a href="#3-删除指定索引" class="headerlink" title="3.删除指定索引"></a>3.删除指定索引</h4><pre><code class="lang-bash">curl -XDELETE http://localhost:9200/&lt;indice_name&gt;</code></pre><h4 id="4-向索引里插入一条数据"><a href="#4-向索引里插入一条数据" class="headerlink" title="4.向索引里插入一条数据"></a>4.向索引里插入一条数据</h4><pre><code class="lang-bash">curl -H&#39;Content-Type: application/json&#39; -XPUT &#39;localhost:9200/customer/external/1?pretty&#39; -d &#39;{&quot;name&quot;:&quot;John Doe&quot;}&#39;</code></pre><h4 id="5-根据编号获取一条数据"><a href="#5-根据编号获取一条数据" class="headerlink" title="5. 根据编号获取一条数据"></a>5. 根据编号获取一条数据</h4><pre><code class="lang-bash">curl -XGET &#39;localhost:9200/customer/external/1?pretty&#39;</code></pre><h3 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h3><h4 id="怎么解决“FORBIDDEN-12-index-read-only”"><a href="#怎么解决“FORBIDDEN-12-index-read-only”" class="headerlink" title="怎么解决“FORBIDDEN/12/index read-only”"></a>怎么解决“FORBIDDEN/12/index read-only”</h4><pre><code class="lang-bash">curl -XPUT -H &quot;Content-Type: application/json&quot; http://localhost:9200/_cluster/settings -d &#39;{ &quot;transient&quot;: { &quot;cluster.routing.allocation.disk.threshold_enabled&quot;: false } }&#39;curl -XPUT -H &quot;Content-Type: application/json&quot; http://localhost:9200/_all/_settings -d &#39;{&quot;index.blocks.read_only_allow_delete&quot;: null}&#39;</code></pre><h3 id="1-max-virtual-memory-areas-vm-max-map-count-65530-is-too-low-increase-to-at-least-262144"><a href="#1-max-virtual-memory-areas-vm-max-map-count-65530-is-too-low-increase-to-at-least-262144" class="headerlink" title="[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]"></a>[1]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</h3><pre><code class="lang-bash">sudo sysctl -w vm.max_map_count=262144</code></pre>]]></content>
      
      
        <tags>
            
            <tag> 检索 elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>维基中文百科获取</title>
      <link href="/2019/05/29/%E7%BB%B4%E5%9F%BA%E4%B8%AD%E6%96%87%E7%99%BE%E7%A7%91%E8%8E%B7%E5%8F%96/"/>
      <url>/2019/05/29/%E7%BB%B4%E5%9F%BA%E4%B8%AD%E6%96%87%E7%99%BE%E7%A7%91%E8%8E%B7%E5%8F%96/</url>
      <content type="html"><![CDATA[<h3 id="维基中文语料获取"><a href="#维基中文语料获取" class="headerlink" title="维基中文语料获取"></a>维基中文语料获取</h3><h4 id="下载中文的Wiki-Dump"><a href="#下载中文的Wiki-Dump" class="headerlink" title="下载中文的Wiki Dump"></a>下载中文的Wiki Dump</h4><pre><code class="lang-bash">wget http://download.wikipedia.com/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2</code></pre><h4 id="下载之后解压"><a href="#下载之后解压" class="headerlink" title="下载之后解压"></a>下载之后解压</h4><pre><code class="lang-bash">tar -zxvf zhwiki-latest-pages-articles.xml.bz2</code></pre><h3 id="使用Wikipedia-Extractor-抽取内容"><a href="#使用Wikipedia-Extractor-抽取内容" class="headerlink" title="使用Wikipedia Extractor 抽取内容"></a>使用Wikipedia Extractor 抽取内容</h3><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><pre><code class="lang-bash">git clone https://github.com/attardi/wikiextractor.git wikiextractorcd wikiextractorpython setup.py install</code></pre><h3 id="运行抽取"><a href="#运行抽取" class="headerlink" title="运行抽取"></a>运行抽取</h3><pre><code class="lang-bash">python WikiExtractor.py -b 1024M -o extracted zhwiki-latest-pages-articles.xml.bz2</code></pre><h3 id="过滤掉括号等不相关内容"><a href="#过滤掉括号等不相关内容" class="headerlink" title="过滤掉括号等不相关内容"></a>过滤掉括号等不相关内容</h3><h4 id="保存为strip文件"><a href="#保存为strip文件" class="headerlink" title="保存为strip文件"></a>保存为strip文件</h4><pre><code class="lang-python">import reimport sysimport codecsdef filte(input_file):    p1 = re.compile(&#39;（）&#39;)    p2 = re.compile(&#39;《》&#39;)    p3 = re.compile(&#39;「&#39;)    p4 = re.compile(&#39;」&#39;)    p5 = re.compile(&#39;&lt;doc (.*)&gt;&#39;)    p6 = re.compile(&#39;&lt;/doc&gt;&#39;)    outfile = codecs.open(&#39;std_&#39; + input_file, &#39;w&#39;, &#39;utf-8&#39;)    with codecs.open(input_file, &#39;r&#39;, &#39;utf-8&#39;) as myfile:        for line in myfile:            line = p1.sub(&#39;&#39;, line)            line = p2.sub(&#39;&#39;, line)            line = p3.sub(&#39;&#39;, line)            line = p4.sub(&#39;&#39;, line)            line = p5.sub(&#39;&#39;, line)            line = p6.sub(&#39;&#39;, line)            outfile.write(line)    outfile.close()if __name__ == &#39;__main__&#39;:    input_file = sys.argv[1]    filte(input_file)</code></pre><h4 id="对AA文件夹下三个文件分别运行"><a href="#对AA文件夹下三个文件分别运行" class="headerlink" title="对AA文件夹下三个文件分别运行"></a>对AA文件夹下三个文件分别运行</h4><pre><code class="lang-bash">python strip.py wiki_00\wiki_01\wiki_02</code></pre><h4 id="此时得到三个-std-wiki文件"><a href="#此时得到三个-std-wiki文件" class="headerlink" title="此时得到三个 std_wiki文件"></a>此时得到三个 std_wiki文件</h4><h3 id="繁转简"><a href="#繁转简" class="headerlink" title="繁转简"></a>繁转简</h3><h4 id="安装opencc"><a href="#安装opencc" class="headerlink" title="安装opencc"></a>安装opencc</h4><p>下载地址为 <a href="https://link.jianshu.com/?t=https://bintray.com/package/files/byvoid/opencc/OpenCC" target="_blank" rel="noopener">https://link.jianshu.com/?t=https://bintray.com/package/files/byvoid/opencc/OpenCC</a></p><h4 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h4><pre><code class="lang-bash">tar -xzvf opencc-1.0.4.tar.gz</code></pre><h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h4><pre><code class="lang-bash">安装cmake doxygensudo apt-get install doxygencd opencc-1.0.4/makesudo mask install测试安装完成opencc --h</code></pre><h4 id="转换"><a href="#转换" class="headerlink" title="转换"></a>转换</h4><p>对之前三个std开头文件分别执行</p><pre><code class="lang-bash">opencc -i std_wiki_00 -o zh_wiki_00 -c t2s.json</code></pre>]]></content>
      
      
        <tags>
            
            <tag> 数据集 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>fpn</title>
      <link href="/2018/07/14/fpn/"/>
      <url>/2018/07/14/fpn/</url>
      <content type="html"><![CDATA[<h2 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h2><blockquote><p>FPN是由facebook所提出，全称为Feature Pyramid Network—特征金字塔网络。FPN主要解决的是物体检测中的多尺度问题，通过简单的网络连接改变，在基本不改变原有模型计算量的情况下，大幅提高了小物体检测的性能。</p></blockquote><p>​       原来多数的目标检测算法都只是采用顶层特征做检测，但事实上低层的特征语义信息比较少，但是目标位置准确；高层的特征语义信息比较丰富，但是目标位置比较粗略。虽然有些算法采用多尺度特征融合的方式，但是一般是采用融合后的特征做检测，而FPN不一样的地方是在预测在不同特征层独立进行的。现在目标检测的方法有许多，常见的<em>Faster R-CNN</em>, <em>YOLO</em>, <em>SSD</em>,后两者在检测速度上大幅提高。但是检测效果一直是由Faster R-CNN主导，虽然速度较为慢，但精度很高，对大物体的检测效果已经非常显著。</p><p>​        但是在目标检测里面，在有限计算量的情况下，常用的网络结构对应的stride一般会比较大，图像中的小物体甚至会小于stride的大小，造成的结果就是小物体检测的性能。</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180714193425.png" alt=""></p><p>如上所示，传统解决这个问题的思路包括：</p><ol><li>多尺度训练和测试，又称图像金字塔，如图(a)所示，这种方法由于很高的时间和计算量开销，很难在实际中得到使用。</li><li><strong>特征分层。</strong>即每层分别预测对应的scale分辨率的检测结果，如图(c)所示。<strong>SSD</strong>框架采用了类似的思想，这样的方法在于强行让不同层去学习同样的语义信息。不同深度对应不同层次的语义特征，<strong>浅层网络分辨率高，学的更多是细节特征，深层网络分辨率低，学的更多的是语义特征。</strong></li></ol><p>所以目前的多尺度目标检测主要面对的挑战为：</p><ul><li>如何学习具有强语义信息的多尺度特征表示？</li><li>如何设计通用的特征表示来解决物体检测中的多个子问题？</li><li>如何高效计算多尺度的特征表示?</li></ul><p>如图(d)，网络直接在原来的单网络上做修改，每个分辨率的feature map引入后一分辨率缩放两倍的feature map做<strong>element-wise</strong>的操作。通过这样的连接，每一层预测所用的feature map都融合了不同分辨率、不同语义强度的特征，融合的不同分辨率的feature map分别做对应分辨率大小的物体检测。这样保证了每一层都有合适的分辨率以及强语义特征。同时，由于此方法只是在原网络基础上加上了额外的跨层连接，在实际应用中几乎不增加额外的时间和计算量。</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180714194713.png" alt=""></p><p>在Faster R-CNN中加入FPN，其分别是在<strong>RPN</strong>和<strong>Fast RCNN</strong>两步起作用。</p><p>主网络采用ResNet，算法结构大致为Figure 3，一个自底向上的线路，一个自顶向下的线路，横向连接。图中放大区域就是横向连接，$1\times1$大小的卷积核的作用是减少feature map的个数， 而并不改变其大小。自底向上为网络的前向传播过程，将feature map未改变大小的层归为一个<strong>stage</strong>， 每次抽取的特征都是每个stage的最后一层输出，这样能够构成金字塔。自顶向下的过程采用上采样完成，横向连接就是将上采用的结果和自底向上的生成的相同大小的feature map 相融合。</p><ul><li>在RPN中区别于原论文直接在最后的feature map上设置anchor，FPN在相应的feature map上设置，在每个scale都设置不同的anchor且设置类型变为$5\times3$种， FPN对比原来的RPN网络，召回率得到大幅度提升。</li><li>在Fast RCNN中， 首先需要固定FPN+RPN提取的proposal结果。在Fast RCNN中，FPN主要用于选择哪一层的feature map 来做ROI Pooling， FPN筛选ROI区域，同样对于检测小物体的精度有大幅提升。</li></ul><p>实验结果</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180715092613.png" alt=""></p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180715092757.png" alt=""></p><p>FPN算法同时利用低层特征高分辨率和高层特征的高语义信息，通过融合这些不同层的特征达到预测效果。并且预测是在每个融合后的特征层上单独进行的，这和常规的特征融合方式不同。</p><p><a href="https://blog.csdn.net/u014380165/article/details/72890275/" target="_blank" rel="noopener">参考</a></p>]]></content>
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>faster-rcnn</title>
      <link href="/2018/06/26/faster-rcnn/"/>
      <url>/2018/06/26/faster-rcnn/</url>
      <content type="html"><![CDATA[<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><blockquote><p>在目标检测领域，在第一次出现了<strong>R-CNN</strong>之后，开始广泛使用了神经网络的方法，在R-CNN基础上出现了<strong>Fast R-CNN</strong>，其变得比R-CNN更快，但不能改变的是在产生候选区域的过程中，它们两者都采用的叫一种<em>Selective search</em>的方法，这种方法非常慢。而Faster R-CNN的出现，其利用卷积神经网络去提取候选区域，大大加快了训练速度，同样也提高了准确率，Faster-RCNN是在目标检测领域非常重要的一个方法。</p></blockquote><h3 id="R-CNN-和-Fast-R-CNN"><a href="#R-CNN-和-Fast-R-CNN" class="headerlink" title="R-CNN 和 Fast R-CNN"></a>R-CNN 和 Fast R-CNN</h3><p><strong>R-CNN步骤</strong>：</p><ol><li><p>训练或者下载一个分类模型（基于ImageNet），对该模型做<em>fine-tuning</em>，将分类数从1000改为20，并去掉最后一个全连接层。</p></li><li><p>利用<strong>选择性搜索</strong>(selective search)，从图像中选取大约2000个候选框</p></li><li><p>对于所选择的每一个区域，修正区域的大小以适合CNN的输入，将每个候选区域传入网络中提取特征</p></li><li><p>特征送入每一类的<strong>SVM分类器</strong>，判断是否属于此类。并使用回归器精修候选框的位置。</p></li></ol><p>   <img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630160655.png" alt=""></p><p>由于R-CNN使用<em>selective search</em>方法选择出候选框之后，需将每个候选框传入神经网络中提取特征进行判断，所以这个过程非常慢，Fast R-CNN在此基础上提升了区域框的选取过程，不是先选取框再传入CNN之中一个一个训练，而是直接将整张图片传入CNN之中提取特征。由于选择出的RoIs的大小都各不相同，所以在Fast R-CNN之中引入了RoI pooling，可将不同区域大小的候选区pooling为相同尺寸的特征区域。</p><p><strong>Fast R-CNN步骤</strong>:</p><ol><li>任意大小的图片传入ImageNet预训练网络(VGG)之中，得到feature map</li><li>在此图像中通过selective search选取2000个左右的候选框</li><li>通过特征图和原图的映射关系，将在原图中提取到的候选框，映射到feature map中</li><li>通过RoI Pooling 将特征图上的2000个候选框池化为固定大小(VGG中为7x7大小)，经过一个全连接层得到固定的特征向量。</li><li>所得到的特征向量再经过两个全连接层分别得到两个输出向量：一个是softmax的<strong>分类</strong>得分，一个是Bounding-box的窗口<strong>回归</strong>。</li><li>利用窗口得到的score分别对每一类物体进行非极大值抑制(nms)，剔除重叠的建议框，最终得到每个类别回归修正得分最高的窗口。</li></ol><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630162003.png" alt=""></p><h3 id="Faster-R-CNN-1"><a href="#Faster-R-CNN-1" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><p><a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">论文</a></p><p>整体流程：</p><p><img src="https://pic2.zhimg.com/80/v2-4e372e4536ef6d3d28ebd8803a9b13e2_hd.jpg" alt=""></p><p>大致分为三个区域：</p><ol><li><strong>Extractor</strong>，为常用的预训练模型，通过输入图像，以此来提取特征。</li><li><strong>RPN</strong>，Faster-RCNN中新提出的区域生成方法，摈除了之前采用的<em>Selective search</em>，而采用了卷积神经网络去生成RoIs，这样大大提高了网络的速度。</li><li><strong>ROIHead</strong>，通过传入RPN中生成的区域，对每个区域进行分类和坐标回归，此处和之前的Fast R-CNN类似。</li></ol><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><p>数据采用常用的目标检测数据库VOC或COCO，需做以下处理：</p><ul><li>对每个图片,reshape为边长小于或等于1000和600，其中（至少一个等于）</li><li>对相应的<em>ground truth</em>也做同样尺度的缩放</li></ul><p>最后训练过程中所需要的四个值分别为：</p><ul><li><em>images</em>: $3<em>H</em>W$大小</li><li><em>bboxes</em>: $4*K$, 其中$K$为bboxes数量，坐标形如(Y_min, X_min, Y_max, X_max)</li><li><em>labels</em>: $(K, )$, 对应K个bboxes的labels，在VOC中为(0~19)</li><li><em>scale</em>: 图像缩放的倍数，原图$H^{‘} <em> W^{‘}$reshape到$H </em> W$,则$scale=H^{‘} / H$</li></ul><h4 id="Extractor"><a href="#Extractor" class="headerlink" title="Extractor"></a>Extractor</h4><p><img src="https://pic2.zhimg.com/80/v2-28887eb4f69439e1384165da0ca20b6f_hd.jpg" alt="img"> </p><p>这里使用VGG16,当然也可以使用ResNet101，在VGG的前四层，由于训练时为了节约显存，所以将其学习率设置为0，在<strong>Extractor</strong>部分，只用到了conv5_3之前，及图像reshape到大小为$1000<em>600$之后，传入到VGG16中，在conv5_3处输出图像的feature map，到此图像下采样了16倍，得到了$C</em>(H/16)<em>(W/16)$特征图，在此具体为$512</em>62*38$。在conv5_3之后还有两个全连接层，在extractor中并未使用，但在之后的ROIHead中用到了。</p><h4 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h4><p><strong>Anchor</strong></p><p>作者首先一改之前，提出了Anchor，即尺寸大小固定的候选框，在论文中使用了三种尺寸(1:1,1:2,2:1)，三种大小(128,256,512)，得到了9个不同的anchor</p><p><img src="https://pic1.zhimg.com/80/v2-7abead97efcc46a3ee5b030a2151643f_hd.jpg" alt=""></p><p>这9个anchor在刚生成的feature map中左右上下移动，对于每个点都得到了9个anchor，这样就得到了共$62<em>38</em>9$~20000个anchor.当然这20000个anchor并不会全部传给ROIHead训练，只会从中选取2000个传给之后。</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630165723.png" alt=""></p><p>在RPN中就需要对候选框进行分类，但此处不是20分类，而是二分类，即判断是否含有物体。在特征图的基础上，在一个3x3卷积之后，分别使用$9<em>2$和$9</em>4$个1x1的卷积核进行卷积操作，这样原本特征图为512x62x38，则分别卷积到62x38x9*2，和62x38x9x4，这样得到大约20000个框的score和坐标。</p><h4 id="RPN生成RoIs"><a href="#RPN生成RoIs" class="headerlink" title="RPN生成RoIs"></a>RPN生成RoIs</h4><p>RPN的主要作用就是为之后的ROIHead生成大约RoIs，在代码中为(Proposal Creator)</p><ul><li>对于每张图片的大约20000个候选框，首先先选取score较大的12000个anchor</li><li>利用回归的位置参数，修正这12000个anchor,得到RoIs</li><li>利用非极大值抑制(NMS)，选出概率最大的2000个RoIs。</li></ul><p>注意：在Test时，12000和2000分别变为6000和300</p><h4 id="RPN训练"><a href="#RPN训练" class="headerlink" title="RPN训练"></a>RPN训练</h4><p>RPN自身也要训练，以此选取更好的RoIs，此处RPN从20000个选出大约256个供自身训练，其中正负样本各占一半，选择过程如下,代码中为<code>Anchor Target creator</code>：</p><ul><li>对于每个ground truth bbox，选择和它IOU最高的一个anchor作为正样本</li><li>对于每个anchor，若有ground truth和它的IOU大于0.7，则选取它作为正样本，正样本的数目不超过128，若不够，则由负样本凑</li><li>随机选取和任意ground truth的IOU都小于0.3的anchor作为负样本，数目为128</li></ul><p>对于分类只有二分类，即要么为1（前景），0（背景），回归坐标则需要改变一下</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630171202.png" alt=""></p><p>其中分类采用交叉熵损失，而计算回归则采用的是<code>Smooth L1</code>损失，同样在计算<strong>回归</strong>损失时，只计算正样本的损失，而不计算负样本的损失。</p><h3 id="ROIHead"><a href="#ROIHead" class="headerlink" title="ROIHead"></a>ROIHead</h3><p><img src="https://pic1.zhimg.com/80/v2-5b0d1ca6e990fcdecd41280b69cd8622_hd.jpg" alt=""></p><p>RPN会产生大约2000个ROIs，但并不是全部都要在ROIHead中训练，而是通过<code>ProposalTargetCreator</code>选取128个RoIs进行训练。选择的规则如下：</p><ul><li>RoIs和gt_bboxes的IoU大于0.5的选择32个作为正样本</li><li>IoU小于等于0或0.1(自己设置)选择96个作为负样本</li></ul><p>但由于这些候选框的大小都不相同，所以采用RoIPooling将这些候选框pooling成相同的大小(7x7,在VGG中)。选取的框需要映射到feature map 中，所以RoIpooling将区域都统一下采样到$512\times7\times7$，由于选取了128个，所以就得到了$128\times512\times7\times7$大小的特征向量，之前VGG的全连接层在这里还需要用到，将特征向量reshape为一维的之后，传入全连接层，再分别传入<strong>FC21</strong>和<strong>FC84</strong>得到分类结果和坐标结果，损失函数和之前RPN中采用的相同。</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630173140.png" alt=""></p><p>完整结构如上所示。</p><p><a href="https://zhuanlan.zhihu.com/p/32404424" target="_blank" rel="noopener">参考</a></p>]]></content>
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>K-近邻算法</title>
      <link href="/2018/06/05/knn/"/>
      <url>/2018/06/05/knn/</url>
      <content type="html"><![CDATA[<h2 id="K-近邻算法-KNN"><a href="#K-近邻算法-KNN" class="headerlink" title="K-近邻算法(KNN)"></a>K-近邻算法(KNN)</h2><blockquote><p>k-近邻算法采用测量不同特征值之间的距离方法进行分类</p></blockquote><ul><li>监督学习方法，适用于分类</li><li>优点：精度高，对异常值不敏感，无数据输入假定。</li><li>缺点：计算复杂度高，空间复杂度高。</li><li>适用数据范围：数值型，标称型。</li></ul><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>如果存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在<strong>标签</strong>，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据<strong>（最近邻）</strong>的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是<strong>不大于20</strong>的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。</p><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><p>对未知类别属性的数据集中的每个点依次执行以下操作：</p><ol><li>计算已知类别数据集中的点与当前点之间的距离；</li><li>按照距离递增次序排序；</li><li>选取与当前点距离最小的k个点；</li><li>确定前k个点所在类别的出现频率；</li><li>返回前k个点出现频率最高的类别作为当前点的预测分类</li></ol><p>其中计算距离通常采用<strong>欧式距离公式</strong>：</p><script type="math/tex; mode=display">d=\sqrt{(xA_{0}-xB_{0})^{2}+(xA_{1}-xB_{1})^{2}}</script><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><pre><code class="lang-python">import numpy as npimport operatordef CreateDataSet():    &quot;&quot;&quot;    Create some fake data    &quot;&quot;&quot;    group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])    labels = [&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;]    return group, labelsdef classify0(inX, dataSet, labels, k):    &quot;&quot;&quot;    KNN algorithm:    1. calculate the distance between every data from        sample with the target data.    2. sort these distances by ascending    3. get the top k data with smallest distance    4. confirm the frequnces of topk&#39;s class    5. return the highest frequncy of class      &quot;&quot;&quot;    dataSetSize = dataSet.shape[0]  # the amount of data    # calculate the distance between two points    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet    sqDiffMat = diffMat ** 2    sqDistances = sqDiffMat.sum(axis=1)    distances = sqDistances ** 0.5    sortedDistIndices = distances.argsort()    # choose the topk    classCount = {}    for i in range(k):        voteIlabel = labels[sortedDistIndices[i]]        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1    sortedClassCount = sorted(classCount.items(),        key=operator.itemgetter(1), reverse=True)    return sortedClassCount[0][0]if __name__ == &#39;__main__&#39;:    group, labels = CreateDataSet()    output = classify0([0, 0], group, labels, 3)    print(output)</code></pre><p><a href="https://github.com/HandsomeCao/Machine-Learning-learn/tree/master/KNN" target="_blank" rel="noopener">代码</a></p>]]></content>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mAP</title>
      <link href="/2018/05/27/mAP/"/>
      <url>/2018/05/27/mAP/</url>
      <content type="html"><![CDATA[<h2 id="mAP-目标检测模型中的性能评估"><a href="#mAP-目标检测模型中的性能评估" class="headerlink" title="mAP - 目标检测模型中的性能评估"></a>mAP - 目标检测模型中的性能评估</h2><blockquote><p><strong>目标检测</strong>问题是指：给定一个图像，找到其中的目标，找到它们的位置，并且对目标进行分类。目标检测模型通常是在一组固定的类上进行训练的，所以模型只能定位和分类图像中的那些类。此外，目标的位置通常是边界矩阵的形式。所以，目标检测需要涉及图像中目标的位置信息和对目标进行分类。 均值平均精度(<em>Mean Average Precision</em>)对于评估模型定位性能、目标检测性能和分割模型性能都是很有用的。</p></blockquote><h3 id="精确率和召回率"><a href="#精确率和召回率" class="headerlink" title="精确率和召回率"></a>精确率和召回率</h3><p>要理解精确率(<em>presicion</em>)和召回率(<em>recall</em>)首先要理解以下概念：</p><ul><li>TP ——- 将正类预测为正类数</li><li>FN ——- 将正类预测为负类数</li><li>FP ——— 将负类预测为正类数</li><li>TN ——- 将负类预测为负类数</li></ul><p>举个例子:</p><blockquote><p>假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本，系统查找出50个，其中只有40个是真正的正样本，计算上述各指标 ：</p></blockquote><ul><li><strong>TP = 40</strong>    (检测出的40个为正)</li><li><strong>FN = 20</strong>   (有60个正，只检测出40个为正，所以60-40=20)</li><li><strong>FP = 10</strong>   (找出了50个，但只有40为正，50-40=10)</li><li><strong>TN = 30</strong>  (找出中的50个，只有40个为正，也即其中10个为负，所以40-10=30)</li></ul><p>而<strong>精确率</strong>是针对<strong>预测结果</strong>而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类<strong>(TP)</strong>，另一种就是把负类预测为正类(<strong>FP</strong>)，也就是 </p><script type="math/tex; mode=display">P = \frac{TP}{TP+FP}</script><p>而<strong>召回率</strong>是针对我们原来的<strong>样本</strong>而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类<strong>(TP)</strong>，另一种就是把原来的正类预测为负类(<strong>FN)</strong>:</p><script type="math/tex; mode=display">R = \frac{TP}{TP+FN}</script><blockquote><p>简单来说，<strong>精确率</strong>是指对于<strong>检测出的</strong>样本中，为正的样本所占比例。而<strong>召回率</strong>是指<strong>本来的为正的样本</strong>中，检测出的正样本所占的比例。</p></blockquote><p>所以：</p><p><strong>精确率</strong>(<em>precision</em>) = $ TP/(TP+FP) = 4/5$</p><p><strong>召回率</strong>(recall) = $ TP/(TP+FN) = 2/3 $ </p><p>额外：</p><p><strong>准确率</strong>(<em>accuracy</em>) = 预测对的/所有 = $(TP+TN)/(TP+FN+FP+TN) = \frac{7}{10} $</p><p><img src="http://s9.sinaimg.cn/mw690/002T2ChPgy6XQdjij4Ae8" alt=""></p><h3 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h3><blockquote><p> <strong>loU(交并比)</strong>是模型所预测的检测框和真实(<em>ground truth</em>)的检测框的<strong>交集和并集之间的比例</strong>。这个数据也被称为<em>Jaccard</em>指数。 </p></blockquote><p><img src="https://img-blog.csdn.net/20161121150037641" alt=""></p><p>对于图像中的GroundTruth框$A$，其检测出的矩形框为$B$，则其IoU(Intersection over Union)可以计算如下:</p><script type="math/tex; mode=display">IoU=\frac{A\cap B}{A \cup B}</script><h3 id="AP"><a href="#AP" class="headerlink" title="AP"></a>AP</h3><ul><li>对于PASCAL_VOC2007， 首先设定一组阈值，$[0, 0.1, 0.2, …, 1]$。然后对于$recall$大于每一个阈值（比如$recall&gt;0.3$），我们都会得到一个对应的最大$precision$。这样，我们就计算出了$11$个$precision$。通过对这11个散点做出PR图，<strong>AP</strong>即为这11个$precision$对于每个$recall$值所做的曲线下的<strong>面积</strong>。这种方法英文叫做$11-point interpolated average precision$。</li><li>当然<strong>PASCAL VOC CHALLENGE</strong>自2010年后就换了另一种计算方法。新的计算方法假设这$N$个样本中有$M$个正例，那么我们会得到M个$recall$值$（1/M, 2/M, …, M/M）$,对于每个$recall$值$r$，我们可以计算出对应$（r’ &gt; r）$的<strong>最大</strong>$precision$，然后对这$M$个$precision$值同样做出PR曲线，求此曲线下的面积。</li></ul><p>实际多类别分类任务中，我们通常不满足只通过top-5(<strong>top-#是指通过score排序得到的预测序列</strong>)来衡量一个模型的好坏，而是需要知道从top-1到top-N（N是所有测试样本个数）对应的precision和recall。显然随着我们选定的样本越来也多，recall一定会越来越高，而precision整体上会呈下降趋势。把recall当成横坐标，precision当成纵坐标，即可得到常用的precision-recall曲线。这个例子的precision-recall曲线如下： </p><p><img src="http://s10.sinaimg.cn/mw690/002T2ChPgy6XQddBz7ze9" alt=""></p><h3 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h3><ul><li>求出每个类别的AP，之后只需要对每个类别的AP相加求平均值，即得到mAP。</li></ul><p>具体可参考这篇<a href="http://blog.sina.com.cn/s/blog_9db078090102whzw.html" target="_blank" rel="noopener">博文</a></p>]]></content>
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker使用</title>
      <link href="/2018/05/13/docker/"/>
      <url>/2018/05/13/docker/</url>
      <content type="html"><![CDATA[<h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p><a href="www.docker.com">Docker</a>是一个<strong>开源</strong>的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。按理说，Docker并不是专门用于深度学习的工具，它运用非常广泛，对于任何编程的项目，Docker都能提供很好的帮助。</p><p>在实验室中需要使用Docker的原因主要是为了</p><blockquote><p>防止在服务器中相互影响和破坏底层环境，从而使用Docker为每个人生成一个虚拟的单独的环境</p></blockquote><p>这是相当有用的，对于每个生产环境，都可以生产一个单独的<strong>容器</strong>, 同时与其他生产环境相隔离。这和虚拟机似乎有点类似，但相比较于虚拟机，Docker所生成的容器具有<strong>更快速，更轻量</strong> 的效果。在Docker中有两个很重要的概念</p><ul><li><strong>容器</strong>(container)，其对应于面向对象方法中的<strong>对象</strong></li><li><strong>镜像</strong>(image)， 其对应于面向对象方法中的<strong>类</strong></li></ul><p>所以使用Docker的过程通常为：</p><ol><li>自己或者找到一个别人配好的适合自己生产环境的镜像。通常自己配镜像是通过<strong>DockerFile</strong>文件</li></ol><pre><code class="lang-bash">列出本机的所有 image 文件。$ docker images删除 image 文件$ docker image rm [imageName]</code></pre><p>image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别人的 image 文件进行加工，而不是从零开始制作。</p><pre><code class="lang-bash"># pull 命令从官网抓取hello-world镜像$ docker image pull library/hello-world</code></pre><ol><li>利用得到的image文件，生成容器实例</li></ol><pre><code class="lang-bash">$ docker container run hello-world</code></pre><p>在docker中最常用的就是<code>docker run</code>命令，也是最重要的。这里就用实验室所用的<code>docker run</code>命令展现其每个参数的意义</p><pre><code class="lang-bash">$ docker run -p 7981:8888 -it --name=[容器名称] -v /home/cao/workspace:/root/workspace --device /dev/nvidia-uvm --device /dev/nvidia0 --device /dev/nvidia1 [镜像名称] /bin/bash</code></pre><ul><li><strong>-p</strong> : 端口映射，即容器的8888端口映射到本机的7981端口</li><li><strong>-it</strong>  : 表示进入容器之后，进入命令行交互模式</li><li><strong>—name</strong> : 指定生成容器的名称，<em>一定要指定</em>。</li><li><strong>-v</strong>  : 路径映射，即容器的<em>/root/workspace</em>， 与本机的<em>/home/cao/workspace</em> 相互挂载，所以不能轻易删除</li><li><strong>—device</strong> : 映射本机的指定显卡</li></ul><p>这样在生成一个容器之后，通常就只需要对此容器进行操作，而生产环境全由<code>docker attach [容器名称]</code>进入容器之中操作。使用<code>docker -h</code>可查看全部帮助。</p>]]></content>
      
      
        <tags>
            
            <tag> docker 工具 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>卷积神经网络</title>
      <link href="/2018/05/13/cnn-basic/"/>
      <url>/2018/05/13/cnn-basic/</url>
      <content type="html"><![CDATA[<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><blockquote><p> <strong>卷积层</strong>是卷积神经网络(<em>Convolutional Neural Network</em>)中的基本操作。其使用一个<strong>卷积核</strong>通过对输入层进行卷积操作，从而可以提取到图像中的高层信息。</p></blockquote><p>假设输入图像是下图中的一个$6*6$的矩阵,其中每个格代表了图像点的像素值。</p><p><img src="https://i.imgur.com/In87wix.png" alt=""></p><p>设置其卷积核（<em>kernel</em>）为$3*3$的矩阵，卷积核中的参数不同，可导致其卷积得到的结果不同:</p><p><img src="https://i.imgur.com/Dn0HGFv.png" alt=""></p><p>同时，假定卷积操作每做一次卷积，卷积核移动一个像素位置，即卷积的<strong>步长</strong>(<em>stride</em>)为1。第一次卷积操作从图像$(0,0)$像素开始，由卷积核中的参数与对应位置图像像素<strong>逐位相乘后累加</strong>作为一次卷积结果。</p><p><img src="https://i.imgur.com/OyxUEt2.png" alt=""></p><p>对于<strong>卷积核1</strong>(<em>filter1</em>)，其对于$(0,0)​$位置进行卷积操作:</p><script type="math/tex; mode=display">Conv_{out}=\sum{a_{i}b_{i}=}1*1+0*(-1)+0*(-1)+0*(-1)+1*1+0*(-1)+0*(-1)+1*1=3</script><p>当步长为$1$时，卷积核按照补偿大小在输入图像<strong>从左到右从上到下</strong>依次将卷积操作进行下去，最终输出一个$4<em>4$大小的<em>*卷积特征</em></em>，同时这卷积特征将作为下一层操作的输入。</p><p><img src="https://i.imgur.com/NdLlBtZ.png" alt=""></p><p>与之类似，若三维情形下的卷积层$l$的输入张量为$x^{l}\in R^{H^{l}\times W^{l} \times D^{l}}$,该层的卷积核为$f^{l}\in R^{H^{l}\times W^{l} \times D^{l}}$。三维输入时，卷积操作实际上只是将二维卷积扩展到了相应位置的所有通道上，最终将一次卷积处理的所有$HWD^{l}$个元素求和作为该位置的卷积结果。</p><p>若进一步，类似$f^{l}$这样的卷积核有$D$个，则在同一个位置可得到$1 \times 1 \times 1 \times D$维度的卷积输出，而$D$即为第$l+1$层特征$x^{l+1}$的通道数$D^{l+1}$。对于三维图像，形式化的卷积操作为:</p><script type="math/tex; mode=display">y_{i^{l+1},j^{l+1},d}=\sum_{i=0}^{H}\sum_{j=0}^{W}\sum_{d^{l}=0}^{D^{l}}f_{i,j,d^{l},d} \times x_{i^{l+1}+i, j^{l+1}+j,d^{l}}^{l}</script><p>其中$(i^{l+1},j^{l+1})$为卷积结果的位置坐标，在卷积层中，$f$可视作学习到的网络中的权重(<em>weight</em>)，可以发现该项权重对不同位置的所有输入都是相同的，也就是一个卷积核时作用于不同的区域的，这也就是卷积神经网络中的<strong>权值共享</strong>特性，当然除此之外，也可以为卷积操作设定其神经元中的<strong>偏置项</strong>，当然也可将其设置为0。</p><p><strong>零填充</strong>：</p><hr><p>可见，对于上面介绍的卷积操作，对于一张输入图像，进行不断的卷积操作，得到的输出特征尺寸将在不断<strong>减小</strong>，有时这样是不可取的，因为最终的输出逐渐减小后，所学到的图像特征也所剩无几了。所以这里有个保证图像输出不再减小的方法，称为<strong>零填充<em>(Zero padding)</em></strong>。</p><p><img src="https://i.imgur.com/7ccpHke.png" alt=""></p><p>如上图所示，即是在卷积操作中设置$padding=1$，也就是在边缘像素周围再以1个0填充。对于本来的输入为$6 \times6$大小的图像，以卷积核为$3 \times 3$，步长为$1$进行卷积，会得到$4 \times 4$大小的输出图像。但当<strong>加上零填充</strong>之后，输入图像也就可看作是$8 \times 8$大小，进行同样的卷积操作，输出却得到了$6 \times 6$大小的图像，和输入保持不变，这样也就能<strong>增加网络中的卷积操作，学到更为高层的特征</strong>。</p><p>所以在卷积操作中有三个重要的<strong>超参数</strong>(<em>Hyper parameters</em>)：</p><ul><li><strong>卷积核大小(<em>filter size</em>)</strong>: $(f \times f)$</li><li><strong>卷积步长(<em>filter stride</em>)</strong>：$s$</li><li><strong>零填充(<em>padding</em>)</strong>: $p$</li></ul><p>对于输入图像大小为$n \times n$，对于<strong>输出尺寸</strong>可以得到如下的一般公式:</p><script type="math/tex; mode=display">\lfloor\frac{n+2p-f}{s}+1\rfloor \times \lfloor\frac{n+2p-f}{s}+1\rfloor</script><p>当然，合适的超参数设置会对模型带来意想不到的效果提升。在<strong>pytorch</strong>中，对于二维图像的卷积操作，使用<code>nn.Conv2d</code>表示。</p><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><blockquote><p>在卷积神经网络中，池化层往往在卷积层的后面，通过池化来<strong>降低</strong>卷积层输出的特征向量，同时改善结果，防止过拟合。</p></blockquote><p>池化通常用的两种方法为：<strong>最大值池化</strong>(Max-Pooling)和<strong>平均值池化</strong>(Average-Pooling)。</p><ul><li><strong>最大值池化</strong>：</li></ul><script type="math/tex; mode=display">y_{i^{l+1},j^{l+1},d}=max(x_{i^{l+1} \times H+I, j^{l+1} \times W+j,d^{l}}^{l})</script><ul><li><strong>平均值池化</strong>:</li></ul><script type="math/tex; mode=display">y_{i^{l+1},j^{l+1},d}=\frac{1}{HW}\sum x_{i^{l+1} \times H+I, j^{l+1} \times W+j,d^{l}}^{l}</script><p>对于卷积后得到的图像特征，<em>Max-Pooling</em>可形象表示为:</p><p><img src="https://i.imgur.com/yyCG6On.png" alt=""></p><p>这里池化的核大小选择为$(2 \times 2)$，也就是对于第一个块中，选择最大值7得到输出值。当然，如果是平均值池化，也就是取四个数的平均值作为其池化后的值。</p><p>可以发现，池化操作后的结果相比其输入减小了，其实际上是一种<strong>降采样(<em>down-sampling</em>)</strong>，池化层的引入是按照人的视觉系统对视觉输入对象进行降采样和抽象，其主要作用主要有以下三项：</p><ol><li><strong>特征不变性</strong>：池化操作使模型更关注是否存在某些特征而不是特征具体的位置。可看作是一种很强的先验，使特征学习包含某种程度自由度，能容忍一些特征微小的位移。</li><li><strong>特征降维</strong>：由于池化操作的降采样作用，汇合结果中的一个元素对应于原输入数据的一个子区域，因此池化相当于在空间范围内做了维度约减，从而使模型可以抽取更广范围的特征。同时减小了下一层输入大小，进而减小计算量和参数个数。</li><li>在一定程度上<strong>防止过拟合</strong>，方便优化。</li></ol><h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p><img src="https://i.imgur.com/vh9DPQ7.png" alt=""></p><blockquote><p> LeNet-5可以说是最早的卷积神经网络结构了，它主要用于手写数字识别的任务上，其发表于1998年的<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="noopener">论文</a></p></blockquote><p><strong>结构</strong>：LeNet-5不包括输入层一共有7个层，每一层都包含了可以训练的参数，输入为一张$32 \times 32$的图像。</p><ol><li><strong>C1卷积层</strong></li></ol><p>这一层的输入就是原始的图像，输入层接受图片的输入大小为$32 \times32 \times1$。卷积层的核（过滤器）尺寸为$5\times5$，深度为$6$，不使用$0$进行填充，步长为$1$。通过计算公式可以求出输出的尺寸为$28\times28\times6$，卷积层的深度决定了输出尺寸的深度。卷积层总共的参数有$5<em>5</em>1<em>6+6 =156$个参数，加的$6$为卷积后的偏置项参数。本层所拥有的节点有$28</em>28<em>6=4704$个节点， 而本层的每一个节点都是经过一个$5\times5$的卷积和一个偏置项计算所得到的，$5</em>5+1=26$，所以本层卷积层一共有$4704*26 = 122304$个连接。</p><ol><li><strong>S2池化层</strong></li></ol><p>本层的输入是C1的输出，它接收一个$28\times28\times6$大小的矩阵。在卷积神经网络中，常有的池化方法为最大池化和平均池化，由于使用的核为$2\times2$，步长也为$2$，意味着每四个相邻元素经过S2之后会得到一个输出，所以输出矩阵大小变为$14\times14\times6$大小。</p><ol><li><strong>C3卷积层</strong></li></ol><p>本层卷积操作，采用的卷积核仍为$5\times5$，使用$16$个卷积核，也就是深度为$16$，同样不使用零填充，步长为$1$，所以得到输出大小为$10\times10\times16$。</p><ol><li><strong>S4池化层</strong></li></ol><p>本层采用同S2相同的池化操作，使输出值再缩小一半量级，变为$5\times5\times16$。</p><ol><li><strong>C5卷积层</strong></li></ol><p>C5层由$120$个卷积核组成，一个卷积与<strong>S4</strong>中每一个<em>feature map</em>（$5<em>5</em>16$）相连，所以每一个C5的卷积核都会输出一个$1<em>1$的矩阵，所以在S4与C5之间是可看作属于全连接。C5是一个卷积层而不是一个全连接层，如果这个LeNet5的输入变的更大了而其它的保持不变，那么这个输出将要大于$1</em>1$。</p><ol><li><strong>F6全连接层</strong></li></ol><p>F6层包含了$84$个结点，计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过<strong>sigmoid</strong>函数，来产生一个输出，也就是之前的输入为$120$个神经元，现在通过一层全连接，其中含$84$个神经元，来将输出降维。 </p><ol><li><strong>输出层</strong></li></ol><p>输出层是由<strong>欧式径向基函数（RBF）</strong>组成。每一个输出对应一个RBF函数，每一个RBF函数都有$84$维的输入向量.。每一个RBF函数都会有一个输出，最后输出层会输出一个10维的向量。，以映射到10个数字分别的预测的准确度。</p><p><strong>MNIST数据集</strong></p><p>MNIST数据集是入门的第一个数据集，其数据都为$28\times28$大小的<strong>单通道</strong>图像，它含有$60000$张训练图片，和$10000$张验证图片。其形式非常简单，图像如下图</p><p><img src="http://wiki.jikexueyuan.com/project/tensorflow-zh/images/mnist_digits.png" alt=""></p><p>用<strong>LeNet-5</strong>对MNIST数据集进行训练，可以取得<strong>92%</strong>左右的效果，已比传统机器学习方法实现的效果更好。</p><p><img src="http://yann.lecun.com/exdb/lenet/gifs/a35.gif" alt=""></p><p>通过pytorch实现的LeNet结构</p><pre><code class="lang-python">class LeNet(nn.Module):    def __init__(self):        super(LeNet, self).__init__()        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)        self.conv2 = nn.Conv2d(6, 16, 5)        # self.conv3 = nn.Conv2d(16, 120, 5)        self.fc1 = nn.Linear(16*5*5, 120)        self.fc2 = nn.Linear(120, 84)        self.fc3 = nn.Linear(84, 10)    def forward(self, x):        out = F.relu(self.conv1(x))  # 28*28*6        out = F.max_pool2d(out, 2)  # 14*14*6        out = F.relu(self.conv2(out))  # 10 *10 *16        out = F.max_pool2d(out, 2)  # 5*5*16        out = out.view(out.size(0), -1)        out = F.relu(self.fc1(out))        out = F.relu(self.fc2(out))        out = self.fc3(out)        return out</code></pre><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><blockquote><p>在LeNet-5之后，卷积神经网络由于硬件，数据等元素的局限，训练较为困难，所以发展一直都是不温不火，直到<strong>AlexNet</strong>在2012年<strong>ImageNet</strong>竞赛中以超越第二名10.9个百分点的优异成绩一举夺冠，从而打响了卷积神经网络、乃至深度学习在计算机视觉领域中研究热潮的“第一枪”。</p></blockquote><p><strong>结构</strong>：</p><p><img src="https://i.imgur.com/et352X8.png" alt=""></p><p>在AlexNet的网络结构中，共含五层卷积层和三层全连接层。AlexNet的上下两支是为了方便同时使用两片GPU进行训练，不过在第三层卷积和全连接层处上下两支信息可交互。由于两支网络完全一致，只需对其中一支进行分析。</p><ol><li><strong>卷积层C1</strong>：输入图像为$3\times224\times224$大小，实际是$3\times227\times227$大小，卷积核为$11<em>11$，不使用零填充，步长为$4$，总共使用$96$个卷积核，由公式可得$\lfloor\frac{227-11}{4}+1\rfloor=55$，即由卷积得到$96\times55\times55$大小的特征图。采用$3</em>3$尺度，步长为$2$去池化，则池化后的图像尺寸为$27$，所以像素规模为$96\times27\times27$，由于采用两个GPU，则分为两组，每组大小为$48\times27\times27$。</li><li><strong>卷积层C2</strong>: 对于上一层的输出，采用$256$个$3*3$大小的卷积核，使用$1$个padding，步长为$1$，对其进行卷积得到$256\times26\times26$的特征图，对其同样采用最大池化，上下两层分别得到$128\times13\times13$大小的输出特征图。</li><li><strong>卷积层C3</strong>：此层采用$384$个$3*3$大小的卷积核，同样使用$1$个零填充，上下两层分别得到$192\times13\times13$大小的输出图。</li><li><strong>卷积层C4</strong>: 同上一层，此层采用$384$个$3*3$大小的卷积核，同样使用$1$个零填充，上下两层分别得到$192 \times13\times13$大小的输出图。</li><li><strong>卷积层C5</strong>：此层采用$256$个$3*3$大小的卷积核，同样使用$1$个零填充，上下两层分别得到$128\times12\times12 $大小的输出图。再采用最大池化，降维到$128\times 6 \times 6$大小。</li><li><strong>全连接层</strong> ： 之后共采用了三层全连接结构，对于其中一个GPU, 特征大小逐渐从$128<em>6</em>6$到$2048$，再从$2048$到$2048$，最后将两个GPU合并，也就是将特征从$4096$映射到$1000$，也就是ImageNet中类别的数量。</li></ol><p><strong>贡献</strong>:</p><ul><li><strong>AlexNet</strong>  首次将卷积神经网络应用于计算机视觉领域的海量图像数据集<strong>ImageNet</strong>， 揭示了卷积神经网络拥有强大的学习能力和表达能力。另一方面海量的数据也能防止神经网络过拟合。自此引发深度学习井喷式增长。</li><li>利用<strong>GPU</strong>实现网络训练，之前由于计算资源的发展受限，阻碍了神经网络的研究进程。如今，利用GPU已大大减少了大型网络模型开发的成本和时间。</li><li>一些训练技巧为之后研究打下了基础。<strong>ReLU激活函数</strong>，<strong>局部响应规范化</strong>(LRN)操作(如今已不常用)，随机失活(<strong>Dropout</strong>: 随机再网络中去除一些连接)，这些训练技巧不仅保证了模型的性能，也为之后深度卷积神经网络构建提供了范本。</li></ul><p><strong>代码实现</strong>:</p><pre><code class="lang-python">class AlexNet(nn.Module):    def __init__(self, num_classes=1000):        super(AlexNet, self).__init__()        self.features = nn.Sequential(            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),            nn.ReLU(inplace=True),            LRN(local_size=5, alpha=0.0001, beta=0.75),            nn.MaxPool2d(kernel_size=3, stride=2),            nn.Conv2d(96, 256, kernel_size=5, padding=2, groups=2),            nn.ReLU(inplace=True),            LRN(local_size=5, alpha=0.0001, beta=0.75),            nn.MaxPool2d(kernel_size=3, stride=2),            nn.Conv2d(256, 384, kernel_size=3, padding=1),            nn.ReLU(inplace=True),            nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2),            nn.ReLU(inplace=True),            nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2),            nn.ReLU(inplace=True),            nn.MaxPool2d(kernel_size=3, stride=2),        )        self.classifier = nn.Sequential(            nn.Linear(256 * 6 * 6, 4096),            nn.ReLU(inplace=True),            nn.Dropout(),            nn.Linear(4096, 4096),            nn.ReLU(inplace=True),            nn.Dropout(),            nn.Linear(4096, num_classes),        )    def forward(self, x):        x = self.features(x)        x = x.view(x.size(0), 256 * 6 * 6)        x = self.classifier(x)        return x</code></pre><h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p>VGG网络有类似Alex的形式，但它在一些地方也有不同。</p><ul><li>VGG-Net中普遍使用了小卷积核，AlexNet多采用的大于5的卷积核，而VGG的卷积核多为$3*3$</li><li>网络卷积层的通道数从$3\to64\to128\to256\to512$。通道数逐渐变得很大，学到的特征多。</li><li>VGG中的卷积很多都保持了输入大小，也就是卷积后大小保持不变，为的是在增加网络深度时确保各层输入大小随深度增加而不极具减小。</li></ul><p><strong>结构</strong></p><p><img src="https://i.imgur.com/t4U5sHK.png" alt=""></p><p><img src="https://i.imgur.com/rQwN1Zn.png" alt=""></p><h3 id="ResNets"><a href="#ResNets" class="headerlink" title="ResNets"></a>ResNets</h3><blockquote><p> 理论和实验表明，神经网络的<strong>深度</strong>和<strong>宽度</strong>是表征网络复杂度的两个核心因素，不过深度相比宽度在增加网络复杂性上更加有效，然而随着深度的增加，训练会变得愈加困难。这主要是因为在基于<strong>随机梯度下降</strong>的网络训练过程中，误差的多层反向传播会导致<strong>梯度弥散</strong>或<strong>梯度爆炸</strong>。可能随着网络的训练，误差并未减少而却增加。<strong>残差网络</strong>(ResNets)便很好地解决了这一问题。</p></blockquote><p><strong>残差块</strong></p><p><img src="https://i.imgur.com/qxiUrhA.png" alt=""></p><p>残差网络主要受<strong>高速网络</strong>的影响，假设某卷积神经网络有$L$层，其中第$i$层的输入为$x^{i}$，参数为$w^{i}$，该层的输出为$y^{i}=x^{i+1}$，忽略偏置，则之间关系表示为:</p><script type="math/tex; mode=display">y=F(x,w)</script><p>其中，$F$为非线性激活函数，而对于高速网络来言，$y$的计算定义如下:</p><script type="math/tex; mode=display">y=F(x,w)*(T(x,w)+x*C(x,w)</script><p>其中$T,C$是两个非线性变换,分别称作“<strong>变换门</strong>”和“<strong>携带门</strong>”。变换门负责控制变换的强度，携带门则控制原输入信号的保留强度，由于增加了<strong>保留原输入数据的可能性</strong>，所以这种网络会更加灵活。而残差网络可以看作其的特殊情况：本来优化目标为:</p><script type="math/tex; mode=display">y=F(x,w)+x</script><p>简单变形为</p><script type="math/tex; mode=display">F(x,w)=y-x</script><p>也就是说，网络所要学习的就是<strong>残差项</strong>$y-x$。残差块有两个学习分支，其一是左侧的残差函数，其二为右侧对输入的恒等映射。这两个分支经过简单的整合，再经过一个非线性变换<strong>ReLU</strong>，从而形成网络的残差块。由多个残差块堆积而成了<strong>残差网络</strong>。</p><p><img src="https://img-blog.csdn.net/20161028170505110" alt=""></p><ul><li>利用pytorch构建残差块</li></ul><pre><code class="lang-python"># Residual blockclass ResidualBlock(nn.Module):    def __init__(self, in_channels, out_channels, stride=1, downsample=None):        super(ResidualBlock, self).__init__()        self.conv1 = conv3x3(in_channels, out_channels, stride)        self.bn1 = nn.BatchNorm2d(out_channels)        self.relu = nn.ReLU(inplace=True)        self.conv2 = conv3x3(out_channels, out_channels)        self.bn2 = nn.BatchNorm2d(out_channels)        self.downsample = downsample    def forward(self, x):        residual = x        out = self.conv1(x)        out = self.bn1(out)        out = self.relu(out)        out = self.conv2(out)        out = self.bn2(out)        if self.downsample:            residual = self.downsample(x)        out += residual # 加上残差项        out = self.relu(out)        return out</code></pre><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><blockquote><p>由于增加网络的深度和宽度会导致训练难以进行下去，<strong>Inception</strong>主要思路是用<strong>密集成分来近似最优的局部稀疏结构</strong>去加深网络的同时，增<strong>宽</strong>网络结构。</p></blockquote><p><strong>Inception模块</strong></p><p><img src="https://img-blog.csdn.net/20160225155351172" alt=""></p><ul><li>采用不同大小的卷积核，意味着得到不同大小的感受野，最后<strong>拼接</strong>起来意味着不同尺度的融合。</li><li>之所以卷积核采用1，3，5，主要为了方便对齐。设定步长$stide=1$之后，只要设定相应的$padding$为0， 1， 2，那么卷积之后即可得到相同维度的特征，那么这些特征即可拼接再一起。</li><li>在一个方向上先采用了最大化池化，这样能得到更好的效果。</li><li>采用了$1*1$卷积</li><li>网络越到后面，特征越抽象，而且每个特征涉及的感受野也更大了，因此随着层数的增加，$3<em>3$和$5</em>5$卷积的比例也要增加。</li></ul><p>由多个<strong>Inception</strong>模块构建成了<strong>GoogLeNet</strong></p><p><img src="https://img-blog.csdn.net/20160225155403967" alt=""></p><p>在Inception-v1之后为了提高训练速度和效果出现了许多衍生版本，但思想都不变，理解了Inception模块，就嫩理解Inception网络。</p><p>Inception模块的pytorch实现</p><pre><code class="lang-python">class Inception_base(nn.Module):    def __init__(self, depth_dim, input_size, config):        super(Inception_base, self).__init__()        self.depth_dim = depth_dim        #mixed &#39;name&#39;_1x1        self.conv1 = nn.Conv2d(input_size, out_channels=config[0][0], kernel_size=1, stride=1, padding=0)        #mixed &#39;name&#39;_3x3_bottleneck        self.conv3_1 = nn.Conv2d(input_size, out_channels=config[1][0], kernel_size=1, stride=1, padding=0)        #mixed &#39;name&#39;_3x3        self.conv3_3 = nn.Conv2d(config[1][0], config[1][1], kernel_size=3, stride=1, padding=1)        # mixed &#39;name&#39;_5x5_bottleneck        self.conv5_1 = nn.Conv2d(input_size, out_channels=config[2][0], kernel_size=1, stride=1, padding=0)        # mixed &#39;name&#39;_5x5        self.conv5_5 = nn.Conv2d(config[2][0], config[2][1], kernel_size=5, stride=1, padding=2)        self.max_pool_1 = nn.MaxPool2d(kernel_size=config[3][0], stride=1, padding=1)        #mixed &#39;name&#39;_pool_reduce        self.conv_max_1 = nn.Conv2d(input_size, out_channels=config[3][1], kernel_size=1, stride=1, padding=0)        self.apply(helpers.modules.layer_init)    def forward(self, input):        output1 = F.relu(self.conv1(input))        output2 = F.relu(self.conv3_1(input))        output2 = F.relu(self.conv3_3(output2))        output3 = F.relu(self.conv5_1(input))        output3 = F.relu(self.conv5_5(output3))        output4 = F.relu(self.conv_max_1(self.max_pool_1(input)))        return torch.cat([output1, output2, output3, output4], dim=self.depth_dim)</code></pre>]]></content>
      
      
        <tags>
            
            <tag> CNN 卷积神经网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>神经网络基础</title>
      <link href="/2018/05/12/nn-basic/"/>
      <url>/2018/05/12/nn-basic/</url>
      <content type="html"><![CDATA[<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><p>如图，一个<strong>神经元通常有如下的结构</strong>：<img src="https://i.imgur.com/BT6bd4A.png" alt="Snipaste_2018-05-08_14-41-31"></p><p>对于一组输入${a_{1}, a_{2}….,a_{k}}$，分别施于不同的<strong>权重</strong>(weight)，再通过加上一个<strong>偏置</strong>(bias)，得到神经元的<strong>线性模型</strong>,也就是之前学过的线性规划:</p><script type="math/tex; mode=display">z=a_{1}w_{1}+a_{2}w_{2}+......+a_{k}w_{k}+b</script><p>用向量化表示为:</p><script type="math/tex; mode=display">z=w^{T}a+b</script><p>由于线性变化所能解决的问题并不多，所以在输出施加一个<strong>激活函数</strong>(<em>activate function</em>)， 以在方程模型中引入非线性，同时另外的作用是可对输出进行限制:</p><script type="math/tex; mode=display">a_{out}=\delta(z)=\delta(w^{T}a_{in}+b)</script><ul><li><strong>实例</strong></li></ul><p><img src="https://i.imgur.com/ZKWIH2G.png" alt="Snipaste_2018-05-08_14-59-43"></p><p>对于上方的神经元实例，输入$a=[2, -1, 1]^{T}$,对于其三个输入分别施加的权重为$w=[1,-2, -1]^{T}$，将偏置<em>bias</em>设置为$1$，激活函数选择<strong>Sigmoid</strong>函数$\delta(z)=\frac{1}{1+e^{-z}}$，所以计算结果可以得到:</p><script type="math/tex; mode=display">a_{out}=\delta(w^{T}x+b)=\frac{1}{1+e^{-(2*1+(-1)*(-2)+1*(-1)+1)}}=0.98</script><h3 id="全连接神经网络"><a href="#全连接神经网络" class="headerlink" title="全连接神经网络"></a>全连接神经网络</h3><p>对于许多神经元，将其组合起来，对于网络每一层，设置不同数量的神经元，即可得到一个<strong>全连接前馈神经网络</strong>：</p><p><img src="https://i.imgur.com/7ivKJwZ.png" alt="Snipaste_2018-05-08_15-11-01"></p><p>全连接神经网络通过输入的特征向量$x$，得到输出$y$，而网络层中的权重$w$和偏置$b$即是，网络中的参数。在训练过程中，可通过<strong>反向传播</strong>和<strong>梯度下降算法</strong>进行更新。</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>这里介绍三种常见激活函数：</p><ul><li><p><strong>Sigmoid</strong>:</p><script type="math/tex; mode=display">f(z)=\frac{1}{1+e^{-z}}</script><p>其图像可表示为:</p><p><img src="https://i.imgur.com/IRPHg7V.png" alt=""></p></li></ul><p>很明显，可以看出经过<strong>Sigmoid</strong>函数作用后，输出响应的值域被压缩到了[0,1]之间，这也是<strong>逻辑回归</strong>中用到它的原因。对<strong>Sigmoid</strong>函数求导：</p><script type="math/tex; mode=display">\frac{d}{dz}f(z)=\frac{e^{-z}}{(1+e^{-z})^{2}}</script><p>对梯度画出图可见:</p><p><img src="https://i.imgur.com/v9Vx5WH.png" alt="sigmoid_梯度"></p><p><strong>不足之处</strong>：</p><ol><li>当$z$大于5或者小于-5时，部分的梯度<strong>接近于0</strong>，这会导致在误差反向传播中，导数处于该区域内的误差很难传播到前层，进而影响整个网络导致其无法训练。</li><li>从<strong>Sigmoid</strong>函数中可以看出其值域的均值都大于0，而并非<strong>等于</strong>0，这也不满足神经网络内对数值的期望。</li></ol><ul><li><strong>Tanh：</strong></li></ul><script type="math/tex; mode=display">f(z)=\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}</script><p><img src="https://i.imgur.com/vBRVjtq.png" alt="tanh"></p><blockquote><p>Tanh函数在Sigmoid函数的基础上解决了<strong>均值问题</strong>。</p></blockquote><p><strong>Tanh</strong>函数又称作<strong>双曲正切函数</strong>，其函数范围为$(-1,1)$，输出的响应均值为0。<strong>Tanh</strong>函数与<strong>Sigmoid</strong>函数的关系为:</p><script type="math/tex; mode=display">Tanh(z)=2Sigmoid(2z)-1</script><p>所以，求<strong>Tanh</strong>的导数:</p><script type="math/tex; mode=display">\frac{d}{dz}Tanh(z)=4Sigmoid(2z)*Sigmoid(2z)^{'}=\frac{4e^{-2z}}{(1+e^{-2z})^{3}}</script><p>具体地：</p><script type="math/tex; mode=display">\frac{d}{dz}Tanh(z)=1-(tanh(z))^{2}</script><p>由于<strong>Tanh</strong>函数仍基于<strong>Sigmoid</strong>函数，所以使用它仍依然会有<strong>“梯度饱和”</strong>现象。</p><ul><li><strong>ReLU</strong></li></ul><blockquote><p>为了避免<strong>梯度饱和</strong>现象的发生，在神经网络中引入了修正线性单元(<em>Rectified Linear Unit</em>)。</p></blockquote><script type="math/tex; mode=display">ReLU(x)=max(0,x)</script><script type="math/tex; mode=display">\begin{equation}ReLU(x)=\begin{cases}x& x\ge0\\0& x<0\end{cases}\end{equation}</script><p><img src="https://i.imgur.com/1lU9PNR.png" alt="relu"></p><p><strong>ReLU</strong>的导数:</p><script type="math/tex; mode=display">\begin{equation}\frac{d}{dx}ReLU(x)=\begin{cases}1& x >0\\0& x<0\\undefined&x=0\end{cases}\end{equation}</script><p>与前两个激活函数相比，<strong>ReLU</strong>的梯度在$x\ge0$时为$1$，反之为$0$，对$x\ge0$部分完全消除了之前的梯度饱和效应。计算复杂度上，<strong>ReLU</strong>函数也相比之前的两种指数函数简单，实验中还发现其有助于随机梯度下降方法收敛。<strong>ReLU</strong>函数已是目前深层卷积神经网络中最为常用的激活函数。</p>]]></content>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>回归分析</title>
      <link href="/2018/05/11/regression/"/>
      <url>/2018/05/11/regression/</url>
      <content type="html"><![CDATA[<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><blockquote><p> <strong>回归分析</strong>是一种统计学上分析数据的方法，目的在于了解两个或多个变量是否相关、相关方向与程度，并建立数学模型以便观察特定变量来预测研究者感兴趣的变量。更具体的来说，回归分析可以帮助人们了解在只有一个自变量变化时因变量的变化量。一般来说，通过回归分析我们可以由给出的自变量估计因变量的条件期望。</p></blockquote><p><strong>线性回归</strong>可以说是机器学习中最简单的模型，但是其实际地位很重要。先通过<strong>房价预测</strong>的例子来了解线性回归。</p><hr><p>假设有一个房屋销售的数据如下</p><div class="table-container"><table><thead><tr><th>房屋面积(m^2)</th><th>销售价钱(万元)</th></tr></thead><tbody><tr><td>123</td><td>250</td></tr><tr><td>150</td><td>320</td></tr><tr><td>87</td><td>160</td></tr><tr><td>102</td><td>220</td></tr><tr><td>……….</td><td>………..</td></tr></tbody></table></div><p>我们用几何图表示出这样的数据</p><p><img src="https://i.imgur.com/0lc9czo.png" alt=""></p><p>当我们有很多组这样的数据时，这些就是训练数据，我们希望学习一个模型，当有新的一个面积数据来到时，可以自动预测出销售价钱。也就是我们可以在这张图上用一条直线去尽量拟合这些数据，当有新的值来到时，可以用这条直线所对应的值去返回预测的价钱， 绿色的点就是我们所想要预测的点。当然，不是说线性回归就一定是一条直线，当变量x是一维的时候才是一条直线，而在高维时，是<strong>超平面</strong> 。</p><p><img src="https://i.imgur.com/BRBoV1l.png" alt="pic"></p><p>在这里先定义下<strong>数学符号</strong>，我们用$X=(x_{1}, x_{2}, x_{3},…,x_{n})^{T}$来表示输入数据矩阵，其中$x_{i}\in R^{p}$表示一个p维度长的数据样本，$y = (y_{1}, y_{2}, ….,y_{n}) \in R^{n}$表示数据的标签。</p><p>线性回归的模型可以表示为， 对于一个样本$x_{i}$，它的输出值是其特征的线性组合：</p><script type="math/tex; mode=display">f(x_{i}) = \sum_{m=1}^{p}w_{m}x_{im} + w_{0} = w^{T}x_{i}</script><p>其中<strong>$w_{0}$</strong>称为截距，或者<em>bias</em> 。线性回归的目标是用预测结果尽可能地拟合目标<em>label</em> 。对于机器学习模型，需要定义一个<strong>损失函数</strong>(Loss function)，用它来表示其与真实输出之间的误差， 从而评判模型的好坏。在这里定义如下的损失函数：</p><script type="math/tex; mode=display">J(w) = \frac{1}{2}\sum_{i=1}^{n}(h_{w}(x^{i})-y^{i})^{2}</script><p>这个错误估计函数是去对$x^{i}$的估计值与真实值$y^{i}$差的平方和作为错误估计函数，前面乘上的1/2是为了在求导的时候，这个系数就不见了, 从而方便之后的求导计算。为了训练模型，去<strong>最小化误差</strong> ， 使其接近于0， 这里需要用到的方法称为<strong>梯度下降法</strong> 。先用张图表示:</p><p><img src="https://i.imgur.com/tYp7YPW.png" alt=""></p><blockquote><p>梯度下降法，就是要一步步沿着梯度反向方向逐渐下降，从而走到局部甚至全局最小值。</p></blockquote><p>梯度下降法是按以下流程逐渐进行的：</p><ol><li>首先对$w$赋值， 这个值可以是随机的，也可以让其是个全零的向量。</li><li>改变$w$的值，使得$J(w)$按梯度下降的方向进行减少。这一步，就需要先求得每个参数的梯度，再通过梯度，逐渐改变其值。<strong>数学公式</strong>表示为:</li></ol><script type="math/tex; mode=display">\frac{\partial}{\partial w}J(w) = \frac{\partial}{\partial w}\frac{1}{2}\sum_{i=1}^{n}(h_{w}(x)-y)^{2}=(h_{w}(x)-y)x^{(i)}</script><ol><li>求得梯度后，就能通过设置一个学习率$\alpha$来沿着梯度减少的方向变化:</li></ol><script type="math/tex; mode=display">w_{i} := w_{i}-\alpha\frac{\partial}{\partial w_{i}}J(w)</script><p>代入上式的损失函数和所计算的梯度，也就得到:</p><script type="math/tex; mode=display">w_{i} = w_{i} - \alpha\frac{\partial}{\partial w_{}}J(w) = w_{i} - \alpha(h_{0}(x)-y)x^{(i)}</script><p>在真实计算时，往往参数使用矩阵或向量表示:</p><script type="math/tex; mode=display">\nabla J = \begin{vmatrix} \frac{\partial}{\partial w_{1}} J \\ \frac{\partial}{\partial w_{2}} J \\ ... \\ \frac{\partial}{\partial w_{n}} J\end{vmatrix}</script><script type="math/tex; mode=display">w = w - \alpha \nabla_{w} J</script><ul><li>线性回归实现: </li></ul><pre><code class="lang-python"># Linear Regression Modelclass LinearRegression(nn.Module):    def __init__(self, input_size, output_size):        super(LinearRegression, self).__init__()        self.linear = nn.Linear(input_size, output_size)      def forward(self, x):        out = self.linear(x)        return out</code></pre><hr><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><blockquote><p>逻辑回归也称为对数几率回归。明明叫回归，但却是<strong>分类问题</strong>中极为重要的手段。其思想也是基于线性回归，属于<strong>广义线性回归</strong>模型。</p></blockquote><p>对于二分类问题来讲，给你一个输入特征向量$X$，它可能对应一张图片，你想识别看它是否是一张猫的图片， 通过一个算法输出预测$\hat{y}$， 也就是对于实际值$y$的估计。换句话说，也就是想通过输入图片$X$， 想通过输出$\hat{y}$来知道这张图片是猫的几率有多大。用$w$来表示逻辑回归的参数，$x$是一个$n_{x}$维的特征向量，$b$表示这个模型中所要用到的偏置。如果用<strong>线性回归</strong>的方法来表示这个模型:</p><script type="math/tex; mode=display">\hat{y} = wx + b</script><p>这时候我们得到一个关于输入$x$的线性函数，但是对于这个二元分类来讲，似乎并不是一个很好的算法。因为我们想要得到的是这张图片是否为猫的概率，所以输出值应该介于<em>0 ~ 1</em>之间，而通过<strong>线性回归</strong>输出的$\hat{y}$可能要比1大很多，甚至为负值，这样来说这个模型就没有意义了，因此在<strong>逻辑回归</strong>当中，我们应将输出局限在<em>0~1</em>之间， 所以增加了一个<em>Sigmoid</em>函数将线性函数转换为非线性函数。</p><script type="math/tex; mode=display">\delta(z) = \frac{1}{1+e^{-z}}</script><p>使用<strong>matplotlib</strong>画出<em>Sigmoid</em>的图形表示如下，可以看出输出值都在<em>0~1</em>之间</p><pre><code class="lang-python"># 画sigmoidimport matplotlib.pyplot as pltimport numpy as npimport math%matplotlib inlinedef sigmoid(x):    a = []    for item in x:        a.append(1/(1+math.exp(-item)))    return ax = np.arange(-10, 10, 0.2)sig = sigmoid(x)plt.plot(x, sig)plt.show()</code></pre><p><img src="https://i.imgur.com/IRPHg7V.png" alt=""></p><p>如果$z$非常大那么$e^{-z}$将会接近于0，那么<strong>sigmoid</strong>函数的值将会近似等于1除以1加上某个非常接近于0的项，因为$e$ 的指数如果是个绝对值很大的负数的话，这项将会接近于0，所以如果$z$很大的话那么关于$z$的<strong>sigmoid</strong>函数会非常接近1。相反地，如果$z$非常小或者说是一个绝对值很大的负数，那么关于$e^{-z}$这项会变成一个很大的数，你可以认为这是1除以1加上一个非常非常大的数，所以这个就接近于0 。</p><p>所以要将识别猫这个任务所得到的结果规定在<em>0~1</em>之间，那么久需要对刚才定义的线性模型增加一个<strong>sigmoid</strong>函数，使其变为非线性:</p><script type="math/tex; mode=display">\hat{y} = \delta(wx+b)</script><script type="math/tex; mode=display">\delta(z) = \frac{1}{1+e^{-z}}</script><p>也就是:</p><script type="math/tex; mode=display">\hat{y}(x)=\frac{1}{1+e^{-(wx+b)}}</script><p>有了这个模型，要去实现这个识别猫的分类任务，接下来要做的就是通过给定的数据集，通过训练模型，把$w$参数给找出来。要找模型中的权重，就需要先定义<strong>损失函数</strong>。那么怎么去找到能衡量这个二分类的损失函数，通过使用<strong>极大似然估计</strong>。由于所要判断出的图片，只有两种可能:</p><ul><li>1表示图片里是猫</li><li>0表示图片里不是猫</li></ul><p>所以这两种情况的概率分别为:</p><script type="math/tex; mode=display">P(y=1|x; w) = \phi(w^{T}x+b)=\phi(z)</script><script type="math/tex; mode=display">P(y=0|x;w)=1-\phi(w^{T}x+b)=1-\phi(z)</script><p>根据上面两式，通过<strong>最大似然估计</strong>求解损失函数，首先得到<strong>概率函数</strong>为:</p><script type="math/tex; mode=display">P(y|x;w)=\phi(z)^{y}(1-\phi(z))^{(1-y)}</script><p>因为数据集中样本数据是相互独立的，所以它们的联合分布可以表示为总的乘积:</p><script type="math/tex; mode=display">L(w)=\prod_{i=1}^{m}P(y^{i}|x^{i};w)</script><script type="math/tex; mode=display">L(w) =\prod_{i=1}^{m}\phi(z^{i})^{y^{i}}(1-\phi(z^{i}))^{1-y^{i}}</script><p>取<strong>对数似然函数</strong>:</p><script type="math/tex; mode=display">l(w)=ln(L(w))=\sum_{i=1}^{m}ln(\phi(z^{i})^{y^{i}})+ln(1-\phi(z^{i}))^{(1-y^{i})}</script><script type="math/tex; mode=display">l(w)=ln(L(w))=\sum_{i=1}^{m}y^{i}ln(\phi(z^{i}))+(1-y^{i})ln(1-\phi(z^{i}))</script><p>最大似然估计就是要取使$l(w)$最大时的$w$,所以在前面加上一个<strong>负号</strong>不就是使求其最小了吗？这样就得到损失函数:</p><script type="math/tex; mode=display">J(w) = -l(w)=-y^{i}ln(\phi(z^{i}))-(1-y^{i})ln(1-\phi(z^{i}))</script><p>所以简化形式的损失函数为:</p><script type="math/tex; mode=display">L(\hat{y}, y)=-yln(\hat{y})-(1-y)ln(1-\hat{y})</script><p>当$y=1$时损失函数$L=-ln(\hat{y})$，如果想要损失函数$L$尽可能得小，那么$\hat{y}$就要尽可能大，因为<strong>sigmoid</strong>函数取值$[0,1]$，所以$\hat{y}$会无限接近于1。</p><p>当$y=0$时损失函数$L=-ln(1-\hat{y})$，如果想要损失函数$L$尽可能得小，那么$\hat{y}$就要尽可能小，因为<strong>sigmoid</strong>函数取值$[0,1]$，所以$\hat{y}$会无限接近于0。</p><p>这只是对于单个样本的损失函数，对于总的样本，需将所有代价加起来除以m：</p><script type="math/tex; mode=display">J(w)=\frac{1}{m}\sum_{i=1}^{m}L(\hat{y}, y)</script><p>接下来要做的就是通过<strong>梯度下降法</strong>求得导数，再如之前一样更新参数$w$和$b$的值即可。</p><p>同样使用<strong>pytorch</strong>来实现逻辑回归模型:</p><pre><code class="lang-python">class LogisticRegression(nn.Module):    def __init__(self, input_size, num_classes):        super(LogisticRegression, self).__init__()        self.linear = nn.Linear(input_size, num_classes)    def forward(self, x):        out = self.linear(x)        out = torch.sigmoid(out)        return out</code></pre>]]></content>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
