<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>faster-rcnn</title>
      <link href="/2018/06/26/faster-rcnn/"/>
      <url>/2018/06/26/faster-rcnn/</url>
      <content type="html"><![CDATA[<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h2><blockquote><p>在目标检测领域，在第一次出现了<strong>R-CNN</strong>之后，开始广泛使用了神经网络的方法，在R-CNN基础上出现了<strong>Fast R-CNN</strong>，其变得比R-CNN更快，但不能改变的是在产生候选区域的过程中，它们两者都采用的叫一种<em>Selective search</em>的方法，这种方法非常慢。而Faster R-CNN的出现，其利用卷积神经网络去提取候选区域，大大加快了训练速度，同样也提高了准确率，Faster-RCNN是在目标检测领域非常重要的一个方法。</p></blockquote><h3 id="R-CNN-和-Fast-R-CNN"><a href="#R-CNN-和-Fast-R-CNN" class="headerlink" title="R-CNN 和 Fast R-CNN"></a>R-CNN 和 Fast R-CNN</h3><p><strong>R-CNN步骤</strong>：</p><ol><li><p>训练或者下载一个分类模型（基于ImageNet），对该模型做<em>fine-tuning</em>，将分类数从1000改为20，并去掉最后一个全连接层。</p></li><li><p>利用<strong>选择性搜索</strong>(selective search)，从图像中选取大约2000个候选框</p></li><li><p>对于所选择的每一个区域，修正区域的大小以适合CNN的输入，将每个候选区域传入网络中提取特征</p></li><li><p>特征送入每一类的<strong>SVM分类器</strong>，判断是否属于此类。并使用回归器精修候选框的位置。</p></li></ol><p>   <img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630160655.png" alt=""></p><p>由于R-CNN使用<em>selective search</em>方法选择出候选框之后，需将每个候选框传入神经网络中提取特征进行判断，所以这个过程非常慢，Fast R-CNN在此基础上提升了区域框的选取过程，不是先选取框再传入CNN之中一个一个训练，而是直接将整张图片传入CNN之中提取特征。由于选择出的RoIs的大小都各不相同，所以在Fast R-CNN之中引入了RoI pooling，可将不同区域大小的候选区pooling为相同尺寸的特征区域。</p><p><strong>Fast R-CNN步骤</strong>:</p><ol><li>任意大小的图片传入ImageNet预训练网络(VGG)之中，得到feature map</li><li>在此图像中通过selective search选取2000个左右的候选框</li><li>通过特征图和原图的映射关系，将在原图中提取到的候选框，映射到feature map中</li><li>通过RoI Pooling 将特征图上的2000个候选框池化为固定大小(VGG中为7x7大小)，经过一个全连接层得到固定的特征向量。</li><li>所得到的特征向量再经过两个全连接层分别得到两个输出向量：一个是softmax的<strong>分类</strong>得分，一个是Bounding-box的窗口<strong>回归</strong>。</li><li>利用窗口得到的score分别对每一类物体进行非极大值抑制(nms)，剔除重叠的建议框，最终得到每个类别回归修正得分最高的窗口。</li></ol><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630162003.png" alt=""></p><h3 id="Faster-R-CNN-1"><a href="#Faster-R-CNN-1" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h3><p><a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">论文</a></p><p>整体流程：</p><p><img src="https://pic2.zhimg.com/80/v2-4e372e4536ef6d3d28ebd8803a9b13e2_hd.jpg" alt=""></p><p>大致分为三个区域：</p><ol><li><strong>Extractor</strong>，为常用的预训练模型，通过输入图像，以此来提取特征。</li><li><strong>RPN</strong>，Faster-RCNN中新提出的区域生成方法，摈除了之前采用的<em>Selective search</em>，而采用了卷积神经网络去生成RoIs，这样大大提高了网络的速度。</li><li><strong>ROIHead</strong>，通过传入RPN中生成的区域，对每个区域进行分类和坐标回归，此处和之前的Fast R-CNN类似。</li></ol><h4 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h4><p>数据采用常用的目标检测数据库VOC或COCO，需做以下处理：</p><ul><li>对每个图片,reshape为边长小于或等于1000和600，其中（至少一个等于）</li><li>对相应的<em>ground truth</em>也做同样尺度的缩放</li></ul><p>最后训练过程中所需要的四个值分别为：</p><ul><li><em>images</em>: $3<em>H</em>W$大小</li><li><em>bboxes</em>: $4*K$, 其中$K$为bboxes数量，坐标形如(Y_min, X_min, Y_max, X_max)</li><li><em>labels</em>: $(K, )$, 对应K个bboxes的labels，在VOC中为(0~19)</li><li><em>scale</em>: 图像缩放的倍数，原图$H^{‘} <em> W^{‘}$reshape到$H </em> W$,则$scale=H^{‘} / H$</li></ul><h4 id="Extractor"><a href="#Extractor" class="headerlink" title="Extractor"></a>Extractor</h4><p><img src="https://pic2.zhimg.com/80/v2-28887eb4f69439e1384165da0ca20b6f_hd.jpg" alt="img"> </p><p>这里使用VGG16,当然也可以使用ResNet101，在VGG的前四层，由于训练时为了节约显存，所以将其学习率设置为0，在<strong>Extractor</strong>部分，只用到了conv5_3之前，及图像reshape到大小为$1000<em>600$之后，传入到VGG16中，在conv5_3处输出图像的feature map，到此图像下采样了16倍，得到了$C</em>(H/16)<em>(W/16)$特征图，在此具体为$512</em>62*38$。在conv5_3之后还有两个全连接层，在extractor中并未使用，但在之后的ROIHead中用到了。</p><h4 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h4><p><strong>Anchor</strong></p><p>作者首先一改之前，提出了Anchor，即尺寸大小固定的候选框，在论文中使用了三种尺寸(1:1,1:2,2:1)，三种大小(128,256,512)，得到了9个不同的anchor</p><p><img src="https://pic1.zhimg.com/80/v2-7abead97efcc46a3ee5b030a2151643f_hd.jpg" alt=""></p><p>这9个anchor在刚生成的feature map中左右上下移动，对于每个点都得到了9个anchor，这样就得到了共$62<em>38</em>9$~20000个anchor.当然这20000个anchor并不会全部传给ROIHead训练，只会从中选取2000个传给之后。</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630165723.png" alt=""></p><p>在RPN中就需要对候选框进行分类，但此处不是20分类，而是二分类，即判断是否含有物体。在特征图的基础上，在一个3x3卷积之后，分别使用$9<em>2$和$9</em>4$个1x1的卷积核进行卷积操作，这样原本特征图为512x62x38，则分别卷积到62x38x9*2，和62x38x9x4，这样得到大约20000个框的score和坐标。</p><h4 id="RPN生成RoIs"><a href="#RPN生成RoIs" class="headerlink" title="RPN生成RoIs"></a>RPN生成RoIs</h4><p>RPN的主要作用就是为之后的ROIHead生成大约RoIs，在代码中为(Proposal Creator)</p><ul><li>对于每张图片的大约20000个候选框，首先先选取score较大的12000个anchor</li><li>利用回归的位置参数，修正这12000个anchor,得到RoIs</li><li>利用非极大值抑制(NMS)，选出概率最大的2000个RoIs。</li></ul><p>注意：在Test时，12000和2000分别变为6000和300</p><h4 id="RPN训练"><a href="#RPN训练" class="headerlink" title="RPN训练"></a>RPN训练</h4><p>RPN自身也要训练，以此选取更好的RoIs，此处RPN从20000个选出大约256个供自身训练，其中正负样本各占一半，选择过程如下,代码中为<code>Anchor Target creator</code>：</p><ul><li>对于每个ground truth bbox，选择和它IOU最高的一个anchor作为正样本</li><li>对于每个anchor，若有ground truth和它的IOU大于0.7，则选取它作为正样本，正样本的数目不超过128，若不够，则由负样本凑</li><li>随机选取和任意ground truth的IOU都小于0.3的anchor作为负样本，数目为128</li></ul><p>对于分类只有二分类，即要么为1（前景），0（背景），回归坐标则需要改变一下</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630171202.png" alt=""></p><p>其中分类采用交叉熵损失，而计算回归则采用的是<code>Smooth L1</code>损失，同样在计算<strong>回归</strong>损失时，只计算正样本的损失，而不计算负样本的损失。</p><h3 id="ROIHead"><a href="#ROIHead" class="headerlink" title="ROIHead"></a>ROIHead</h3><p><img src="https://pic1.zhimg.com/80/v2-5b0d1ca6e990fcdecd41280b69cd8622_hd.jpg" alt=""></p><p>RPN会产生大约2000个ROIs，但并不是全部都要在ROIHead中训练，而是通过<code>ProposalTargetCreator</code>选取128个RoIs进行训练。选择的规则如下：</p><ul><li>RoIs和gt_bboxes的IoU大于0.5的选择32个作为正样本</li><li>IoU小于等于0或0.1(自己设置)选择96个作为负样本</li></ul><p>但由于这些候选框的大小都不相同，所以采用RoIPooling将这些候选框pooling成相同的大小(7x7,在VGG中)。选取的框需要映射到feature map 中，所以RoIpooling将区域都统一下采样到$512\times7\times7$，由于选取了128个，所以就得到了$128\times512\times7\times7$大小的特征向量，之前VGG的全连接层在这里还需要用到，将特征向量reshape为一维的之后，传入全连接层，再分别传入<strong>FC21</strong>和<strong>FC84</strong>得到分类结果和坐标结果，损失函数和之前RPN中采用的相同。</p><p><img src="https://raw.githubusercontent.com/HandsomeCao/markdown-picture/master/20180630173140.png" alt=""></p><p>完整结构如上所示。</p><p><a href="https://zhuanlan.zhihu.com/p/32404424" target="_blank" rel="noopener">参考</a></p>]]></content>
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>K-近邻算法</title>
      <link href="/2018/06/05/knn/"/>
      <url>/2018/06/05/knn/</url>
      <content type="html"><![CDATA[<h2 id="K-近邻算法-KNN"><a href="#K-近邻算法-KNN" class="headerlink" title="K-近邻算法(KNN)"></a>K-近邻算法(KNN)</h2><blockquote><p>k-近邻算法采用测量不同特征值之间的距离方法进行分类</p></blockquote><ul><li>监督学习方法，适用于分类</li><li>优点：精度高，对异常值不敏感，无数据输入假定。</li><li>缺点：计算复杂度高，空间复杂度高。</li><li>适用数据范围：数值型，标称型。</li></ul><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>如果存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在<strong>标签</strong>，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据<strong>（最近邻）</strong>的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是<strong>不大于20</strong>的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。</p><h3 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h3><p>对未知类别属性的数据集中的每个点依次执行以下操作：</p><ol><li>计算已知类别数据集中的点与当前点之间的距离；</li><li>按照距离递增次序排序；</li><li>选取与当前点距离最小的k个点；</li><li>确定前k个点所在类别的出现频率；</li><li>返回前k个点出现频率最高的类别作为当前点的预测分类</li></ol><p>其中计算距离通常采用<strong>欧式距离公式</strong>：</p><script type="math/tex; mode=display">d=\sqrt{(xA_{0}-xB_{0})^{2}+(xA_{1}-xB_{1})^{2}}</script><h3 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h3><pre><code class="lang-python">import numpy as npimport operatordef CreateDataSet():    &quot;&quot;&quot;    Create some fake data    &quot;&quot;&quot;    group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])    labels = [&#39;A&#39;,&#39;A&#39;,&#39;B&#39;,&#39;B&#39;]    return group, labelsdef classify0(inX, dataSet, labels, k):    &quot;&quot;&quot;    KNN algorithm:    1. calculate the distance between every data from        sample with the target data.    2. sort these distances by ascending    3. get the top k data with smallest distance    4. confirm the frequnces of topk&#39;s class    5. return the highest frequncy of class      &quot;&quot;&quot;    dataSetSize = dataSet.shape[0]  # the amount of data    # calculate the distance between two points    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet    sqDiffMat = diffMat ** 2    sqDistances = sqDiffMat.sum(axis=1)    distances = sqDistances ** 0.5    sortedDistIndices = distances.argsort()    # choose the topk    classCount = {}    for i in range(k):        voteIlabel = labels[sortedDistIndices[i]]        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1    sortedClassCount = sorted(classCount.items(),        key=operator.itemgetter(1), reverse=True)    return sortedClassCount[0][0]if __name__ == &#39;__main__&#39;:    group, labels = CreateDataSet()    output = classify0([0, 0], group, labels, 3)    print(output)</code></pre><p><a href="https://github.com/HandsomeCao/Machine-Learning-learn/tree/master/KNN" target="_blank" rel="noopener">代码</a></p>]]></content>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mAP</title>
      <link href="/2018/05/27/mAP/"/>
      <url>/2018/05/27/mAP/</url>
      <content type="html"><![CDATA[<h2 id="mAP-目标检测模型中的性能评估"><a href="#mAP-目标检测模型中的性能评估" class="headerlink" title="mAP - 目标检测模型中的性能评估"></a>mAP - 目标检测模型中的性能评估</h2><blockquote><p><strong>目标检测</strong>问题是指：给定一个图像，找到其中的目标，找到它们的位置，并且对目标进行分类。目标检测模型通常是在一组固定的类上进行训练的，所以模型只能定位和分类图像中的那些类。此外，目标的位置通常是边界矩阵的形式。所以，目标检测需要涉及图像中目标的位置信息和对目标进行分类。 均值平均精度(<em>Mean Average Precision</em>)对于评估模型定位性能、目标检测性能和分割模型性能都是很有用的。</p></blockquote><h3 id="精确率和召回率"><a href="#精确率和召回率" class="headerlink" title="精确率和召回率"></a>精确率和召回率</h3><p>要理解精确率(<em>presicion</em>)和召回率(<em>recall</em>)首先要理解以下概念：</p><ul><li>TP ——- 将正类预测为正类数</li><li>FN ——- 将正类预测为负类数</li><li>FP ——— 将负类预测为正类数</li><li>TN ——- 将负类预测为负类数</li></ul><p>举个例子:</p><blockquote><p>假设我们手上有60个正样本，40个负样本，我们要找出所有的正样本，系统查找出50个，其中只有40个是真正的正样本，计算上述各指标 ：</p></blockquote><ul><li><strong>TP = 40</strong>    (检测出的40个为正)</li><li><strong>FN = 20</strong>   (有60个正，只检测出40个为正，所以60-40=20)</li><li><strong>FP = 10</strong>   (找出了50个，但只有40为正，50-40=10)</li><li><strong>TN = 30</strong>  (找出中的50个，只有40个为正，也即其中10个为负，所以40-10=30)</li></ul><p>而<strong>精确率</strong>是针对<strong>预测结果</strong>而言的，它表示的是预测为正的样本中有多少是真正的正样本。那么预测为正就有两种可能了，一种就是把正类预测为正类<strong>(TP)</strong>，另一种就是把负类预测为正类(<strong>FP</strong>)，也就是 </p><script type="math/tex; mode=display">P = \frac{TP}{TP+FP}</script><p>而<strong>召回率</strong>是针对我们原来的<strong>样本</strong>而言的，它表示的是样本中的正例有多少被预测正确了。那也有两种可能，一种是把原来的正类预测成正类<strong>(TP)</strong>，另一种就是把原来的正类预测为负类(<strong>FN)</strong>:</p><script type="math/tex; mode=display">R = \frac{TP}{TP+FN}</script><blockquote><p>简单来说，<strong>精确率</strong>是指对于<strong>检测出的</strong>样本中，为正的样本所占比例。而<strong>召回率</strong>是指<strong>本来的为正的样本</strong>中，检测出的正样本所占的比例。</p></blockquote><p>所以：</p><p><strong>精确率</strong>(<em>precision</em>) = $ TP/(TP+FP) = 4/5$</p><p><strong>召回率</strong>(recall) = $ TP/(TP+FN) = 2/3 $ </p><p>额外：</p><p><strong>准确率</strong>(<em>accuracy</em>) = 预测对的/所有 = $(TP+TN)/(TP+FN+FP+TN) = \frac{7}{10} $</p><p><img src="http://s9.sinaimg.cn/mw690/002T2ChPgy6XQdjij4Ae8" alt=""></p><h3 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h3><blockquote><p> <strong>loU(交并比)</strong>是模型所预测的检测框和真实(<em>ground truth</em>)的检测框的<strong>交集和并集之间的比例</strong>。这个数据也被称为<em>Jaccard</em>指数。 </p></blockquote><p><img src="https://img-blog.csdn.net/20161121150037641" alt=""></p><p>对于图像中的GroundTruth框$A$，其检测出的矩形框为$B$，则其IoU(Intersection over Union)可以计算如下:</p><script type="math/tex; mode=display">IoU=\frac{A\cap B}{A \cup B}</script><h3 id="AP"><a href="#AP" class="headerlink" title="AP"></a>AP</h3><ul><li>对于PASCAL_VOC2007， 首先设定一组阈值，$[0, 0.1, 0.2, …, 1]$。然后对于$recall$大于每一个阈值（比如$recall&gt;0.3$），我们都会得到一个对应的最大$precision$。这样，我们就计算出了$11$个$precision$。通过对这11个散点做出PR图，<strong>AP</strong>即为这11个$precision$对于每个$recall$值所做的曲线下的<strong>面积</strong>。这种方法英文叫做$11-point interpolated average precision$。</li><li>当然<strong>PASCAL VOC CHALLENGE</strong>自2010年后就换了另一种计算方法。新的计算方法假设这$N$个样本中有$M$个正例，那么我们会得到M个$recall$值$（1/M, 2/M, …, M/M）$,对于每个$recall$值$r$，我们可以计算出对应$（r’ &gt; r）$的<strong>最大</strong>$precision$，然后对这$M$个$precision$值同样做出PR曲线，求此曲线下的面积。</li></ul><p>实际多类别分类任务中，我们通常不满足只通过top-5(<strong>top-#是指通过score排序得到的预测序列</strong>)来衡量一个模型的好坏，而是需要知道从top-1到top-N（N是所有测试样本个数）对应的precision和recall。显然随着我们选定的样本越来也多，recall一定会越来越高，而precision整体上会呈下降趋势。把recall当成横坐标，precision当成纵坐标，即可得到常用的precision-recall曲线。这个例子的precision-recall曲线如下： </p><p><img src="http://s10.sinaimg.cn/mw690/002T2ChPgy6XQddBz7ze9" alt=""></p><h3 id="mAP"><a href="#mAP" class="headerlink" title="mAP"></a>mAP</h3><ul><li>求出每个类别的AP，之后只需要对每个类别的AP相加求平均值，即得到mAP。</li></ul><p>具体可参考这篇<a href="http://blog.sina.com.cn/s/blog_9db078090102whzw.html" target="_blank" rel="noopener">博文</a></p>]]></content>
      
      
        <tags>
            
            <tag> 目标检测 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>docker使用</title>
      <link href="/2018/05/13/docker/"/>
      <url>/2018/05/13/docker/</url>
      <content type="html"><![CDATA[<h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p><a href="www.docker.com">Docker</a>是一个<strong>开源</strong>的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。按理说，Docker并不是专门用于深度学习的工具，它运用非常广泛，对于任何编程的项目，Docker都能提供很好的帮助。</p><p>在实验室中需要使用Docker的原因主要是为了</p><blockquote><p>防止在服务器中相互影响和破坏底层环境，从而使用Docker为每个人生成一个虚拟的单独的环境</p></blockquote><p>这是相当有用的，对于每个生产环境，都可以生产一个单独的<strong>容器</strong>, 同时与其他生产环境相隔离。这和虚拟机似乎有点类似，但相比较于虚拟机，Docker所生成的容器具有<strong>更快速，更轻量</strong> 的效果。在Docker中有两个很重要的概念</p><ul><li><strong>容器</strong>(container)，其对应于面向对象方法中的<strong>对象</strong></li><li><strong>镜像</strong>(image)， 其对应于面向对象方法中的<strong>类</strong></li></ul><p>所以使用Docker的过程通常为：</p><ol><li>自己或者找到一个别人配好的适合自己生产环境的镜像。通常自己配镜像是通过<strong>DockerFile</strong>文件</li></ol><pre><code class="lang-bash">列出本机的所有 image 文件。$ docker images删除 image 文件$ docker image rm [imageName]</code></pre><p>image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别人的 image 文件进行加工，而不是从零开始制作。</p><pre><code class="lang-bash"># pull 命令从官网抓取hello-world镜像$ docker image pull library/hello-world</code></pre><ol><li>利用得到的image文件，生成容器实例</li></ol><pre><code class="lang-bash">$ docker container run hello-world</code></pre><p>在docker中最常用的就是<code>docker run</code>命令，也是最重要的。这里就用实验室所用的<code>docker run</code>命令展现其每个参数的意义</p><pre><code class="lang-bash">$ docker run -p 7981:8888 -it --name=[容器名称] -v /home/cao/workspace:/root/workspace --device /dev/nvidia-uvm --device /dev/nvidia0 --device /dev/nvidia1 [镜像名称] /bin/bash</code></pre><ul><li><strong>-p</strong> : 端口映射，即容器的8888端口映射到本机的7981端口</li><li><strong>-it</strong>  : 表示进入容器之后，进入命令行交互模式</li><li><strong>—name</strong> : 指定生成容器的名称，<em>一定要指定</em>。</li><li><strong>-v</strong>  : 路径映射，即容器的<em>/root/workspace</em>， 与本机的<em>/home/cao/workspace</em> 相互挂载，所以不能轻易删除</li><li><strong>—device</strong> : 映射本机的指定显卡</li></ul><p>这样在生成一个容器之后，通常就只需要对此容器进行操作，而生产环境全由<code>docker attach [容器名称]</code>进入容器之中操作。使用<code>docker -h</code>可查看全部帮助。</p>]]></content>
      
      
        <tags>
            
            <tag> docker 工具 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>卷积神经网络</title>
      <link href="/2018/05/13/cnn-basic/"/>
      <url>/2018/05/13/cnn-basic/</url>
      <content type="html"><![CDATA[<h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><blockquote><p> <strong>卷积层</strong>是卷积神经网络(<em>Convolutional Neural Network</em>)中的基本操作。其使用一个<strong>卷积核</strong>通过对输入层进行卷积操作，从而可以提取到图像中的高层信息。</p></blockquote><p>假设输入图像是下图中的一个$6*6$的矩阵,其中每个格代表了图像点的像素值。</p><p><img src="https://i.imgur.com/In87wix.png" alt=""></p><p>设置其卷积核（<em>kernel</em>）为$3*3$的矩阵，卷积核中的参数不同，可导致其卷积得到的结果不同:</p><p><img src="https://i.imgur.com/Dn0HGFv.png" alt=""></p><p>同时，假定卷积操作每做一次卷积，卷积核移动一个像素位置，即卷积的<strong>步长</strong>(<em>stride</em>)为1。第一次卷积操作从图像$(0,0)$像素开始，由卷积核中的参数与对应位置图像像素<strong>逐位相乘后累加</strong>作为一次卷积结果。</p><p><img src="https://i.imgur.com/OyxUEt2.png" alt=""></p><p>对于<strong>卷积核1</strong>(<em>filter1</em>)，其对于$(0,0)​$位置进行卷积操作:</p><script type="math/tex; mode=display">Conv_{out}=\sum{a_{i}b_{i}=}1*1+0*(-1)+0*(-1)+0*(-1)+1*1+0*(-1)+0*(-1)+1*1=3</script><p>当步长为$1$时，卷积核按照补偿大小在输入图像<strong>从左到右从上到下</strong>依次将卷积操作进行下去，最终输出一个$4<em>4$大小的<em>*卷积特征</em></em>，同时这卷积特征将作为下一层操作的输入。</p><p><img src="https://i.imgur.com/NdLlBtZ.png" alt=""></p><p>与之类似，若三维情形下的卷积层$l$的输入张量为$x^{l}\in R^{H^{l}\times W^{l} \times D^{l}}$,该层的卷积核为$f^{l}\in R^{H^{l}\times W^{l} \times D^{l}}$。三维输入时，卷积操作实际上只是将二维卷积扩展到了相应位置的所有通道上，最终将一次卷积处理的所有$HWD^{l}$个元素求和作为该位置的卷积结果。</p><p>若进一步，类似$f^{l}$这样的卷积核有$D$个，则在同一个位置可得到$1 \times 1 \times 1 \times D$维度的卷积输出，而$D$即为第$l+1$层特征$x^{l+1}$的通道数$D^{l+1}$。对于三维图像，形式化的卷积操作为:</p><script type="math/tex; mode=display">y_{i^{l+1},j^{l+1},d}=\sum_{i=0}^{H}\sum_{j=0}^{W}\sum_{d^{l}=0}^{D^{l}}f_{i,j,d^{l},d} \times x_{i^{l+1}+i, j^{l+1}+j,d^{l}}^{l}</script><p>其中$(i^{l+1},j^{l+1})$为卷积结果的位置坐标，在卷积层中，$f$可视作学习到的网络中的权重(<em>weight</em>)，可以发现该项权重对不同位置的所有输入都是相同的，也就是一个卷积核时作用于不同的区域的，这也就是卷积神经网络中的<strong>权值共享</strong>特性，当然除此之外，也可以为卷积操作设定其神经元中的<strong>偏置项</strong>，当然也可将其设置为0。</p><p><strong>零填充</strong>：</p><hr><p>可见，对于上面介绍的卷积操作，对于一张输入图像，进行不断的卷积操作，得到的输出特征尺寸将在不断<strong>减小</strong>，有时这样是不可取的，因为最终的输出逐渐减小后，所学到的图像特征也所剩无几了。所以这里有个保证图像输出不再减小的方法，称为<strong>零填充<em>(Zero padding)</em></strong>。</p><p><img src="https://i.imgur.com/7ccpHke.png" alt=""></p><p>如上图所示，即是在卷积操作中设置$padding=1$，也就是在边缘像素周围再以1个0填充。对于本来的输入为$6 \times6$大小的图像，以卷积核为$3 \times 3$，步长为$1$进行卷积，会得到$4 \times 4$大小的输出图像。但当<strong>加上零填充</strong>之后，输入图像也就可看作是$8 \times 8$大小，进行同样的卷积操作，输出却得到了$6 \times 6$大小的图像，和输入保持不变，这样也就能<strong>增加网络中的卷积操作，学到更为高层的特征</strong>。</p><p>所以在卷积操作中有三个重要的<strong>超参数</strong>(<em>Hyper parameters</em>)：</p><ul><li><strong>卷积核大小(<em>filter size</em>)</strong>: $(f \times f)$</li><li><strong>卷积步长(<em>filter stride</em>)</strong>：$s$</li><li><strong>零填充(<em>padding</em>)</strong>: $p$</li></ul><p>对于输入图像大小为$n \times n$，对于<strong>输出尺寸</strong>可以得到如下的一般公式:</p><script type="math/tex; mode=display">\lfloor\frac{n+2p-f}{s}+1\rfloor \times \lfloor\frac{n+2p-f}{s}+1\rfloor</script><p>当然，合适的超参数设置会对模型带来意想不到的效果提升。在<strong>pytorch</strong>中，对于二维图像的卷积操作，使用<code>nn.Conv2d</code>表示。</p><h3 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h3><blockquote><p>在卷积神经网络中，池化层往往在卷积层的后面，通过池化来<strong>降低</strong>卷积层输出的特征向量，同时改善结果，防止过拟合。</p></blockquote><p>池化通常用的两种方法为：<strong>最大值池化</strong>(Max-Pooling)和<strong>平均值池化</strong>(Average-Pooling)。</p><ul><li><strong>最大值池化</strong>：</li></ul><script type="math/tex; mode=display">y_{i^{l+1},j^{l+1},d}=max(x_{i^{l+1} \times H+I, j^{l+1} \times W+j,d^{l}}^{l})</script><ul><li><strong>平均值池化</strong>:</li></ul><script type="math/tex; mode=display">y_{i^{l+1},j^{l+1},d}=\frac{1}{HW}\sum x_{i^{l+1} \times H+I, j^{l+1} \times W+j,d^{l}}^{l}</script><p>对于卷积后得到的图像特征，<em>Max-Pooling</em>可形象表示为:</p><p><img src="https://i.imgur.com/yyCG6On.png" alt=""></p><p>这里池化的核大小选择为$(2 \times 2)$，也就是对于第一个块中，选择最大值7得到输出值。当然，如果是平均值池化，也就是取四个数的平均值作为其池化后的值。</p><p>可以发现，池化操作后的结果相比其输入减小了，其实际上是一种<strong>降采样(<em>down-sampling</em>)</strong>，池化层的引入是按照人的视觉系统对视觉输入对象进行降采样和抽象，其主要作用主要有以下三项：</p><ol><li><strong>特征不变性</strong>：池化操作使模型更关注是否存在某些特征而不是特征具体的位置。可看作是一种很强的先验，使特征学习包含某种程度自由度，能容忍一些特征微小的位移。</li><li><strong>特征降维</strong>：由于池化操作的降采样作用，汇合结果中的一个元素对应于原输入数据的一个子区域，因此池化相当于在空间范围内做了维度约减，从而使模型可以抽取更广范围的特征。同时减小了下一层输入大小，进而减小计算量和参数个数。</li><li>在一定程度上<strong>防止过拟合</strong>，方便优化。</li></ol><h3 id="LeNet-5"><a href="#LeNet-5" class="headerlink" title="LeNet-5"></a>LeNet-5</h3><p><img src="https://i.imgur.com/vh9DPQ7.png" alt=""></p><blockquote><p> LeNet-5可以说是最早的卷积神经网络结构了，它主要用于手写数字识别的任务上，其发表于1998年的<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="noopener">论文</a></p></blockquote><p><strong>结构</strong>：LeNet-5不包括输入层一共有7个层，每一层都包含了可以训练的参数，输入为一张$32 \times 32$的图像。</p><ol><li><strong>C1卷积层</strong></li></ol><p>这一层的输入就是原始的图像，输入层接受图片的输入大小为$32 \times32 \times1$。卷积层的核（过滤器）尺寸为$5\times5$，深度为$6$，不使用$0$进行填充，步长为$1$。通过计算公式可以求出输出的尺寸为$28\times28\times6$，卷积层的深度决定了输出尺寸的深度。卷积层总共的参数有$5<em>5</em>1<em>6+6 =156$个参数，加的$6$为卷积后的偏置项参数。本层所拥有的节点有$28</em>28<em>6=4704$个节点， 而本层的每一个节点都是经过一个$5\times5$的卷积和一个偏置项计算所得到的，$5</em>5+1=26$，所以本层卷积层一共有$4704*26 = 122304$个连接。</p><ol><li><strong>S2池化层</strong></li></ol><p>本层的输入是C1的输出，它接收一个$28\times28\times6$大小的矩阵。在卷积神经网络中，常有的池化方法为最大池化和平均池化，由于使用的核为$2\times2$，步长也为$2$，意味着每四个相邻元素经过S2之后会得到一个输出，所以输出矩阵大小变为$14\times14\times6$大小。</p><ol><li><strong>C3卷积层</strong></li></ol><p>本层卷积操作，采用的卷积核仍为$5\times5$，使用$16$个卷积核，也就是深度为$16$，同样不使用零填充，步长为$1$，所以得到输出大小为$10\times10\times16$。</p><ol><li><strong>S4池化层</strong></li></ol><p>本层采用同S2相同的池化操作，使输出值再缩小一半量级，变为$5\times5\times16$。</p><ol><li><strong>C5卷积层</strong></li></ol><p>C5层由$120$个卷积核组成，一个卷积与<strong>S4</strong>中每一个<em>feature map</em>（$5<em>5</em>16$）相连，所以每一个C5的卷积核都会输出一个$1<em>1$的矩阵，所以在S4与C5之间是可看作属于全连接。C5是一个卷积层而不是一个全连接层，如果这个LeNet5的输入变的更大了而其它的保持不变，那么这个输出将要大于$1</em>1$。</p><ol><li><strong>F6全连接层</strong></li></ol><p>F6层包含了$84$个结点，计算输入向量和权重向量之间的点积，再加上一个偏置，结果通过<strong>sigmoid</strong>函数，来产生一个输出，也就是之前的输入为$120$个神经元，现在通过一层全连接，其中含$84$个神经元，来将输出降维。 </p><ol><li><strong>输出层</strong></li></ol><p>输出层是由<strong>欧式径向基函数（RBF）</strong>组成。每一个输出对应一个RBF函数，每一个RBF函数都有$84$维的输入向量.。每一个RBF函数都会有一个输出，最后输出层会输出一个10维的向量。，以映射到10个数字分别的预测的准确度。</p><p><strong>MNIST数据集</strong></p><p>MNIST数据集是入门的第一个数据集，其数据都为$28\times28$大小的<strong>单通道</strong>图像，它含有$60000$张训练图片，和$10000$张验证图片。其形式非常简单，图像如下图</p><p><img src="http://wiki.jikexueyuan.com/project/tensorflow-zh/images/mnist_digits.png" alt=""></p><p>用<strong>LeNet-5</strong>对MNIST数据集进行训练，可以取得<strong>92%</strong>左右的效果，已比传统机器学习方法实现的效果更好。</p><p><img src="http://yann.lecun.com/exdb/lenet/gifs/a35.gif" alt=""></p><p>通过pytorch实现的LeNet结构</p><pre><code class="lang-python">class LeNet(nn.Module):    def __init__(self):        super(LeNet, self).__init__()        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2)        self.conv2 = nn.Conv2d(6, 16, 5)        # self.conv3 = nn.Conv2d(16, 120, 5)        self.fc1 = nn.Linear(16*5*5, 120)        self.fc2 = nn.Linear(120, 84)        self.fc3 = nn.Linear(84, 10)    def forward(self, x):        out = F.relu(self.conv1(x))  # 28*28*6        out = F.max_pool2d(out, 2)  # 14*14*6        out = F.relu(self.conv2(out))  # 10 *10 *16        out = F.max_pool2d(out, 2)  # 5*5*16        out = out.view(out.size(0), -1)        out = F.relu(self.fc1(out))        out = F.relu(self.fc2(out))        out = self.fc3(out)        return out</code></pre><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><blockquote><p>在LeNet-5之后，卷积神经网络由于硬件，数据等元素的局限，训练较为困难，所以发展一直都是不温不火，直到<strong>AlexNet</strong>在2012年<strong>ImageNet</strong>竞赛中以超越第二名10.9个百分点的优异成绩一举夺冠，从而打响了卷积神经网络、乃至深度学习在计算机视觉领域中研究热潮的“第一枪”。</p></blockquote><p><strong>结构</strong>：</p><p><img src="https://i.imgur.com/et352X8.png" alt=""></p><p>在AlexNet的网络结构中，共含五层卷积层和三层全连接层。AlexNet的上下两支是为了方便同时使用两片GPU进行训练，不过在第三层卷积和全连接层处上下两支信息可交互。由于两支网络完全一致，只需对其中一支进行分析。</p><ol><li><strong>卷积层C1</strong>：输入图像为$3\times224\times224$大小，实际是$3\times227\times227$大小，卷积核为$11<em>11$，不使用零填充，步长为$4$，总共使用$96$个卷积核，由公式可得$\lfloor\frac{227-11}{4}+1\rfloor=55$，即由卷积得到$96\times55\times55$大小的特征图。采用$3</em>3$尺度，步长为$2$去池化，则池化后的图像尺寸为$27$，所以像素规模为$96\times27\times27$，由于采用两个GPU，则分为两组，每组大小为$48\times27\times27$。</li><li><strong>卷积层C2</strong>: 对于上一层的输出，采用$256$个$3*3$大小的卷积核，使用$1$个padding，步长为$1$，对其进行卷积得到$256\times26\times26$的特征图，对其同样采用最大池化，上下两层分别得到$128\times13\times13$大小的输出特征图。</li><li><strong>卷积层C3</strong>：此层采用$384$个$3*3$大小的卷积核，同样使用$1$个零填充，上下两层分别得到$192\times13\times13$大小的输出图。</li><li><strong>卷积层C4</strong>: 同上一层，此层采用$384$个$3*3$大小的卷积核，同样使用$1$个零填充，上下两层分别得到$192 \times13\times13$大小的输出图。</li><li><strong>卷积层C5</strong>：此层采用$256$个$3*3$大小的卷积核，同样使用$1$个零填充，上下两层分别得到$128\times12\times12 $大小的输出图。再采用最大池化，降维到$128\times 6 \times 6$大小。</li><li><strong>全连接层</strong> ： 之后共采用了三层全连接结构，对于其中一个GPU, 特征大小逐渐从$128<em>6</em>6$到$2048$，再从$2048$到$2048$，最后将两个GPU合并，也就是将特征从$4096$映射到$1000$，也就是ImageNet中类别的数量。</li></ol><p><strong>贡献</strong>:</p><ul><li><strong>AlexNet</strong>  首次将卷积神经网络应用于计算机视觉领域的海量图像数据集<strong>ImageNet</strong>， 揭示了卷积神经网络拥有强大的学习能力和表达能力。另一方面海量的数据也能防止神经网络过拟合。自此引发深度学习井喷式增长。</li><li>利用<strong>GPU</strong>实现网络训练，之前由于计算资源的发展受限，阻碍了神经网络的研究进程。如今，利用GPU已大大减少了大型网络模型开发的成本和时间。</li><li>一些训练技巧为之后研究打下了基础。<strong>ReLU激活函数</strong>，<strong>局部响应规范化</strong>(LRN)操作(如今已不常用)，随机失活(<strong>Dropout</strong>: 随机再网络中去除一些连接)，这些训练技巧不仅保证了模型的性能，也为之后深度卷积神经网络构建提供了范本。</li></ul><p><strong>代码实现</strong>:</p><pre><code class="lang-python">class AlexNet(nn.Module):    def __init__(self, num_classes=1000):        super(AlexNet, self).__init__()        self.features = nn.Sequential(            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),            nn.ReLU(inplace=True),            LRN(local_size=5, alpha=0.0001, beta=0.75),            nn.MaxPool2d(kernel_size=3, stride=2),            nn.Conv2d(96, 256, kernel_size=5, padding=2, groups=2),            nn.ReLU(inplace=True),            LRN(local_size=5, alpha=0.0001, beta=0.75),            nn.MaxPool2d(kernel_size=3, stride=2),            nn.Conv2d(256, 384, kernel_size=3, padding=1),            nn.ReLU(inplace=True),            nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2),            nn.ReLU(inplace=True),            nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2),            nn.ReLU(inplace=True),            nn.MaxPool2d(kernel_size=3, stride=2),        )        self.classifier = nn.Sequential(            nn.Linear(256 * 6 * 6, 4096),            nn.ReLU(inplace=True),            nn.Dropout(),            nn.Linear(4096, 4096),            nn.ReLU(inplace=True),            nn.Dropout(),            nn.Linear(4096, num_classes),        )    def forward(self, x):        x = self.features(x)        x = x.view(x.size(0), 256 * 6 * 6)        x = self.classifier(x)        return x</code></pre><h3 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h3><p>VGG网络有类似Alex的形式，但它在一些地方也有不同。</p><ul><li>VGG-Net中普遍使用了小卷积核，AlexNet多采用的大于5的卷积核，而VGG的卷积核多为$3*3$</li><li>网络卷积层的通道数从$3\to64\to128\to256\to512$。通道数逐渐变得很大，学到的特征多。</li><li>VGG中的卷积很多都保持了输入大小，也就是卷积后大小保持不变，为的是在增加网络深度时确保各层输入大小随深度增加而不极具减小。</li></ul><p><strong>结构</strong></p><p><img src="https://i.imgur.com/t4U5sHK.png" alt=""></p><p><img src="https://i.imgur.com/rQwN1Zn.png" alt=""></p><h3 id="ResNets"><a href="#ResNets" class="headerlink" title="ResNets"></a>ResNets</h3><blockquote><p> 理论和实验表明，神经网络的<strong>深度</strong>和<strong>宽度</strong>是表征网络复杂度的两个核心因素，不过深度相比宽度在增加网络复杂性上更加有效，然而随着深度的增加，训练会变得愈加困难。这主要是因为在基于<strong>随机梯度下降</strong>的网络训练过程中，误差的多层反向传播会导致<strong>梯度弥散</strong>或<strong>梯度爆炸</strong>。可能随着网络的训练，误差并未减少而却增加。<strong>残差网络</strong>(ResNets)便很好地解决了这一问题。</p></blockquote><p><strong>残差块</strong></p><p><img src="https://i.imgur.com/qxiUrhA.png" alt=""></p><p>残差网络主要受<strong>高速网络</strong>的影响，假设某卷积神经网络有$L$层，其中第$i$层的输入为$x^{i}$，参数为$w^{i}$，该层的输出为$y^{i}=x^{i+1}$，忽略偏置，则之间关系表示为:</p><script type="math/tex; mode=display">y=F(x,w)</script><p>其中，$F$为非线性激活函数，而对于高速网络来言，$y$的计算定义如下:</p><script type="math/tex; mode=display">y=F(x,w)*(T(x,w)+x*C(x,w)</script><p>其中$T,C$是两个非线性变换,分别称作“<strong>变换门</strong>”和“<strong>携带门</strong>”。变换门负责控制变换的强度，携带门则控制原输入信号的保留强度，由于增加了<strong>保留原输入数据的可能性</strong>，所以这种网络会更加灵活。而残差网络可以看作其的特殊情况：本来优化目标为:</p><script type="math/tex; mode=display">y=F(x,w)+x</script><p>简单变形为</p><script type="math/tex; mode=display">F(x,w)=y-x</script><p>也就是说，网络所要学习的就是<strong>残差项</strong>$y-x$。残差块有两个学习分支，其一是左侧的残差函数，其二为右侧对输入的恒等映射。这两个分支经过简单的整合，再经过一个非线性变换<strong>ReLU</strong>，从而形成网络的残差块。由多个残差块堆积而成了<strong>残差网络</strong>。</p><p><img src="https://img-blog.csdn.net/20161028170505110" alt=""></p><ul><li>利用pytorch构建残差块</li></ul><pre><code class="lang-python"># Residual blockclass ResidualBlock(nn.Module):    def __init__(self, in_channels, out_channels, stride=1, downsample=None):        super(ResidualBlock, self).__init__()        self.conv1 = conv3x3(in_channels, out_channels, stride)        self.bn1 = nn.BatchNorm2d(out_channels)        self.relu = nn.ReLU(inplace=True)        self.conv2 = conv3x3(out_channels, out_channels)        self.bn2 = nn.BatchNorm2d(out_channels)        self.downsample = downsample    def forward(self, x):        residual = x        out = self.conv1(x)        out = self.bn1(out)        out = self.relu(out)        out = self.conv2(out)        out = self.bn2(out)        if self.downsample:            residual = self.downsample(x)        out += residual # 加上残差项        out = self.relu(out)        return out</code></pre><h3 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h3><blockquote><p>由于增加网络的深度和宽度会导致训练难以进行下去，<strong>Inception</strong>主要思路是用<strong>密集成分来近似最优的局部稀疏结构</strong>去加深网络的同时，增<strong>宽</strong>网络结构。</p></blockquote><p><strong>Inception模块</strong></p><p><img src="https://img-blog.csdn.net/20160225155351172" alt=""></p><ul><li>采用不同大小的卷积核，意味着得到不同大小的感受野，最后<strong>拼接</strong>起来意味着不同尺度的融合。</li><li>之所以卷积核采用1，3，5，主要为了方便对齐。设定步长$stide=1$之后，只要设定相应的$padding$为0， 1， 2，那么卷积之后即可得到相同维度的特征，那么这些特征即可拼接再一起。</li><li>在一个方向上先采用了最大化池化，这样能得到更好的效果。</li><li>采用了$1*1$卷积</li><li>网络越到后面，特征越抽象，而且每个特征涉及的感受野也更大了，因此随着层数的增加，$3<em>3$和$5</em>5$卷积的比例也要增加。</li></ul><p>由多个<strong>Inception</strong>模块构建成了<strong>GoogLeNet</strong></p><p><img src="https://img-blog.csdn.net/20160225155403967" alt=""></p><p>在Inception-v1之后为了提高训练速度和效果出现了许多衍生版本，但思想都不变，理解了Inception模块，就嫩理解Inception网络。</p><p>Inception模块的pytorch实现</p><pre><code class="lang-python">class Inception_base(nn.Module):    def __init__(self, depth_dim, input_size, config):        super(Inception_base, self).__init__()        self.depth_dim = depth_dim        #mixed &#39;name&#39;_1x1        self.conv1 = nn.Conv2d(input_size, out_channels=config[0][0], kernel_size=1, stride=1, padding=0)        #mixed &#39;name&#39;_3x3_bottleneck        self.conv3_1 = nn.Conv2d(input_size, out_channels=config[1][0], kernel_size=1, stride=1, padding=0)        #mixed &#39;name&#39;_3x3        self.conv3_3 = nn.Conv2d(config[1][0], config[1][1], kernel_size=3, stride=1, padding=1)        # mixed &#39;name&#39;_5x5_bottleneck        self.conv5_1 = nn.Conv2d(input_size, out_channels=config[2][0], kernel_size=1, stride=1, padding=0)        # mixed &#39;name&#39;_5x5        self.conv5_5 = nn.Conv2d(config[2][0], config[2][1], kernel_size=5, stride=1, padding=2)        self.max_pool_1 = nn.MaxPool2d(kernel_size=config[3][0], stride=1, padding=1)        #mixed &#39;name&#39;_pool_reduce        self.conv_max_1 = nn.Conv2d(input_size, out_channels=config[3][1], kernel_size=1, stride=1, padding=0)        self.apply(helpers.modules.layer_init)    def forward(self, input):        output1 = F.relu(self.conv1(input))        output2 = F.relu(self.conv3_1(input))        output2 = F.relu(self.conv3_3(output2))        output3 = F.relu(self.conv5_1(input))        output3 = F.relu(self.conv5_5(output3))        output4 = F.relu(self.conv_max_1(self.max_pool_1(input)))        return torch.cat([output1, output2, output3, output4], dim=self.depth_dim)</code></pre>]]></content>
      
      
        <tags>
            
            <tag> CNN 卷积神经网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>神经网络基础</title>
      <link href="/2018/05/12/nn-basic/"/>
      <url>/2018/05/12/nn-basic/</url>
      <content type="html"><![CDATA[<h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><p>如图，一个<strong>神经元通常有如下的结构</strong>：<img src="https://i.imgur.com/BT6bd4A.png" alt="Snipaste_2018-05-08_14-41-31"></p><p>对于一组输入${a_{1}, a_{2}….,a_{k}}$，分别施于不同的<strong>权重</strong>(weight)，再通过加上一个<strong>偏置</strong>(bias)，得到神经元的<strong>线性模型</strong>,也就是之前学过的线性规划:</p><script type="math/tex; mode=display">z=a_{1}w_{1}+a_{2}w_{2}+......+a_{k}w_{k}+b</script><p>用向量化表示为:</p><script type="math/tex; mode=display">z=w^{T}a+b</script><p>由于线性变化所能解决的问题并不多，所以在输出施加一个<strong>激活函数</strong>(<em>activate function</em>)， 以在方程模型中引入非线性，同时另外的作用是可对输出进行限制:</p><script type="math/tex; mode=display">a_{out}=\delta(z)=\delta(w^{T}a_{in}+b)</script><ul><li><strong>实例</strong></li></ul><p><img src="https://i.imgur.com/ZKWIH2G.png" alt="Snipaste_2018-05-08_14-59-43"></p><p>对于上方的神经元实例，输入$a=[2, -1, 1]^{T}$,对于其三个输入分别施加的权重为$w=[1,-2, -1]^{T}$，将偏置<em>bias</em>设置为$1$，激活函数选择<strong>Sigmoid</strong>函数$\delta(z)=\frac{1}{1+e^{-z}}$，所以计算结果可以得到:</p><script type="math/tex; mode=display">a_{out}=\delta(w^{T}x+b)=\frac{1}{1+e^{-(2*1+(-1)*(-2)+1*(-1)+1)}}=0.98</script><h3 id="全连接神经网络"><a href="#全连接神经网络" class="headerlink" title="全连接神经网络"></a>全连接神经网络</h3><p>对于许多神经元，将其组合起来，对于网络每一层，设置不同数量的神经元，即可得到一个<strong>全连接前馈神经网络</strong>：</p><p><img src="https://i.imgur.com/7ivKJwZ.png" alt="Snipaste_2018-05-08_15-11-01"></p><p>全连接神经网络通过输入的特征向量$x$，得到输出$y$，而网络层中的权重$w$和偏置$b$即是，网络中的参数。在训练过程中，可通过<strong>反向传播</strong>和<strong>梯度下降算法</strong>进行更新。</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><p>这里介绍三种常见激活函数：</p><ul><li><p><strong>Sigmoid</strong>:</p><script type="math/tex; mode=display">f(z)=\frac{1}{1+e^{-z}}</script><p>其图像可表示为:</p><p><img src="https://i.imgur.com/IRPHg7V.png" alt=""></p></li></ul><p>很明显，可以看出经过<strong>Sigmoid</strong>函数作用后，输出响应的值域被压缩到了[0,1]之间，这也是<strong>逻辑回归</strong>中用到它的原因。对<strong>Sigmoid</strong>函数求导：</p><script type="math/tex; mode=display">\frac{d}{dz}f(z)=\frac{e^{-z}}{(1+e^{-z})^{2}}</script><p>对梯度画出图可见:</p><p><img src="https://i.imgur.com/v9Vx5WH.png" alt="sigmoid_梯度"></p><p><strong>不足之处</strong>：</p><ol><li>当$z$大于5或者小于-5时，部分的梯度<strong>接近于0</strong>，这会导致在误差反向传播中，导数处于该区域内的误差很难传播到前层，进而影响整个网络导致其无法训练。</li><li>从<strong>Sigmoid</strong>函数中可以看出其值域的均值都大于0，而并非<strong>等于</strong>0，这也不满足神经网络内对数值的期望。</li></ol><ul><li><strong>Tanh：</strong></li></ul><script type="math/tex; mode=display">f(z)=\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}</script><p><img src="https://i.imgur.com/vBRVjtq.png" alt="tanh"></p><blockquote><p>Tanh函数在Sigmoid函数的基础上解决了<strong>均值问题</strong>。</p></blockquote><p><strong>Tanh</strong>函数又称作<strong>双曲正切函数</strong>，其函数范围为$(-1,1)$，输出的响应均值为0。<strong>Tanh</strong>函数与<strong>Sigmoid</strong>函数的关系为:</p><script type="math/tex; mode=display">Tanh(z)=2Sigmoid(2z)-1</script><p>所以，求<strong>Tanh</strong>的导数:</p><script type="math/tex; mode=display">\frac{d}{dz}Tanh(z)=4Sigmoid(2z)*Sigmoid(2z)^{'}=\frac{4e^{-2z}}{(1+e^{-2z})^{3}}</script><p>具体地：</p><script type="math/tex; mode=display">\frac{d}{dz}Tanh(z)=1-(tanh(z))^{2}</script><p>由于<strong>Tanh</strong>函数仍基于<strong>Sigmoid</strong>函数，所以使用它仍依然会有<strong>“梯度饱和”</strong>现象。</p><ul><li><strong>ReLU</strong></li></ul><blockquote><p>为了避免<strong>梯度饱和</strong>现象的发生，在神经网络中引入了修正线性单元(<em>Rectified Linear Unit</em>)。</p></blockquote><script type="math/tex; mode=display">ReLU(x)=max(0,x)</script><script type="math/tex; mode=display">\begin{equation}ReLU(x)=\begin{cases}x& x\ge0\\0& x<0\end{cases}\end{equation}</script><p><img src="https://i.imgur.com/1lU9PNR.png" alt="relu"></p><p><strong>ReLU</strong>的导数:</p><script type="math/tex; mode=display">\begin{equation}\frac{d}{dx}ReLU(x)=\begin{cases}1& x >0\\0& x<0\\undefined&x=0\end{cases}\end{equation}</script><p>与前两个激活函数相比，<strong>ReLU</strong>的梯度在$x\ge0$时为$1$，反之为$0$，对$x\ge0$部分完全消除了之前的梯度饱和效应。计算复杂度上，<strong>ReLU</strong>函数也相比之前的两种指数函数简单，实验中还发现其有助于随机梯度下降方法收敛。<strong>ReLU</strong>函数已是目前深层卷积神经网络中最为常用的激活函数。</p>]]></content>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>回归分析</title>
      <link href="/2018/05/11/regression/"/>
      <url>/2018/05/11/regression/</url>
      <content type="html"><![CDATA[<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><blockquote><p> <strong>回归分析</strong>是一种统计学上分析数据的方法，目的在于了解两个或多个变量是否相关、相关方向与程度，并建立数学模型以便观察特定变量来预测研究者感兴趣的变量。更具体的来说，回归分析可以帮助人们了解在只有一个自变量变化时因变量的变化量。一般来说，通过回归分析我们可以由给出的自变量估计因变量的条件期望。</p></blockquote><p><strong>线性回归</strong>可以说是机器学习中最简单的模型，但是其实际地位很重要。先通过<strong>房价预测</strong>的例子来了解线性回归。</p><hr><p>假设有一个房屋销售的数据如下</p><div class="table-container"><table><thead><tr><th>房屋面积(m^2)</th><th>销售价钱(万元)</th></tr></thead><tbody><tr><td>123</td><td>250</td></tr><tr><td>150</td><td>320</td></tr><tr><td>87</td><td>160</td></tr><tr><td>102</td><td>220</td></tr><tr><td>……….</td><td>………..</td></tr></tbody></table></div><p>我们用几何图表示出这样的数据</p><p><img src="https://i.imgur.com/0lc9czo.png" alt=""></p><p>当我们有很多组这样的数据时，这些就是训练数据，我们希望学习一个模型，当有新的一个面积数据来到时，可以自动预测出销售价钱。也就是我们可以在这张图上用一条直线去尽量拟合这些数据，当有新的值来到时，可以用这条直线所对应的值去返回预测的价钱， 绿色的点就是我们所想要预测的点。当然，不是说线性回归就一定是一条直线，当变量x是一维的时候才是一条直线，而在高维时，是<strong>超平面</strong> 。</p><p><img src="https://i.imgur.com/BRBoV1l.png" alt="pic"></p><p>在这里先定义下<strong>数学符号</strong>，我们用$X=(x_{1}, x_{2}, x_{3},…,x_{n})^{T}$来表示输入数据矩阵，其中$x_{i}\in R^{p}$表示一个p维度长的数据样本，$y = (y_{1}, y_{2}, ….,y_{n}) \in R^{n}$表示数据的标签。</p><p>线性回归的模型可以表示为， 对于一个样本$x_{i}$，它的输出值是其特征的线性组合：</p><script type="math/tex; mode=display">f(x_{i}) = \sum_{m=1}^{p}w_{m}x_{im} + w_{0} = w^{T}x_{i}</script><p>其中<strong>$w_{0}$</strong>称为截距，或者<em>bias</em> 。线性回归的目标是用预测结果尽可能地拟合目标<em>label</em> 。对于机器学习模型，需要定义一个<strong>损失函数</strong>(Loss function)，用它来表示其与真实输出之间的误差， 从而评判模型的好坏。在这里定义如下的损失函数：</p><script type="math/tex; mode=display">J(w) = \frac{1}{2}\sum_{i=1}^{n}(h_{w}(x^{i})-y^{i})^{2}</script><p>这个错误估计函数是去对$x^{i}$的估计值与真实值$y^{i}$差的平方和作为错误估计函数，前面乘上的1/2是为了在求导的时候，这个系数就不见了, 从而方便之后的求导计算。为了训练模型，去<strong>最小化误差</strong> ， 使其接近于0， 这里需要用到的方法称为<strong>梯度下降法</strong> 。先用张图表示:</p><p><img src="https://i.imgur.com/tYp7YPW.png" alt=""></p><blockquote><p>梯度下降法，就是要一步步沿着梯度反向方向逐渐下降，从而走到局部甚至全局最小值。</p></blockquote><p>梯度下降法是按以下流程逐渐进行的：</p><ol><li>首先对$w$赋值， 这个值可以是随机的，也可以让其是个全零的向量。</li><li>改变$w$的值，使得$J(w)$按梯度下降的方向进行减少。这一步，就需要先求得每个参数的梯度，再通过梯度，逐渐改变其值。<strong>数学公式</strong>表示为:</li></ol><script type="math/tex; mode=display">\frac{\partial}{\partial w}J(w) = \frac{\partial}{\partial w}\frac{1}{2}\sum_{i=1}^{n}(h_{w}(x)-y)^{2}=(h_{w}(x)-y)x^{(i)}</script><ol><li>求得梯度后，就能通过设置一个学习率$\alpha$来沿着梯度减少的方向变化:</li></ol><script type="math/tex; mode=display">w_{i} := w_{i}-\alpha\frac{\partial}{\partial w_{i}}J(w)</script><p>代入上式的损失函数和所计算的梯度，也就得到:</p><script type="math/tex; mode=display">w_{i} = w_{i} - \alpha\frac{\partial}{\partial w_{}}J(w) = w_{i} - \alpha(h_{0}(x)-y)x^{(i)}</script><p>在真实计算时，往往参数使用矩阵或向量表示:</p><script type="math/tex; mode=display">\nabla J = \begin{vmatrix} \frac{\partial}{\partial w_{1}} J \\ \frac{\partial}{\partial w_{2}} J \\ ... \\ \frac{\partial}{\partial w_{n}} J\end{vmatrix}</script><script type="math/tex; mode=display">w = w - \alpha \nabla_{w} J</script><ul><li>线性回归实现: </li></ul><pre><code class="lang-python"># Linear Regression Modelclass LinearRegression(nn.Module):    def __init__(self, input_size, output_size):        super(LinearRegression, self).__init__()        self.linear = nn.Linear(input_size, output_size)      def forward(self, x):        out = self.linear(x)        return out</code></pre><hr><h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><blockquote><p>逻辑回归也称为对数几率回归。明明叫回归，但却是<strong>分类问题</strong>中极为重要的手段。其思想也是基于线性回归，属于<strong>广义线性回归</strong>模型。</p></blockquote><p>对于二分类问题来讲，给你一个输入特征向量$X$，它可能对应一张图片，你想识别看它是否是一张猫的图片， 通过一个算法输出预测$\hat{y}$， 也就是对于实际值$y$的估计。换句话说，也就是想通过输入图片$X$， 想通过输出$\hat{y}$来知道这张图片是猫的几率有多大。用$w$来表示逻辑回归的参数，$x$是一个$n_{x}$维的特征向量，$b$表示这个模型中所要用到的偏置。如果用<strong>线性回归</strong>的方法来表示这个模型:</p><script type="math/tex; mode=display">\hat{y} = wx + b</script><p>这时候我们得到一个关于输入$x$的线性函数，但是对于这个二元分类来讲，似乎并不是一个很好的算法。因为我们想要得到的是这张图片是否为猫的概率，所以输出值应该介于<em>0 ~ 1</em>之间，而通过<strong>线性回归</strong>输出的$\hat{y}$可能要比1大很多，甚至为负值，这样来说这个模型就没有意义了，因此在<strong>逻辑回归</strong>当中，我们应将输出局限在<em>0~1</em>之间， 所以增加了一个<em>Sigmoid</em>函数将线性函数转换为非线性函数。</p><script type="math/tex; mode=display">\delta(z) = \frac{1}{1+e^{-z}}</script><p>使用<strong>matplotlib</strong>画出<em>Sigmoid</em>的图形表示如下，可以看出输出值都在<em>0~1</em>之间</p><pre><code class="lang-python"># 画sigmoidimport matplotlib.pyplot as pltimport numpy as npimport math%matplotlib inlinedef sigmoid(x):    a = []    for item in x:        a.append(1/(1+math.exp(-item)))    return ax = np.arange(-10, 10, 0.2)sig = sigmoid(x)plt.plot(x, sig)plt.show()</code></pre><p><img src="https://i.imgur.com/IRPHg7V.png" alt=""></p><p>如果$z$非常大那么$e^{-z}$将会接近于0，那么<strong>sigmoid</strong>函数的值将会近似等于1除以1加上某个非常接近于0的项，因为$e$ 的指数如果是个绝对值很大的负数的话，这项将会接近于0，所以如果$z$很大的话那么关于$z$的<strong>sigmoid</strong>函数会非常接近1。相反地，如果$z$非常小或者说是一个绝对值很大的负数，那么关于$e^{-z}$这项会变成一个很大的数，你可以认为这是1除以1加上一个非常非常大的数，所以这个就接近于0 。</p><p>所以要将识别猫这个任务所得到的结果规定在<em>0~1</em>之间，那么久需要对刚才定义的线性模型增加一个<strong>sigmoid</strong>函数，使其变为非线性:</p><script type="math/tex; mode=display">\hat{y} = \delta(wx+b)</script><script type="math/tex; mode=display">\delta(z) = \frac{1}{1+e^{-z}}</script><p>也就是:</p><script type="math/tex; mode=display">\hat{y}(x)=\frac{1}{1+e^{-(wx+b)}}</script><p>有了这个模型，要去实现这个识别猫的分类任务，接下来要做的就是通过给定的数据集，通过训练模型，把$w$参数给找出来。要找模型中的权重，就需要先定义<strong>损失函数</strong>。那么怎么去找到能衡量这个二分类的损失函数，通过使用<strong>极大似然估计</strong>。由于所要判断出的图片，只有两种可能:</p><ul><li>1表示图片里是猫</li><li>0表示图片里不是猫</li></ul><p>所以这两种情况的概率分别为:</p><script type="math/tex; mode=display">P(y=1|x; w) = \phi(w^{T}x+b)=\phi(z)</script><script type="math/tex; mode=display">P(y=0|x;w)=1-\phi(w^{T}x+b)=1-\phi(z)</script><p>根据上面两式，通过<strong>最大似然估计</strong>求解损失函数，首先得到<strong>概率函数</strong>为:</p><script type="math/tex; mode=display">P(y|x;w)=\phi(z)^{y}(1-\phi(z))^{(1-y)}</script><p>因为数据集中样本数据是相互独立的，所以它们的联合分布可以表示为总的乘积:</p><script type="math/tex; mode=display">L(w)=\prod_{i=1}^{m}P(y^{i}|x^{i};w)</script><script type="math/tex; mode=display">L(w) =\prod_{i=1}^{m}\phi(z^{i})^{y^{i}}(1-\phi(z^{i}))^{1-y^{i}}</script><p>取<strong>对数似然函数</strong>:</p><script type="math/tex; mode=display">l(w)=ln(L(w))=\sum_{i=1}^{m}ln(\phi(z^{i})^{y^{i}})+ln(1-\phi(z^{i}))^{(1-y^{i})}</script><script type="math/tex; mode=display">l(w)=ln(L(w))=\sum_{i=1}^{m}y^{i}ln(\phi(z^{i}))+(1-y^{i})ln(1-\phi(z^{i}))</script><p>最大似然估计就是要取使$l(w)$最大时的$w$,所以在前面加上一个<strong>负号</strong>不就是使求其最小了吗？这样就得到损失函数:</p><script type="math/tex; mode=display">J(w) = -l(w)=-y^{i}ln(\phi(z^{i}))-(1-y^{i})ln(1-\phi(z^{i}))</script><p>所以简化形式的损失函数为:</p><script type="math/tex; mode=display">L(\hat{y}, y)=-yln(\hat{y})-(1-y)ln(1-\hat{y})</script><p>当$y=1$时损失函数$L=-ln(\hat{y})$，如果想要损失函数$L$尽可能得小，那么$\hat{y}$就要尽可能大，因为<strong>sigmoid</strong>函数取值$[0,1]$，所以$\hat{y}$会无限接近于1。</p><p>当$y=0$时损失函数$L=-ln(1-\hat{y})$，如果想要损失函数$L$尽可能得小，那么$\hat{y}$就要尽可能小，因为<strong>sigmoid</strong>函数取值$[0,1]$，所以$\hat{y}$会无限接近于0。</p><p>这只是对于单个样本的损失函数，对于总的样本，需将所有代价加起来除以m：</p><script type="math/tex; mode=display">J(w)=\frac{1}{m}\sum_{i=1}^{m}L(\hat{y}, y)</script><p>接下来要做的就是通过<strong>梯度下降法</strong>求得导数，再如之前一样更新参数$w$和$b$的值即可。</p><p>同样使用<strong>pytorch</strong>来实现逻辑回归模型:</p><pre><code class="lang-python">class LogisticRegression(nn.Module):    def __init__(self, input_size, num_classes):        super(LogisticRegression, self).__init__()        self.linear = nn.Linear(input_size, num_classes)    def forward(self, x):        out = self.linear(x)        out = torch.sigmoid(out)        return out</code></pre>]]></content>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
